{"ast":null,"code":"const Long = require('../utils/long');\n\nconst createRetry = require('../retry');\n\nconst {\n  initialRetryTime\n} = require('../retry/defaults');\n\nconst ConsumerGroup = require('./consumerGroup');\n\nconst Runner = require('./runner');\n\nconst {\n  events,\n  wrap: wrapEvent,\n  unwrap: unwrapEvent\n} = require('./instrumentationEvents');\n\nconst InstrumentationEventEmitter = require('../instrumentation/emitter');\n\nconst {\n  KafkaJSNonRetriableError\n} = require('../errors');\n\nconst {\n  roundRobin\n} = require('./assigners');\n\nconst {\n  EARLIEST_OFFSET,\n  LATEST_OFFSET\n} = require('../constants');\n\nconst ISOLATION_LEVEL = require('../protocol/isolationLevel');\n\nconst {\n  keys,\n  values\n} = Object;\nconst {\n  CONNECT,\n  DISCONNECT,\n  STOP,\n  CRASH\n} = events;\nconst eventNames = values(events);\nconst eventKeys = keys(events).map(key => `consumer.events.${key}`).join(', ');\nconst specialOffsets = [Long.fromValue(EARLIEST_OFFSET).toString(), Long.fromValue(LATEST_OFFSET).toString()];\n/**\n * @param {Object} params\n * @param {import(\"../../types\").Cluster} params.cluster\n * @param {String} params.groupId\n * @param {import('../../types').RetryOptions} params.retry\n * @param {import('../../types').Logger} params.logger\n * @param {import('../../types').PartitionAssigner[]} [params.partitionAssigners]\n * @param {number} [params.sessionTimeout]\n * @param {number} [params.rebalanceTimeout]\n * @param {number} [params.heartbeatInterval]\n * @param {number} [params.maxBytesPerPartition]\n * @param {number} [params.minBytes]\n * @param {number} [params.maxBytes]\n * @param {number} [params.maxWaitTimeInMs]\n * @param {number} [params.isolationLevel]\n * @param {string} [params.rackId]\n * @param {import('../instrumentation/emitter')} [params.instrumentationEmitter]\n * @param {number} params.metadataMaxAge\n *\n * @returns {import(\"../../types\").Consumer}\n */\n\nmodule.exports = ({\n  cluster,\n  groupId,\n  retry,\n  logger: rootLogger,\n  partitionAssigners = [roundRobin],\n  sessionTimeout = 30000,\n  rebalanceTimeout = 60000,\n  heartbeatInterval = 3000,\n  maxBytesPerPartition = 1048576,\n  // 1MB\n  minBytes = 1,\n  maxBytes = 10485760,\n  // 10MB\n  maxWaitTimeInMs = 5000,\n  isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,\n  rackId = '',\n  instrumentationEmitter: rootInstrumentationEmitter,\n  metadataMaxAge\n}) => {\n  if (!groupId) {\n    throw new KafkaJSNonRetriableError('Consumer groupId must be a non-empty string.');\n  }\n\n  const logger = rootLogger.namespace('Consumer');\n  const instrumentationEmitter = rootInstrumentationEmitter || new InstrumentationEventEmitter();\n  const assigners = partitionAssigners.map(createAssigner => createAssigner({\n    groupId,\n    logger,\n    cluster\n  }));\n  const topics = {};\n  let runner = null;\n  let consumerGroup = null;\n\n  if (heartbeatInterval >= sessionTimeout) {\n    throw new KafkaJSNonRetriableError(`Consumer heartbeatInterval (${heartbeatInterval}) must be lower than sessionTimeout (${sessionTimeout}). It is recommended to set heartbeatInterval to approximately a third of the sessionTimeout.`);\n  }\n\n  const createConsumerGroup = ({\n    autoCommitInterval,\n    autoCommitThreshold\n  }) => {\n    return new ConsumerGroup({\n      logger: rootLogger,\n      topics: keys(topics),\n      topicConfigurations: topics,\n      retry,\n      cluster,\n      groupId,\n      assigners,\n      sessionTimeout,\n      rebalanceTimeout,\n      maxBytesPerPartition,\n      minBytes,\n      maxBytes,\n      maxWaitTimeInMs,\n      instrumentationEmitter,\n      autoCommitInterval,\n      autoCommitThreshold,\n      isolationLevel,\n      rackId,\n      metadataMaxAge\n    });\n  };\n\n  const createRunner = ({\n    eachBatchAutoResolve,\n    eachBatch,\n    eachMessage,\n    onCrash,\n    autoCommit,\n    partitionsConsumedConcurrently\n  }) => {\n    return new Runner({\n      autoCommit,\n      logger: rootLogger,\n      consumerGroup,\n      instrumentationEmitter,\n      eachBatchAutoResolve,\n      eachBatch,\n      eachMessage,\n      heartbeatInterval,\n      retry,\n      onCrash,\n      partitionsConsumedConcurrently\n    });\n  };\n  /** @type {import(\"../../types\").Consumer[\"connect\"]} */\n\n\n  const connect = async () => {\n    await cluster.connect();\n    instrumentationEmitter.emit(CONNECT);\n  };\n  /** @type {import(\"../../types\").Consumer[\"disconnect\"]} */\n\n\n  const disconnect = async () => {\n    try {\n      await stop();\n      logger.debug('consumer has stopped, disconnecting', {\n        groupId\n      });\n      await cluster.disconnect();\n      instrumentationEmitter.emit(DISCONNECT);\n    } catch (e) {}\n  };\n  /** @type {import(\"../../types\").Consumer[\"stop\"]} */\n\n\n  const stop = async () => {\n    try {\n      if (runner) {\n        await runner.stop();\n        runner = null;\n        consumerGroup = null;\n        instrumentationEmitter.emit(STOP);\n      }\n\n      logger.info('Stopped', {\n        groupId\n      });\n    } catch (e) {}\n  };\n  /** @type {import(\"../../types\").Consumer[\"subscribe\"]} */\n\n\n  const subscribe = async ({\n    topic,\n    fromBeginning = false\n  }) => {\n    if (consumerGroup) {\n      throw new KafkaJSNonRetriableError('Cannot subscribe to topic while consumer is running');\n    }\n\n    if (!topic) {\n      throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);\n    }\n\n    const isRegExp = topic instanceof RegExp;\n\n    if (typeof topic !== 'string' && !isRegExp) {\n      throw new KafkaJSNonRetriableError(`Invalid topic ${topic} (${typeof topic}), the topic name has to be a String or a RegExp`);\n    }\n\n    const topicsToSubscribe = [];\n\n    if (isRegExp) {\n      const topicRegExp = topic;\n      const metadata = await cluster.metadata();\n      const matchedTopics = metadata.topicMetadata.map(({\n        topic: topicName\n      }) => topicName).filter(topicName => topicRegExp.test(topicName));\n      logger.debug('Subscription based on RegExp', {\n        groupId,\n        topicRegExp: topicRegExp.toString(),\n        matchedTopics\n      });\n      topicsToSubscribe.push(...matchedTopics);\n    } else {\n      topicsToSubscribe.push(topic);\n    }\n\n    for (const t of topicsToSubscribe) {\n      topics[t] = {\n        fromBeginning\n      };\n    }\n\n    await cluster.addMultipleTargetTopics(topicsToSubscribe);\n  };\n  /** @type {import(\"../../types\").Consumer[\"run\"]} */\n\n\n  const run = async ({\n    autoCommit = true,\n    autoCommitInterval = null,\n    autoCommitThreshold = null,\n    eachBatchAutoResolve = true,\n    partitionsConsumedConcurrently = 1,\n    eachBatch = null,\n    eachMessage = null\n  } = {}) => {\n    if (consumerGroup) {\n      logger.warn('consumer#run was called, but the consumer is already running', {\n        groupId\n      });\n      return;\n    }\n\n    consumerGroup = createConsumerGroup({\n      autoCommitInterval,\n      autoCommitThreshold\n    });\n\n    const start = async onCrash => {\n      logger.info('Starting', {\n        groupId\n      });\n      runner = createRunner({\n        autoCommit,\n        eachBatchAutoResolve,\n        eachBatch,\n        eachMessage,\n        onCrash,\n        partitionsConsumedConcurrently\n      });\n      await runner.start();\n    };\n\n    const restart = onCrash => {\n      consumerGroup = createConsumerGroup({\n        autoCommitInterval,\n        autoCommitThreshold\n      });\n      start(onCrash);\n    };\n\n    const onCrash = async e => {\n      logger.error(`Crash: ${e.name}: ${e.message}`, {\n        groupId,\n        retryCount: e.retryCount,\n        stack: e.stack\n      });\n\n      if (e.name === 'KafkaJSConnectionClosedError') {\n        cluster.removeBroker({\n          host: e.host,\n          port: e.port\n        });\n      }\n\n      await disconnect();\n      const isErrorRetriable = e.name === 'KafkaJSNumberOfRetriesExceeded' || e.retriable === true;\n      const shouldRestart = isErrorRetriable && (!retry || !retry.restartOnFailure || (await retry.restartOnFailure(e).catch(error => {\n        logger.error('Caught error when invoking user-provided \"restartOnFailure\" callback. Defaulting to restarting.', {\n          error: error.message || error,\n          originalError: e.message || e,\n          groupId\n        });\n        return true;\n      })));\n      instrumentationEmitter.emit(CRASH, {\n        error: e,\n        groupId,\n        restart: shouldRestart\n      });\n\n      if (shouldRestart) {\n        const retryTime = e.retryTime || retry && retry.initialRetryTime || initialRetryTime;\n        logger.error(`Restarting the consumer in ${retryTime}ms`, {\n          retryCount: e.retryCount,\n          retryTime,\n          groupId\n        });\n        setTimeout(() => restart(onCrash), retryTime);\n      }\n    };\n\n    await start(onCrash);\n  };\n  /** @type {import(\"../../types\").Consumer[\"on\"]} */\n\n\n  const on = (eventName, listener) => {\n    if (!eventNames.includes(eventName)) {\n      throw new KafkaJSNonRetriableError(`Event name should be one of ${eventKeys}`);\n    }\n\n    return instrumentationEmitter.addListener(unwrapEvent(eventName), event => {\n      event.type = wrapEvent(event.type);\n      Promise.resolve(listener(event)).catch(e => {\n        logger.error(`Failed to execute listener: ${e.message}`, {\n          eventName,\n          stack: e.stack\n        });\n      });\n    });\n  };\n  /**\n   * @type {import(\"../../types\").Consumer[\"commitOffsets\"]}\n   * @param topicPartitions\n   *   Example: [{ topic: 'topic-name', partition: 0, offset: '1', metadata: 'event-id-3' }]\n   */\n\n\n  const commitOffsets = async (topicPartitions = []) => {\n    const commitsByTopic = topicPartitions.reduce((payload, {\n      topic,\n      partition,\n      offset,\n      metadata = null\n    }) => {\n      if (!topic) {\n        throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);\n      }\n\n      if (isNaN(partition)) {\n        throw new KafkaJSNonRetriableError(`Invalid partition, expected a number received ${partition}`);\n      }\n\n      let commitOffset;\n\n      try {\n        commitOffset = Long.fromValue(offset);\n      } catch (_) {\n        throw new KafkaJSNonRetriableError(`Invalid offset, expected a long received ${offset}`);\n      }\n\n      if (commitOffset.lessThan(0)) {\n        throw new KafkaJSNonRetriableError('Offset must not be a negative number');\n      }\n\n      if (metadata !== null && typeof metadata !== 'string') {\n        throw new KafkaJSNonRetriableError(`Invalid offset metadata, expected string or null, received ${metadata}`);\n      }\n\n      const topicCommits = payload[topic] || [];\n      topicCommits.push({\n        partition,\n        offset: commitOffset,\n        metadata\n      });\n      return { ...payload,\n        [topic]: topicCommits\n      };\n    }, {});\n\n    if (!consumerGroup) {\n      throw new KafkaJSNonRetriableError('Consumer group was not initialized, consumer#run must be called first');\n    }\n\n    const topics = Object.keys(commitsByTopic);\n    return runner.commitOffsets({\n      topics: topics.map(topic => {\n        return {\n          topic,\n          partitions: commitsByTopic[topic]\n        };\n      })\n    });\n  };\n  /** @type {import(\"../../types\").Consumer[\"seek\"]} */\n\n\n  const seek = ({\n    topic,\n    partition,\n    offset\n  }) => {\n    if (!topic) {\n      throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);\n    }\n\n    if (isNaN(partition)) {\n      throw new KafkaJSNonRetriableError(`Invalid partition, expected a number received ${partition}`);\n    }\n\n    let seekOffset;\n\n    try {\n      seekOffset = Long.fromValue(offset);\n    } catch (_) {\n      throw new KafkaJSNonRetriableError(`Invalid offset, expected a long received ${offset}`);\n    }\n\n    if (seekOffset.lessThan(0) && !specialOffsets.includes(seekOffset.toString())) {\n      throw new KafkaJSNonRetriableError('Offset must not be a negative number');\n    }\n\n    if (!consumerGroup) {\n      throw new KafkaJSNonRetriableError('Consumer group was not initialized, consumer#run must be called first');\n    }\n\n    consumerGroup.seek({\n      topic,\n      partition,\n      offset: seekOffset.toString()\n    });\n  };\n  /** @type {import(\"../../types\").Consumer[\"describeGroup\"]} */\n\n\n  const describeGroup = async () => {\n    const coordinator = await cluster.findGroupCoordinator({\n      groupId\n    });\n    const retrier = createRetry(retry);\n    return retrier(async () => {\n      const {\n        groups\n      } = await coordinator.describeGroups({\n        groupIds: [groupId]\n      });\n      return groups.find(group => group.groupId === groupId);\n    });\n  };\n  /**\n   * @type {import(\"../../types\").Consumer[\"pause\"]}\n   * @param topicPartitions\n   *   Example: [{ topic: 'topic-name', partitions: [1, 2] }]\n   */\n\n\n  const pause = (topicPartitions = []) => {\n    for (const topicPartition of topicPartitions) {\n      if (!topicPartition || !topicPartition.topic) {\n        throw new KafkaJSNonRetriableError(`Invalid topic ${topicPartition && topicPartition.topic || topicPartition}`);\n      } else if (typeof topicPartition.partitions !== 'undefined' && (!Array.isArray(topicPartition.partitions) || topicPartition.partitions.some(isNaN))) {\n        throw new KafkaJSNonRetriableError(`Array of valid partitions required to pause specific partitions instead of ${topicPartition.partitions}`);\n      }\n    }\n\n    if (!consumerGroup) {\n      throw new KafkaJSNonRetriableError('Consumer group was not initialized, consumer#run must be called first');\n    }\n\n    consumerGroup.pause(topicPartitions);\n  };\n  /**\n   * Returns the list of topic partitions paused on this consumer\n   *\n   * @type {import(\"../../types\").Consumer[\"paused\"]}\n   */\n\n\n  const paused = () => {\n    if (!consumerGroup) {\n      return [];\n    }\n\n    return consumerGroup.paused();\n  };\n  /**\n   * @type {import(\"../../types\").Consumer[\"resume\"]}\n   * @param topicPartitions\n   *  Example: [{ topic: 'topic-name', partitions: [1, 2] }]\n   */\n\n\n  const resume = (topicPartitions = []) => {\n    for (const topicPartition of topicPartitions) {\n      if (!topicPartition || !topicPartition.topic) {\n        throw new KafkaJSNonRetriableError(`Invalid topic ${topicPartition && topicPartition.topic || topicPartition}`);\n      } else if (typeof topicPartition.partitions !== 'undefined' && (!Array.isArray(topicPartition.partitions) || topicPartition.partitions.some(isNaN))) {\n        throw new KafkaJSNonRetriableError(`Array of valid partitions required to resume specific partitions instead of ${topicPartition.partitions}`);\n      }\n    }\n\n    if (!consumerGroup) {\n      throw new KafkaJSNonRetriableError('Consumer group was not initialized, consumer#run must be called first');\n    }\n\n    consumerGroup.resume(topicPartitions);\n  };\n  /**\n   * @return {Object} logger\n   */\n\n\n  const getLogger = () => logger;\n\n  return {\n    connect,\n    disconnect,\n    subscribe,\n    stop,\n    run,\n    commitOffsets,\n    seek,\n    describeGroup,\n    pause,\n    paused,\n    resume,\n    on,\n    events,\n    logger: getLogger\n  };\n};","map":{"version":3,"sources":["/Users/gagekrumbach/Documents/call-center-manage/node_modules/kafkajs/src/consumer/index.js"],"names":["Long","require","createRetry","initialRetryTime","ConsumerGroup","Runner","events","wrap","wrapEvent","unwrap","unwrapEvent","InstrumentationEventEmitter","KafkaJSNonRetriableError","roundRobin","EARLIEST_OFFSET","LATEST_OFFSET","ISOLATION_LEVEL","keys","values","Object","CONNECT","DISCONNECT","STOP","CRASH","eventNames","eventKeys","map","key","join","specialOffsets","fromValue","toString","module","exports","cluster","groupId","retry","logger","rootLogger","partitionAssigners","sessionTimeout","rebalanceTimeout","heartbeatInterval","maxBytesPerPartition","minBytes","maxBytes","maxWaitTimeInMs","isolationLevel","READ_COMMITTED","rackId","instrumentationEmitter","rootInstrumentationEmitter","metadataMaxAge","namespace","assigners","createAssigner","topics","runner","consumerGroup","createConsumerGroup","autoCommitInterval","autoCommitThreshold","topicConfigurations","createRunner","eachBatchAutoResolve","eachBatch","eachMessage","onCrash","autoCommit","partitionsConsumedConcurrently","connect","emit","disconnect","stop","debug","e","info","subscribe","topic","fromBeginning","isRegExp","RegExp","topicsToSubscribe","topicRegExp","metadata","matchedTopics","topicMetadata","topicName","filter","test","push","t","addMultipleTargetTopics","run","warn","start","restart","error","name","message","retryCount","stack","removeBroker","host","port","isErrorRetriable","retriable","shouldRestart","restartOnFailure","catch","originalError","retryTime","setTimeout","on","eventName","listener","includes","addListener","event","type","Promise","resolve","commitOffsets","topicPartitions","commitsByTopic","reduce","payload","partition","offset","isNaN","commitOffset","_","lessThan","topicCommits","partitions","seek","seekOffset","describeGroup","coordinator","findGroupCoordinator","retrier","groups","describeGroups","groupIds","find","group","pause","topicPartition","Array","isArray","some","paused","resume","getLogger"],"mappings":"AAAA,MAAMA,IAAI,GAAGC,OAAO,CAAC,eAAD,CAApB;;AACA,MAAMC,WAAW,GAAGD,OAAO,CAAC,UAAD,CAA3B;;AACA,MAAM;AAAEE,EAAAA;AAAF,IAAuBF,OAAO,CAAC,mBAAD,CAApC;;AACA,MAAMG,aAAa,GAAGH,OAAO,CAAC,iBAAD,CAA7B;;AACA,MAAMI,MAAM,GAAGJ,OAAO,CAAC,UAAD,CAAtB;;AACA,MAAM;AAAEK,EAAAA,MAAF;AAAUC,EAAAA,IAAI,EAAEC,SAAhB;AAA2BC,EAAAA,MAAM,EAAEC;AAAnC,IAAmDT,OAAO,CAAC,yBAAD,CAAhE;;AACA,MAAMU,2BAA2B,GAAGV,OAAO,CAAC,4BAAD,CAA3C;;AACA,MAAM;AAAEW,EAAAA;AAAF,IAA+BX,OAAO,CAAC,WAAD,CAA5C;;AACA,MAAM;AAAEY,EAAAA;AAAF,IAAiBZ,OAAO,CAAC,aAAD,CAA9B;;AACA,MAAM;AAAEa,EAAAA,eAAF;AAAmBC,EAAAA;AAAnB,IAAqCd,OAAO,CAAC,cAAD,CAAlD;;AACA,MAAMe,eAAe,GAAGf,OAAO,CAAC,4BAAD,CAA/B;;AAEA,MAAM;AAAEgB,EAAAA,IAAF;AAAQC,EAAAA;AAAR,IAAmBC,MAAzB;AACA,MAAM;AAAEC,EAAAA,OAAF;AAAWC,EAAAA,UAAX;AAAuBC,EAAAA,IAAvB;AAA6BC,EAAAA;AAA7B,IAAuCjB,MAA7C;AAEA,MAAMkB,UAAU,GAAGN,MAAM,CAACZ,MAAD,CAAzB;AACA,MAAMmB,SAAS,GAAGR,IAAI,CAACX,MAAD,CAAJ,CACfoB,GADe,CACXC,GAAG,IAAK,mBAAkBA,GAAI,EADnB,EAEfC,IAFe,CAEV,IAFU,CAAlB;AAIA,MAAMC,cAAc,GAAG,CACrB7B,IAAI,CAAC8B,SAAL,CAAehB,eAAf,EAAgCiB,QAAhC,EADqB,EAErB/B,IAAI,CAAC8B,SAAL,CAAef,aAAf,EAA8BgB,QAA9B,EAFqB,CAAvB;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACAC,MAAM,CAACC,OAAP,GAAiB,CAAC;AAChBC,EAAAA,OADgB;AAEhBC,EAAAA,OAFgB;AAGhBC,EAAAA,KAHgB;AAIhBC,EAAAA,MAAM,EAAEC,UAJQ;AAKhBC,EAAAA,kBAAkB,GAAG,CAAC1B,UAAD,CALL;AAMhB2B,EAAAA,cAAc,GAAG,KAND;AAOhBC,EAAAA,gBAAgB,GAAG,KAPH;AAQhBC,EAAAA,iBAAiB,GAAG,IARJ;AAShBC,EAAAA,oBAAoB,GAAG,OATP;AASgB;AAChCC,EAAAA,QAAQ,GAAG,CAVK;AAWhBC,EAAAA,QAAQ,GAAG,QAXK;AAWK;AACrBC,EAAAA,eAAe,GAAG,IAZF;AAahBC,EAAAA,cAAc,GAAG/B,eAAe,CAACgC,cAbjB;AAchBC,EAAAA,MAAM,GAAG,EAdO;AAehBC,EAAAA,sBAAsB,EAAEC,0BAfR;AAgBhBC,EAAAA;AAhBgB,CAAD,KAiBX;AACJ,MAAI,CAACjB,OAAL,EAAc;AACZ,UAAM,IAAIvB,wBAAJ,CAA6B,8CAA7B,CAAN;AACD;;AAED,QAAMyB,MAAM,GAAGC,UAAU,CAACe,SAAX,CAAqB,UAArB,CAAf;AACA,QAAMH,sBAAsB,GAAGC,0BAA0B,IAAI,IAAIxC,2BAAJ,EAA7D;AACA,QAAM2C,SAAS,GAAGf,kBAAkB,CAACb,GAAnB,CAAuB6B,cAAc,IACrDA,cAAc,CAAC;AAAEpB,IAAAA,OAAF;AAAWE,IAAAA,MAAX;AAAmBH,IAAAA;AAAnB,GAAD,CADE,CAAlB;AAIA,QAAMsB,MAAM,GAAG,EAAf;AACA,MAAIC,MAAM,GAAG,IAAb;AACA,MAAIC,aAAa,GAAG,IAApB;;AAEA,MAAIhB,iBAAiB,IAAIF,cAAzB,EAAyC;AACvC,UAAM,IAAI5B,wBAAJ,CACH,+BAA8B8B,iBAAkB,wCAAuCF,cAAe,+FADnG,CAAN;AAGD;;AAED,QAAMmB,mBAAmB,GAAG,CAAC;AAAEC,IAAAA,kBAAF;AAAsBC,IAAAA;AAAtB,GAAD,KAAiD;AAC3E,WAAO,IAAIzD,aAAJ,CAAkB;AACvBiC,MAAAA,MAAM,EAAEC,UADe;AAEvBkB,MAAAA,MAAM,EAAEvC,IAAI,CAACuC,MAAD,CAFW;AAGvBM,MAAAA,mBAAmB,EAAEN,MAHE;AAIvBpB,MAAAA,KAJuB;AAKvBF,MAAAA,OALuB;AAMvBC,MAAAA,OANuB;AAOvBmB,MAAAA,SAPuB;AAQvBd,MAAAA,cARuB;AASvBC,MAAAA,gBATuB;AAUvBE,MAAAA,oBAVuB;AAWvBC,MAAAA,QAXuB;AAYvBC,MAAAA,QAZuB;AAavBC,MAAAA,eAbuB;AAcvBI,MAAAA,sBAduB;AAevBU,MAAAA,kBAfuB;AAgBvBC,MAAAA,mBAhBuB;AAiBvBd,MAAAA,cAjBuB;AAkBvBE,MAAAA,MAlBuB;AAmBvBG,MAAAA;AAnBuB,KAAlB,CAAP;AAqBD,GAtBD;;AAwBA,QAAMW,YAAY,GAAG,CAAC;AACpBC,IAAAA,oBADoB;AAEpBC,IAAAA,SAFoB;AAGpBC,IAAAA,WAHoB;AAIpBC,IAAAA,OAJoB;AAKpBC,IAAAA,UALoB;AAMpBC,IAAAA;AANoB,GAAD,KAOf;AACJ,WAAO,IAAIhE,MAAJ,CAAW;AAChB+D,MAAAA,UADgB;AAEhB/B,MAAAA,MAAM,EAAEC,UAFQ;AAGhBoB,MAAAA,aAHgB;AAIhBR,MAAAA,sBAJgB;AAKhBc,MAAAA,oBALgB;AAMhBC,MAAAA,SANgB;AAOhBC,MAAAA,WAPgB;AAQhBxB,MAAAA,iBARgB;AAShBN,MAAAA,KATgB;AAUhB+B,MAAAA,OAVgB;AAWhBE,MAAAA;AAXgB,KAAX,CAAP;AAaD,GArBD;AAuBA;;;AACA,QAAMC,OAAO,GAAG,YAAY;AAC1B,UAAMpC,OAAO,CAACoC,OAAR,EAAN;AACApB,IAAAA,sBAAsB,CAACqB,IAAvB,CAA4BnD,OAA5B;AACD,GAHD;AAKA;;;AACA,QAAMoD,UAAU,GAAG,YAAY;AAC7B,QAAI;AACF,YAAMC,IAAI,EAAV;AACApC,MAAAA,MAAM,CAACqC,KAAP,CAAa,qCAAb,EAAoD;AAAEvC,QAAAA;AAAF,OAApD;AACA,YAAMD,OAAO,CAACsC,UAAR,EAAN;AACAtB,MAAAA,sBAAsB,CAACqB,IAAvB,CAA4BlD,UAA5B;AACD,KALD,CAKE,OAAOsD,CAAP,EAAU,CAAE;AACf,GAPD;AASA;;;AACA,QAAMF,IAAI,GAAG,YAAY;AACvB,QAAI;AACF,UAAIhB,MAAJ,EAAY;AACV,cAAMA,MAAM,CAACgB,IAAP,EAAN;AACAhB,QAAAA,MAAM,GAAG,IAAT;AACAC,QAAAA,aAAa,GAAG,IAAhB;AACAR,QAAAA,sBAAsB,CAACqB,IAAvB,CAA4BjD,IAA5B;AACD;;AAEDe,MAAAA,MAAM,CAACuC,IAAP,CAAY,SAAZ,EAAuB;AAAEzC,QAAAA;AAAF,OAAvB;AACD,KATD,CASE,OAAOwC,CAAP,EAAU,CAAE;AACf,GAXD;AAaA;;;AACA,QAAME,SAAS,GAAG,OAAO;AAAEC,IAAAA,KAAF;AAASC,IAAAA,aAAa,GAAG;AAAzB,GAAP,KAA4C;AAC5D,QAAIrB,aAAJ,EAAmB;AACjB,YAAM,IAAI9C,wBAAJ,CAA6B,qDAA7B,CAAN;AACD;;AAED,QAAI,CAACkE,KAAL,EAAY;AACV,YAAM,IAAIlE,wBAAJ,CAA8B,iBAAgBkE,KAAM,EAApD,CAAN;AACD;;AAED,UAAME,QAAQ,GAAGF,KAAK,YAAYG,MAAlC;;AACA,QAAI,OAAOH,KAAP,KAAiB,QAAjB,IAA6B,CAACE,QAAlC,EAA4C;AAC1C,YAAM,IAAIpE,wBAAJ,CACH,iBAAgBkE,KAAM,KAAI,OAAOA,KAAM,kDADpC,CAAN;AAGD;;AAED,UAAMI,iBAAiB,GAAG,EAA1B;;AACA,QAAIF,QAAJ,EAAc;AACZ,YAAMG,WAAW,GAAGL,KAApB;AACA,YAAMM,QAAQ,GAAG,MAAMlD,OAAO,CAACkD,QAAR,EAAvB;AACA,YAAMC,aAAa,GAAGD,QAAQ,CAACE,aAAT,CACnB5D,GADmB,CACf,CAAC;AAAEoD,QAAAA,KAAK,EAAES;AAAT,OAAD,KAA0BA,SADX,EAEnBC,MAFmB,CAEZD,SAAS,IAAIJ,WAAW,CAACM,IAAZ,CAAiBF,SAAjB,CAFD,CAAtB;AAIAlD,MAAAA,MAAM,CAACqC,KAAP,CAAa,8BAAb,EAA6C;AAC3CvC,QAAAA,OAD2C;AAE3CgD,QAAAA,WAAW,EAAEA,WAAW,CAACpD,QAAZ,EAF8B;AAG3CsD,QAAAA;AAH2C,OAA7C;AAMAH,MAAAA,iBAAiB,CAACQ,IAAlB,CAAuB,GAAGL,aAA1B;AACD,KAdD,MAcO;AACLH,MAAAA,iBAAiB,CAACQ,IAAlB,CAAuBZ,KAAvB;AACD;;AAED,SAAK,MAAMa,CAAX,IAAgBT,iBAAhB,EAAmC;AACjC1B,MAAAA,MAAM,CAACmC,CAAD,CAAN,GAAY;AAAEZ,QAAAA;AAAF,OAAZ;AACD;;AAED,UAAM7C,OAAO,CAAC0D,uBAAR,CAAgCV,iBAAhC,CAAN;AACD,GAxCD;AA0CA;;;AACA,QAAMW,GAAG,GAAG,OAAO;AACjBzB,IAAAA,UAAU,GAAG,IADI;AAEjBR,IAAAA,kBAAkB,GAAG,IAFJ;AAGjBC,IAAAA,mBAAmB,GAAG,IAHL;AAIjBG,IAAAA,oBAAoB,GAAG,IAJN;AAKjBK,IAAAA,8BAA8B,GAAG,CALhB;AAMjBJ,IAAAA,SAAS,GAAG,IANK;AAOjBC,IAAAA,WAAW,GAAG;AAPG,MAQf,EARQ,KAQD;AACT,QAAIR,aAAJ,EAAmB;AACjBrB,MAAAA,MAAM,CAACyD,IAAP,CAAY,8DAAZ,EAA4E;AAAE3D,QAAAA;AAAF,OAA5E;AACA;AACD;;AAEDuB,IAAAA,aAAa,GAAGC,mBAAmB,CAAC;AAClCC,MAAAA,kBADkC;AAElCC,MAAAA;AAFkC,KAAD,CAAnC;;AAKA,UAAMkC,KAAK,GAAG,MAAM5B,OAAN,IAAiB;AAC7B9B,MAAAA,MAAM,CAACuC,IAAP,CAAY,UAAZ,EAAwB;AAAEzC,QAAAA;AAAF,OAAxB;AACAsB,MAAAA,MAAM,GAAGM,YAAY,CAAC;AACpBK,QAAAA,UADoB;AAEpBJ,QAAAA,oBAFoB;AAGpBC,QAAAA,SAHoB;AAIpBC,QAAAA,WAJoB;AAKpBC,QAAAA,OALoB;AAMpBE,QAAAA;AANoB,OAAD,CAArB;AASA,YAAMZ,MAAM,CAACsC,KAAP,EAAN;AACD,KAZD;;AAcA,UAAMC,OAAO,GAAG7B,OAAO,IAAI;AACzBT,MAAAA,aAAa,GAAGC,mBAAmB,CAAC;AAClCC,QAAAA,kBADkC;AAElCC,QAAAA;AAFkC,OAAD,CAAnC;AAKAkC,MAAAA,KAAK,CAAC5B,OAAD,CAAL;AACD,KAPD;;AASA,UAAMA,OAAO,GAAG,MAAMQ,CAAN,IAAW;AACzBtC,MAAAA,MAAM,CAAC4D,KAAP,CAAc,UAAStB,CAAC,CAACuB,IAAK,KAAIvB,CAAC,CAACwB,OAAQ,EAA5C,EAA+C;AAC7ChE,QAAAA,OAD6C;AAE7CiE,QAAAA,UAAU,EAAEzB,CAAC,CAACyB,UAF+B;AAG7CC,QAAAA,KAAK,EAAE1B,CAAC,CAAC0B;AAHoC,OAA/C;;AAMA,UAAI1B,CAAC,CAACuB,IAAF,KAAW,8BAAf,EAA+C;AAC7ChE,QAAAA,OAAO,CAACoE,YAAR,CAAqB;AAAEC,UAAAA,IAAI,EAAE5B,CAAC,CAAC4B,IAAV;AAAgBC,UAAAA,IAAI,EAAE7B,CAAC,CAAC6B;AAAxB,SAArB;AACD;;AAED,YAAMhC,UAAU,EAAhB;AAEA,YAAMiC,gBAAgB,GAAG9B,CAAC,CAACuB,IAAF,KAAW,gCAAX,IAA+CvB,CAAC,CAAC+B,SAAF,KAAgB,IAAxF;AACA,YAAMC,aAAa,GACjBF,gBAAgB,KACf,CAACrE,KAAD,IACC,CAACA,KAAK,CAACwE,gBADR,KAEE,MAAMxE,KAAK,CAACwE,gBAAN,CAAuBjC,CAAvB,EAA0BkC,KAA1B,CAAgCZ,KAAK,IAAI;AAC9C5D,QAAAA,MAAM,CAAC4D,KAAP,CACE,iGADF,EAEE;AACEA,UAAAA,KAAK,EAAEA,KAAK,CAACE,OAAN,IAAiBF,KAD1B;AAEEa,UAAAA,aAAa,EAAEnC,CAAC,CAACwB,OAAF,IAAaxB,CAF9B;AAGExC,UAAAA;AAHF,SAFF;AASA,eAAO,IAAP;AACD,OAXM,CAFR,CADe,CADlB;AAiBAe,MAAAA,sBAAsB,CAACqB,IAAvB,CAA4BhD,KAA5B,EAAmC;AACjC0E,QAAAA,KAAK,EAAEtB,CAD0B;AAEjCxC,QAAAA,OAFiC;AAGjC6D,QAAAA,OAAO,EAAEW;AAHwB,OAAnC;;AAMA,UAAIA,aAAJ,EAAmB;AACjB,cAAMI,SAAS,GAAGpC,CAAC,CAACoC,SAAF,IAAgB3E,KAAK,IAAIA,KAAK,CAACjC,gBAA/B,IAAoDA,gBAAtE;AACAkC,QAAAA,MAAM,CAAC4D,KAAP,CAAc,8BAA6Bc,SAAU,IAArD,EAA0D;AACxDX,UAAAA,UAAU,EAAEzB,CAAC,CAACyB,UAD0C;AAExDW,UAAAA,SAFwD;AAGxD5E,UAAAA;AAHwD,SAA1D;AAMA6E,QAAAA,UAAU,CAAC,MAAMhB,OAAO,CAAC7B,OAAD,CAAd,EAAyB4C,SAAzB,CAAV;AACD;AACF,KA/CD;;AAiDA,UAAMhB,KAAK,CAAC5B,OAAD,CAAX;AACD,GA5FD;AA8FA;;;AACA,QAAM8C,EAAE,GAAG,CAACC,SAAD,EAAYC,QAAZ,KAAyB;AAClC,QAAI,CAAC3F,UAAU,CAAC4F,QAAX,CAAoBF,SAApB,CAAL,EAAqC;AACnC,YAAM,IAAItG,wBAAJ,CAA8B,+BAA8Ba,SAAU,EAAtE,CAAN;AACD;;AAED,WAAOyB,sBAAsB,CAACmE,WAAvB,CAAmC3G,WAAW,CAACwG,SAAD,CAA9C,EAA2DI,KAAK,IAAI;AACzEA,MAAAA,KAAK,CAACC,IAAN,GAAa/G,SAAS,CAAC8G,KAAK,CAACC,IAAP,CAAtB;AACAC,MAAAA,OAAO,CAACC,OAAR,CAAgBN,QAAQ,CAACG,KAAD,CAAxB,EAAiCT,KAAjC,CAAuClC,CAAC,IAAI;AAC1CtC,QAAAA,MAAM,CAAC4D,KAAP,CAAc,+BAA8BtB,CAAC,CAACwB,OAAQ,EAAtD,EAAyD;AACvDe,UAAAA,SADuD;AAEvDb,UAAAA,KAAK,EAAE1B,CAAC,CAAC0B;AAF8C,SAAzD;AAID,OALD;AAMD,KARM,CAAP;AASD,GAdD;AAgBA;AACF;AACA;AACA;AACA;;;AACE,QAAMqB,aAAa,GAAG,OAAOC,eAAe,GAAG,EAAzB,KAAgC;AACpD,UAAMC,cAAc,GAAGD,eAAe,CAACE,MAAhB,CACrB,CAACC,OAAD,EAAU;AAAEhD,MAAAA,KAAF;AAASiD,MAAAA,SAAT;AAAoBC,MAAAA,MAApB;AAA4B5C,MAAAA,QAAQ,GAAG;AAAvC,KAAV,KAA4D;AAC1D,UAAI,CAACN,KAAL,EAAY;AACV,cAAM,IAAIlE,wBAAJ,CAA8B,iBAAgBkE,KAAM,EAApD,CAAN;AACD;;AAED,UAAImD,KAAK,CAACF,SAAD,CAAT,EAAsB;AACpB,cAAM,IAAInH,wBAAJ,CACH,iDAAgDmH,SAAU,EADvD,CAAN;AAGD;;AAED,UAAIG,YAAJ;;AACA,UAAI;AACFA,QAAAA,YAAY,GAAGlI,IAAI,CAAC8B,SAAL,CAAekG,MAAf,CAAf;AACD,OAFD,CAEE,OAAOG,CAAP,EAAU;AACV,cAAM,IAAIvH,wBAAJ,CAA8B,4CAA2CoH,MAAO,EAAhF,CAAN;AACD;;AAED,UAAIE,YAAY,CAACE,QAAb,CAAsB,CAAtB,CAAJ,EAA8B;AAC5B,cAAM,IAAIxH,wBAAJ,CAA6B,sCAA7B,CAAN;AACD;;AAED,UAAIwE,QAAQ,KAAK,IAAb,IAAqB,OAAOA,QAAP,KAAoB,QAA7C,EAAuD;AACrD,cAAM,IAAIxE,wBAAJ,CACH,8DAA6DwE,QAAS,EADnE,CAAN;AAGD;;AAED,YAAMiD,YAAY,GAAGP,OAAO,CAAChD,KAAD,CAAP,IAAkB,EAAvC;AAEAuD,MAAAA,YAAY,CAAC3C,IAAb,CAAkB;AAAEqC,QAAAA,SAAF;AAAaC,QAAAA,MAAM,EAAEE,YAArB;AAAmC9C,QAAAA;AAAnC,OAAlB;AAEA,aAAO,EAAE,GAAG0C,OAAL;AAAc,SAAChD,KAAD,GAASuD;AAAvB,OAAP;AACD,KAlCoB,EAmCrB,EAnCqB,CAAvB;;AAsCA,QAAI,CAAC3E,aAAL,EAAoB;AAClB,YAAM,IAAI9C,wBAAJ,CACJ,uEADI,CAAN;AAGD;;AAED,UAAM4C,MAAM,GAAGrC,MAAM,CAACF,IAAP,CAAY2G,cAAZ,CAAf;AAEA,WAAOnE,MAAM,CAACiE,aAAP,CAAqB;AAC1BlE,MAAAA,MAAM,EAAEA,MAAM,CAAC9B,GAAP,CAAWoD,KAAK,IAAI;AAC1B,eAAO;AACLA,UAAAA,KADK;AAELwD,UAAAA,UAAU,EAAEV,cAAc,CAAC9C,KAAD;AAFrB,SAAP;AAID,OALO;AADkB,KAArB,CAAP;AAQD,GAvDD;AAyDA;;;AACA,QAAMyD,IAAI,GAAG,CAAC;AAAEzD,IAAAA,KAAF;AAASiD,IAAAA,SAAT;AAAoBC,IAAAA;AAApB,GAAD,KAAkC;AAC7C,QAAI,CAAClD,KAAL,EAAY;AACV,YAAM,IAAIlE,wBAAJ,CAA8B,iBAAgBkE,KAAM,EAApD,CAAN;AACD;;AAED,QAAImD,KAAK,CAACF,SAAD,CAAT,EAAsB;AACpB,YAAM,IAAInH,wBAAJ,CACH,iDAAgDmH,SAAU,EADvD,CAAN;AAGD;;AAED,QAAIS,UAAJ;;AACA,QAAI;AACFA,MAAAA,UAAU,GAAGxI,IAAI,CAAC8B,SAAL,CAAekG,MAAf,CAAb;AACD,KAFD,CAEE,OAAOG,CAAP,EAAU;AACV,YAAM,IAAIvH,wBAAJ,CAA8B,4CAA2CoH,MAAO,EAAhF,CAAN;AACD;;AAED,QAAIQ,UAAU,CAACJ,QAAX,CAAoB,CAApB,KAA0B,CAACvG,cAAc,CAACuF,QAAf,CAAwBoB,UAAU,CAACzG,QAAX,EAAxB,CAA/B,EAA+E;AAC7E,YAAM,IAAInB,wBAAJ,CAA6B,sCAA7B,CAAN;AACD;;AAED,QAAI,CAAC8C,aAAL,EAAoB;AAClB,YAAM,IAAI9C,wBAAJ,CACJ,uEADI,CAAN;AAGD;;AAED8C,IAAAA,aAAa,CAAC6E,IAAd,CAAmB;AAAEzD,MAAAA,KAAF;AAASiD,MAAAA,SAAT;AAAoBC,MAAAA,MAAM,EAAEQ,UAAU,CAACzG,QAAX;AAA5B,KAAnB;AACD,GA7BD;AA+BA;;;AACA,QAAM0G,aAAa,GAAG,YAAY;AAChC,UAAMC,WAAW,GAAG,MAAMxG,OAAO,CAACyG,oBAAR,CAA6B;AAAExG,MAAAA;AAAF,KAA7B,CAA1B;AACA,UAAMyG,OAAO,GAAG1I,WAAW,CAACkC,KAAD,CAA3B;AACA,WAAOwG,OAAO,CAAC,YAAY;AACzB,YAAM;AAAEC,QAAAA;AAAF,UAAa,MAAMH,WAAW,CAACI,cAAZ,CAA2B;AAAEC,QAAAA,QAAQ,EAAE,CAAC5G,OAAD;AAAZ,OAA3B,CAAzB;AACA,aAAO0G,MAAM,CAACG,IAAP,CAAYC,KAAK,IAAIA,KAAK,CAAC9G,OAAN,KAAkBA,OAAvC,CAAP;AACD,KAHa,CAAd;AAID,GAPD;AASA;AACF;AACA;AACA;AACA;;;AACE,QAAM+G,KAAK,GAAG,CAACvB,eAAe,GAAG,EAAnB,KAA0B;AACtC,SAAK,MAAMwB,cAAX,IAA6BxB,eAA7B,EAA8C;AAC5C,UAAI,CAACwB,cAAD,IAAmB,CAACA,cAAc,CAACrE,KAAvC,EAA8C;AAC5C,cAAM,IAAIlE,wBAAJ,CACH,iBAAiBuI,cAAc,IAAIA,cAAc,CAACrE,KAAlC,IAA4CqE,cAAe,EADxE,CAAN;AAGD,OAJD,MAIO,IACL,OAAOA,cAAc,CAACb,UAAtB,KAAqC,WAArC,KACC,CAACc,KAAK,CAACC,OAAN,CAAcF,cAAc,CAACb,UAA7B,CAAD,IAA6Ca,cAAc,CAACb,UAAf,CAA0BgB,IAA1B,CAA+BrB,KAA/B,CAD9C,CADK,EAGL;AACA,cAAM,IAAIrH,wBAAJ,CACH,8EAA6EuI,cAAc,CAACb,UAAW,EADpG,CAAN;AAGD;AACF;;AAED,QAAI,CAAC5E,aAAL,EAAoB;AAClB,YAAM,IAAI9C,wBAAJ,CACJ,uEADI,CAAN;AAGD;;AAED8C,IAAAA,aAAa,CAACwF,KAAd,CAAoBvB,eAApB;AACD,GAvBD;AAyBA;AACF;AACA;AACA;AACA;;;AACE,QAAM4B,MAAM,GAAG,MAAM;AACnB,QAAI,CAAC7F,aAAL,EAAoB;AAClB,aAAO,EAAP;AACD;;AAED,WAAOA,aAAa,CAAC6F,MAAd,EAAP;AACD,GAND;AAQA;AACF;AACA;AACA;AACA;;;AACE,QAAMC,MAAM,GAAG,CAAC7B,eAAe,GAAG,EAAnB,KAA0B;AACvC,SAAK,MAAMwB,cAAX,IAA6BxB,eAA7B,EAA8C;AAC5C,UAAI,CAACwB,cAAD,IAAmB,CAACA,cAAc,CAACrE,KAAvC,EAA8C;AAC5C,cAAM,IAAIlE,wBAAJ,CACH,iBAAiBuI,cAAc,IAAIA,cAAc,CAACrE,KAAlC,IAA4CqE,cAAe,EADxE,CAAN;AAGD,OAJD,MAIO,IACL,OAAOA,cAAc,CAACb,UAAtB,KAAqC,WAArC,KACC,CAACc,KAAK,CAACC,OAAN,CAAcF,cAAc,CAACb,UAA7B,CAAD,IAA6Ca,cAAc,CAACb,UAAf,CAA0BgB,IAA1B,CAA+BrB,KAA/B,CAD9C,CADK,EAGL;AACA,cAAM,IAAIrH,wBAAJ,CACH,+EAA8EuI,cAAc,CAACb,UAAW,EADrG,CAAN;AAGD;AACF;;AAED,QAAI,CAAC5E,aAAL,EAAoB;AAClB,YAAM,IAAI9C,wBAAJ,CACJ,uEADI,CAAN;AAGD;;AAED8C,IAAAA,aAAa,CAAC8F,MAAd,CAAqB7B,eAArB;AACD,GAvBD;AAyBA;AACF;AACA;;;AACE,QAAM8B,SAAS,GAAG,MAAMpH,MAAxB;;AAEA,SAAO;AACLiC,IAAAA,OADK;AAELE,IAAAA,UAFK;AAGLK,IAAAA,SAHK;AAILJ,IAAAA,IAJK;AAKLoB,IAAAA,GALK;AAML6B,IAAAA,aANK;AAOLa,IAAAA,IAPK;AAQLE,IAAAA,aARK;AASLS,IAAAA,KATK;AAULK,IAAAA,MAVK;AAWLC,IAAAA,MAXK;AAYLvC,IAAAA,EAZK;AAaL3G,IAAAA,MAbK;AAcL+B,IAAAA,MAAM,EAAEoH;AAdH,GAAP;AAgBD,CApdD","sourcesContent":["const Long = require('../utils/long')\nconst createRetry = require('../retry')\nconst { initialRetryTime } = require('../retry/defaults')\nconst ConsumerGroup = require('./consumerGroup')\nconst Runner = require('./runner')\nconst { events, wrap: wrapEvent, unwrap: unwrapEvent } = require('./instrumentationEvents')\nconst InstrumentationEventEmitter = require('../instrumentation/emitter')\nconst { KafkaJSNonRetriableError } = require('../errors')\nconst { roundRobin } = require('./assigners')\nconst { EARLIEST_OFFSET, LATEST_OFFSET } = require('../constants')\nconst ISOLATION_LEVEL = require('../protocol/isolationLevel')\n\nconst { keys, values } = Object\nconst { CONNECT, DISCONNECT, STOP, CRASH } = events\n\nconst eventNames = values(events)\nconst eventKeys = keys(events)\n  .map(key => `consumer.events.${key}`)\n  .join(', ')\n\nconst specialOffsets = [\n  Long.fromValue(EARLIEST_OFFSET).toString(),\n  Long.fromValue(LATEST_OFFSET).toString(),\n]\n\n/**\n * @param {Object} params\n * @param {import(\"../../types\").Cluster} params.cluster\n * @param {String} params.groupId\n * @param {import('../../types').RetryOptions} params.retry\n * @param {import('../../types').Logger} params.logger\n * @param {import('../../types').PartitionAssigner[]} [params.partitionAssigners]\n * @param {number} [params.sessionTimeout]\n * @param {number} [params.rebalanceTimeout]\n * @param {number} [params.heartbeatInterval]\n * @param {number} [params.maxBytesPerPartition]\n * @param {number} [params.minBytes]\n * @param {number} [params.maxBytes]\n * @param {number} [params.maxWaitTimeInMs]\n * @param {number} [params.isolationLevel]\n * @param {string} [params.rackId]\n * @param {import('../instrumentation/emitter')} [params.instrumentationEmitter]\n * @param {number} params.metadataMaxAge\n *\n * @returns {import(\"../../types\").Consumer}\n */\nmodule.exports = ({\n  cluster,\n  groupId,\n  retry,\n  logger: rootLogger,\n  partitionAssigners = [roundRobin],\n  sessionTimeout = 30000,\n  rebalanceTimeout = 60000,\n  heartbeatInterval = 3000,\n  maxBytesPerPartition = 1048576, // 1MB\n  minBytes = 1,\n  maxBytes = 10485760, // 10MB\n  maxWaitTimeInMs = 5000,\n  isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,\n  rackId = '',\n  instrumentationEmitter: rootInstrumentationEmitter,\n  metadataMaxAge,\n}) => {\n  if (!groupId) {\n    throw new KafkaJSNonRetriableError('Consumer groupId must be a non-empty string.')\n  }\n\n  const logger = rootLogger.namespace('Consumer')\n  const instrumentationEmitter = rootInstrumentationEmitter || new InstrumentationEventEmitter()\n  const assigners = partitionAssigners.map(createAssigner =>\n    createAssigner({ groupId, logger, cluster })\n  )\n\n  const topics = {}\n  let runner = null\n  let consumerGroup = null\n\n  if (heartbeatInterval >= sessionTimeout) {\n    throw new KafkaJSNonRetriableError(\n      `Consumer heartbeatInterval (${heartbeatInterval}) must be lower than sessionTimeout (${sessionTimeout}). It is recommended to set heartbeatInterval to approximately a third of the sessionTimeout.`\n    )\n  }\n\n  const createConsumerGroup = ({ autoCommitInterval, autoCommitThreshold }) => {\n    return new ConsumerGroup({\n      logger: rootLogger,\n      topics: keys(topics),\n      topicConfigurations: topics,\n      retry,\n      cluster,\n      groupId,\n      assigners,\n      sessionTimeout,\n      rebalanceTimeout,\n      maxBytesPerPartition,\n      minBytes,\n      maxBytes,\n      maxWaitTimeInMs,\n      instrumentationEmitter,\n      autoCommitInterval,\n      autoCommitThreshold,\n      isolationLevel,\n      rackId,\n      metadataMaxAge,\n    })\n  }\n\n  const createRunner = ({\n    eachBatchAutoResolve,\n    eachBatch,\n    eachMessage,\n    onCrash,\n    autoCommit,\n    partitionsConsumedConcurrently,\n  }) => {\n    return new Runner({\n      autoCommit,\n      logger: rootLogger,\n      consumerGroup,\n      instrumentationEmitter,\n      eachBatchAutoResolve,\n      eachBatch,\n      eachMessage,\n      heartbeatInterval,\n      retry,\n      onCrash,\n      partitionsConsumedConcurrently,\n    })\n  }\n\n  /** @type {import(\"../../types\").Consumer[\"connect\"]} */\n  const connect = async () => {\n    await cluster.connect()\n    instrumentationEmitter.emit(CONNECT)\n  }\n\n  /** @type {import(\"../../types\").Consumer[\"disconnect\"]} */\n  const disconnect = async () => {\n    try {\n      await stop()\n      logger.debug('consumer has stopped, disconnecting', { groupId })\n      await cluster.disconnect()\n      instrumentationEmitter.emit(DISCONNECT)\n    } catch (e) {}\n  }\n\n  /** @type {import(\"../../types\").Consumer[\"stop\"]} */\n  const stop = async () => {\n    try {\n      if (runner) {\n        await runner.stop()\n        runner = null\n        consumerGroup = null\n        instrumentationEmitter.emit(STOP)\n      }\n\n      logger.info('Stopped', { groupId })\n    } catch (e) {}\n  }\n\n  /** @type {import(\"../../types\").Consumer[\"subscribe\"]} */\n  const subscribe = async ({ topic, fromBeginning = false }) => {\n    if (consumerGroup) {\n      throw new KafkaJSNonRetriableError('Cannot subscribe to topic while consumer is running')\n    }\n\n    if (!topic) {\n      throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`)\n    }\n\n    const isRegExp = topic instanceof RegExp\n    if (typeof topic !== 'string' && !isRegExp) {\n      throw new KafkaJSNonRetriableError(\n        `Invalid topic ${topic} (${typeof topic}), the topic name has to be a String or a RegExp`\n      )\n    }\n\n    const topicsToSubscribe = []\n    if (isRegExp) {\n      const topicRegExp = topic\n      const metadata = await cluster.metadata()\n      const matchedTopics = metadata.topicMetadata\n        .map(({ topic: topicName }) => topicName)\n        .filter(topicName => topicRegExp.test(topicName))\n\n      logger.debug('Subscription based on RegExp', {\n        groupId,\n        topicRegExp: topicRegExp.toString(),\n        matchedTopics,\n      })\n\n      topicsToSubscribe.push(...matchedTopics)\n    } else {\n      topicsToSubscribe.push(topic)\n    }\n\n    for (const t of topicsToSubscribe) {\n      topics[t] = { fromBeginning }\n    }\n\n    await cluster.addMultipleTargetTopics(topicsToSubscribe)\n  }\n\n  /** @type {import(\"../../types\").Consumer[\"run\"]} */\n  const run = async ({\n    autoCommit = true,\n    autoCommitInterval = null,\n    autoCommitThreshold = null,\n    eachBatchAutoResolve = true,\n    partitionsConsumedConcurrently = 1,\n    eachBatch = null,\n    eachMessage = null,\n  } = {}) => {\n    if (consumerGroup) {\n      logger.warn('consumer#run was called, but the consumer is already running', { groupId })\n      return\n    }\n\n    consumerGroup = createConsumerGroup({\n      autoCommitInterval,\n      autoCommitThreshold,\n    })\n\n    const start = async onCrash => {\n      logger.info('Starting', { groupId })\n      runner = createRunner({\n        autoCommit,\n        eachBatchAutoResolve,\n        eachBatch,\n        eachMessage,\n        onCrash,\n        partitionsConsumedConcurrently,\n      })\n\n      await runner.start()\n    }\n\n    const restart = onCrash => {\n      consumerGroup = createConsumerGroup({\n        autoCommitInterval,\n        autoCommitThreshold,\n      })\n\n      start(onCrash)\n    }\n\n    const onCrash = async e => {\n      logger.error(`Crash: ${e.name}: ${e.message}`, {\n        groupId,\n        retryCount: e.retryCount,\n        stack: e.stack,\n      })\n\n      if (e.name === 'KafkaJSConnectionClosedError') {\n        cluster.removeBroker({ host: e.host, port: e.port })\n      }\n\n      await disconnect()\n\n      const isErrorRetriable = e.name === 'KafkaJSNumberOfRetriesExceeded' || e.retriable === true\n      const shouldRestart =\n        isErrorRetriable &&\n        (!retry ||\n          !retry.restartOnFailure ||\n          (await retry.restartOnFailure(e).catch(error => {\n            logger.error(\n              'Caught error when invoking user-provided \"restartOnFailure\" callback. Defaulting to restarting.',\n              {\n                error: error.message || error,\n                originalError: e.message || e,\n                groupId,\n              }\n            )\n\n            return true\n          })))\n\n      instrumentationEmitter.emit(CRASH, {\n        error: e,\n        groupId,\n        restart: shouldRestart,\n      })\n\n      if (shouldRestart) {\n        const retryTime = e.retryTime || (retry && retry.initialRetryTime) || initialRetryTime\n        logger.error(`Restarting the consumer in ${retryTime}ms`, {\n          retryCount: e.retryCount,\n          retryTime,\n          groupId,\n        })\n\n        setTimeout(() => restart(onCrash), retryTime)\n      }\n    }\n\n    await start(onCrash)\n  }\n\n  /** @type {import(\"../../types\").Consumer[\"on\"]} */\n  const on = (eventName, listener) => {\n    if (!eventNames.includes(eventName)) {\n      throw new KafkaJSNonRetriableError(`Event name should be one of ${eventKeys}`)\n    }\n\n    return instrumentationEmitter.addListener(unwrapEvent(eventName), event => {\n      event.type = wrapEvent(event.type)\n      Promise.resolve(listener(event)).catch(e => {\n        logger.error(`Failed to execute listener: ${e.message}`, {\n          eventName,\n          stack: e.stack,\n        })\n      })\n    })\n  }\n\n  /**\n   * @type {import(\"../../types\").Consumer[\"commitOffsets\"]}\n   * @param topicPartitions\n   *   Example: [{ topic: 'topic-name', partition: 0, offset: '1', metadata: 'event-id-3' }]\n   */\n  const commitOffsets = async (topicPartitions = []) => {\n    const commitsByTopic = topicPartitions.reduce(\n      (payload, { topic, partition, offset, metadata = null }) => {\n        if (!topic) {\n          throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`)\n        }\n\n        if (isNaN(partition)) {\n          throw new KafkaJSNonRetriableError(\n            `Invalid partition, expected a number received ${partition}`\n          )\n        }\n\n        let commitOffset\n        try {\n          commitOffset = Long.fromValue(offset)\n        } catch (_) {\n          throw new KafkaJSNonRetriableError(`Invalid offset, expected a long received ${offset}`)\n        }\n\n        if (commitOffset.lessThan(0)) {\n          throw new KafkaJSNonRetriableError('Offset must not be a negative number')\n        }\n\n        if (metadata !== null && typeof metadata !== 'string') {\n          throw new KafkaJSNonRetriableError(\n            `Invalid offset metadata, expected string or null, received ${metadata}`\n          )\n        }\n\n        const topicCommits = payload[topic] || []\n\n        topicCommits.push({ partition, offset: commitOffset, metadata })\n\n        return { ...payload, [topic]: topicCommits }\n      },\n      {}\n    )\n\n    if (!consumerGroup) {\n      throw new KafkaJSNonRetriableError(\n        'Consumer group was not initialized, consumer#run must be called first'\n      )\n    }\n\n    const topics = Object.keys(commitsByTopic)\n\n    return runner.commitOffsets({\n      topics: topics.map(topic => {\n        return {\n          topic,\n          partitions: commitsByTopic[topic],\n        }\n      }),\n    })\n  }\n\n  /** @type {import(\"../../types\").Consumer[\"seek\"]} */\n  const seek = ({ topic, partition, offset }) => {\n    if (!topic) {\n      throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`)\n    }\n\n    if (isNaN(partition)) {\n      throw new KafkaJSNonRetriableError(\n        `Invalid partition, expected a number received ${partition}`\n      )\n    }\n\n    let seekOffset\n    try {\n      seekOffset = Long.fromValue(offset)\n    } catch (_) {\n      throw new KafkaJSNonRetriableError(`Invalid offset, expected a long received ${offset}`)\n    }\n\n    if (seekOffset.lessThan(0) && !specialOffsets.includes(seekOffset.toString())) {\n      throw new KafkaJSNonRetriableError('Offset must not be a negative number')\n    }\n\n    if (!consumerGroup) {\n      throw new KafkaJSNonRetriableError(\n        'Consumer group was not initialized, consumer#run must be called first'\n      )\n    }\n\n    consumerGroup.seek({ topic, partition, offset: seekOffset.toString() })\n  }\n\n  /** @type {import(\"../../types\").Consumer[\"describeGroup\"]} */\n  const describeGroup = async () => {\n    const coordinator = await cluster.findGroupCoordinator({ groupId })\n    const retrier = createRetry(retry)\n    return retrier(async () => {\n      const { groups } = await coordinator.describeGroups({ groupIds: [groupId] })\n      return groups.find(group => group.groupId === groupId)\n    })\n  }\n\n  /**\n   * @type {import(\"../../types\").Consumer[\"pause\"]}\n   * @param topicPartitions\n   *   Example: [{ topic: 'topic-name', partitions: [1, 2] }]\n   */\n  const pause = (topicPartitions = []) => {\n    for (const topicPartition of topicPartitions) {\n      if (!topicPartition || !topicPartition.topic) {\n        throw new KafkaJSNonRetriableError(\n          `Invalid topic ${(topicPartition && topicPartition.topic) || topicPartition}`\n        )\n      } else if (\n        typeof topicPartition.partitions !== 'undefined' &&\n        (!Array.isArray(topicPartition.partitions) || topicPartition.partitions.some(isNaN))\n      ) {\n        throw new KafkaJSNonRetriableError(\n          `Array of valid partitions required to pause specific partitions instead of ${topicPartition.partitions}`\n        )\n      }\n    }\n\n    if (!consumerGroup) {\n      throw new KafkaJSNonRetriableError(\n        'Consumer group was not initialized, consumer#run must be called first'\n      )\n    }\n\n    consumerGroup.pause(topicPartitions)\n  }\n\n  /**\n   * Returns the list of topic partitions paused on this consumer\n   *\n   * @type {import(\"../../types\").Consumer[\"paused\"]}\n   */\n  const paused = () => {\n    if (!consumerGroup) {\n      return []\n    }\n\n    return consumerGroup.paused()\n  }\n\n  /**\n   * @type {import(\"../../types\").Consumer[\"resume\"]}\n   * @param topicPartitions\n   *  Example: [{ topic: 'topic-name', partitions: [1, 2] }]\n   */\n  const resume = (topicPartitions = []) => {\n    for (const topicPartition of topicPartitions) {\n      if (!topicPartition || !topicPartition.topic) {\n        throw new KafkaJSNonRetriableError(\n          `Invalid topic ${(topicPartition && topicPartition.topic) || topicPartition}`\n        )\n      } else if (\n        typeof topicPartition.partitions !== 'undefined' &&\n        (!Array.isArray(topicPartition.partitions) || topicPartition.partitions.some(isNaN))\n      ) {\n        throw new KafkaJSNonRetriableError(\n          `Array of valid partitions required to resume specific partitions instead of ${topicPartition.partitions}`\n        )\n      }\n    }\n\n    if (!consumerGroup) {\n      throw new KafkaJSNonRetriableError(\n        'Consumer group was not initialized, consumer#run must be called first'\n      )\n    }\n\n    consumerGroup.resume(topicPartitions)\n  }\n\n  /**\n   * @return {Object} logger\n   */\n  const getLogger = () => logger\n\n  return {\n    connect,\n    disconnect,\n    subscribe,\n    stop,\n    run,\n    commitOffsets,\n    seek,\n    describeGroup,\n    pause,\n    paused,\n    resume,\n    on,\n    events,\n    logger: getLogger,\n  }\n}\n"]},"metadata":{},"sourceType":"script"}