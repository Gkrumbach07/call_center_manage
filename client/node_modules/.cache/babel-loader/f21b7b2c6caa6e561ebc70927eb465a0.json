{"ast":null,"code":"const Decoder = require('../../../decoder');\n\nconst {\n  failure,\n  createErrorFromCode\n} = require('../../../error');\n\nconst flatten = require('../../../../utils/flatten');\n/**\n * Metadata Response (Version: 0) => [brokers] [topic_metadata]\n *   brokers => node_id host port\n *     node_id => INT32\n *     host => STRING\n *     port => INT32\n *   topic_metadata => topic_error_code topic [partition_metadata]\n *     topic_error_code => INT16\n *     topic => STRING\n *     partition_metadata => partition_error_code partition_id leader [replicas] [isr]\n *       partition_error_code => INT16\n *       partition_id => INT32\n *       leader => INT32\n *       replicas => INT32\n *       isr => INT32\n */\n\n\nconst broker = decoder => ({\n  nodeId: decoder.readInt32(),\n  host: decoder.readString(),\n  port: decoder.readInt32()\n});\n\nconst topicMetadata = decoder => ({\n  topicErrorCode: decoder.readInt16(),\n  topic: decoder.readString(),\n  partitionMetadata: decoder.readArray(partitionMetadata)\n});\n\nconst partitionMetadata = decoder => ({\n  partitionErrorCode: decoder.readInt16(),\n  partitionId: decoder.readInt32(),\n  // leader: The node id for the kafka broker currently acting as leader\n  // for this partition\n  leader: decoder.readInt32(),\n  replicas: decoder.readArray(d => d.readInt32()),\n  isr: decoder.readArray(d => d.readInt32())\n});\n\nconst decode = async rawData => {\n  const decoder = new Decoder(rawData);\n  return {\n    brokers: decoder.readArray(broker),\n    topicMetadata: decoder.readArray(topicMetadata)\n  };\n};\n\nconst parse = async data => {\n  const topicsWithErrors = data.topicMetadata.filter(topic => failure(topic.topicErrorCode));\n\n  if (topicsWithErrors.length > 0) {\n    const {\n      topicErrorCode\n    } = topicsWithErrors[0];\n    throw createErrorFromCode(topicErrorCode);\n  }\n\n  const partitionsWithErrors = data.topicMetadata.map(topic => {\n    return topic.partitionMetadata.filter(partition => failure(partition.partitionErrorCode));\n  });\n  const errors = flatten(partitionsWithErrors);\n\n  if (errors.length > 0) {\n    const {\n      partitionErrorCode\n    } = errors[0];\n    throw createErrorFromCode(partitionErrorCode);\n  }\n\n  return data;\n};\n\nmodule.exports = {\n  decode,\n  parse\n};","map":{"version":3,"sources":["/Users/gagekrumbach/Documents/call-center-manage/node_modules/kafkajs/src/protocol/requests/metadata/v0/response.js"],"names":["Decoder","require","failure","createErrorFromCode","flatten","broker","decoder","nodeId","readInt32","host","readString","port","topicMetadata","topicErrorCode","readInt16","topic","partitionMetadata","readArray","partitionErrorCode","partitionId","leader","replicas","d","isr","decode","rawData","brokers","parse","data","topicsWithErrors","filter","length","partitionsWithErrors","map","partition","errors","module","exports"],"mappings":"AAAA,MAAMA,OAAO,GAAGC,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAM;AAAEC,EAAAA,OAAF;AAAWC,EAAAA;AAAX,IAAmCF,OAAO,CAAC,gBAAD,CAAhD;;AACA,MAAMG,OAAO,GAAGH,OAAO,CAAC,2BAAD,CAAvB;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,MAAMI,MAAM,GAAGC,OAAO,KAAK;AACzBC,EAAAA,MAAM,EAAED,OAAO,CAACE,SAAR,EADiB;AAEzBC,EAAAA,IAAI,EAAEH,OAAO,CAACI,UAAR,EAFmB;AAGzBC,EAAAA,IAAI,EAAEL,OAAO,CAACE,SAAR;AAHmB,CAAL,CAAtB;;AAMA,MAAMI,aAAa,GAAGN,OAAO,KAAK;AAChCO,EAAAA,cAAc,EAAEP,OAAO,CAACQ,SAAR,EADgB;AAEhCC,EAAAA,KAAK,EAAET,OAAO,CAACI,UAAR,EAFyB;AAGhCM,EAAAA,iBAAiB,EAAEV,OAAO,CAACW,SAAR,CAAkBD,iBAAlB;AAHa,CAAL,CAA7B;;AAMA,MAAMA,iBAAiB,GAAGV,OAAO,KAAK;AACpCY,EAAAA,kBAAkB,EAAEZ,OAAO,CAACQ,SAAR,EADgB;AAEpCK,EAAAA,WAAW,EAAEb,OAAO,CAACE,SAAR,EAFuB;AAGpC;AACA;AACAY,EAAAA,MAAM,EAAEd,OAAO,CAACE,SAAR,EAL4B;AAMpCa,EAAAA,QAAQ,EAAEf,OAAO,CAACW,SAAR,CAAkBK,CAAC,IAAIA,CAAC,CAACd,SAAF,EAAvB,CAN0B;AAOpCe,EAAAA,GAAG,EAAEjB,OAAO,CAACW,SAAR,CAAkBK,CAAC,IAAIA,CAAC,CAACd,SAAF,EAAvB;AAP+B,CAAL,CAAjC;;AAUA,MAAMgB,MAAM,GAAG,MAAMC,OAAN,IAAiB;AAC9B,QAAMnB,OAAO,GAAG,IAAIN,OAAJ,CAAYyB,OAAZ,CAAhB;AACA,SAAO;AACLC,IAAAA,OAAO,EAAEpB,OAAO,CAACW,SAAR,CAAkBZ,MAAlB,CADJ;AAELO,IAAAA,aAAa,EAAEN,OAAO,CAACW,SAAR,CAAkBL,aAAlB;AAFV,GAAP;AAID,CAND;;AAQA,MAAMe,KAAK,GAAG,MAAMC,IAAN,IAAc;AAC1B,QAAMC,gBAAgB,GAAGD,IAAI,CAAChB,aAAL,CAAmBkB,MAAnB,CAA0Bf,KAAK,IAAIb,OAAO,CAACa,KAAK,CAACF,cAAP,CAA1C,CAAzB;;AACA,MAAIgB,gBAAgB,CAACE,MAAjB,GAA0B,CAA9B,EAAiC;AAC/B,UAAM;AAAElB,MAAAA;AAAF,QAAqBgB,gBAAgB,CAAC,CAAD,CAA3C;AACA,UAAM1B,mBAAmB,CAACU,cAAD,CAAzB;AACD;;AAED,QAAMmB,oBAAoB,GAAGJ,IAAI,CAAChB,aAAL,CAAmBqB,GAAnB,CAAuBlB,KAAK,IAAI;AAC3D,WAAOA,KAAK,CAACC,iBAAN,CAAwBc,MAAxB,CAA+BI,SAAS,IAAIhC,OAAO,CAACgC,SAAS,CAAChB,kBAAX,CAAnD,CAAP;AACD,GAF4B,CAA7B;AAIA,QAAMiB,MAAM,GAAG/B,OAAO,CAAC4B,oBAAD,CAAtB;;AACA,MAAIG,MAAM,CAACJ,MAAP,GAAgB,CAApB,EAAuB;AACrB,UAAM;AAAEb,MAAAA;AAAF,QAAyBiB,MAAM,CAAC,CAAD,CAArC;AACA,UAAMhC,mBAAmB,CAACe,kBAAD,CAAzB;AACD;;AAED,SAAOU,IAAP;AACD,CAlBD;;AAoBAQ,MAAM,CAACC,OAAP,GAAiB;AACfb,EAAAA,MADe;AAEfG,EAAAA;AAFe,CAAjB","sourcesContent":["const Decoder = require('../../../decoder')\nconst { failure, createErrorFromCode } = require('../../../error')\nconst flatten = require('../../../../utils/flatten')\n\n/**\n * Metadata Response (Version: 0) => [brokers] [topic_metadata]\n *   brokers => node_id host port\n *     node_id => INT32\n *     host => STRING\n *     port => INT32\n *   topic_metadata => topic_error_code topic [partition_metadata]\n *     topic_error_code => INT16\n *     topic => STRING\n *     partition_metadata => partition_error_code partition_id leader [replicas] [isr]\n *       partition_error_code => INT16\n *       partition_id => INT32\n *       leader => INT32\n *       replicas => INT32\n *       isr => INT32\n */\n\nconst broker = decoder => ({\n  nodeId: decoder.readInt32(),\n  host: decoder.readString(),\n  port: decoder.readInt32(),\n})\n\nconst topicMetadata = decoder => ({\n  topicErrorCode: decoder.readInt16(),\n  topic: decoder.readString(),\n  partitionMetadata: decoder.readArray(partitionMetadata),\n})\n\nconst partitionMetadata = decoder => ({\n  partitionErrorCode: decoder.readInt16(),\n  partitionId: decoder.readInt32(),\n  // leader: The node id for the kafka broker currently acting as leader\n  // for this partition\n  leader: decoder.readInt32(),\n  replicas: decoder.readArray(d => d.readInt32()),\n  isr: decoder.readArray(d => d.readInt32()),\n})\n\nconst decode = async rawData => {\n  const decoder = new Decoder(rawData)\n  return {\n    brokers: decoder.readArray(broker),\n    topicMetadata: decoder.readArray(topicMetadata),\n  }\n}\n\nconst parse = async data => {\n  const topicsWithErrors = data.topicMetadata.filter(topic => failure(topic.topicErrorCode))\n  if (topicsWithErrors.length > 0) {\n    const { topicErrorCode } = topicsWithErrors[0]\n    throw createErrorFromCode(topicErrorCode)\n  }\n\n  const partitionsWithErrors = data.topicMetadata.map(topic => {\n    return topic.partitionMetadata.filter(partition => failure(partition.partitionErrorCode))\n  })\n\n  const errors = flatten(partitionsWithErrors)\n  if (errors.length > 0) {\n    const { partitionErrorCode } = errors[0]\n    throw createErrorFromCode(partitionErrorCode)\n  }\n\n  return data\n}\n\nmodule.exports = {\n  decode,\n  parse,\n}\n"]},"metadata":{},"sourceType":"script"}