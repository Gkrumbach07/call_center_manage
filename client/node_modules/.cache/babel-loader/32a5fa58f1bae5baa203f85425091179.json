{"ast":null,"code":"const EventEmitter = require('events');\n\nconst Long = require('../utils/long');\n\nconst createRetry = require('../retry');\n\nconst limitConcurrency = require('../utils/concurrency');\n\nconst {\n  KafkaJSError\n} = require('../errors');\n\nconst barrier = require('./barrier');\n\nconst {\n  events: {\n    FETCH,\n    FETCH_START,\n    START_BATCH_PROCESS,\n    END_BATCH_PROCESS\n  }\n} = require('./instrumentationEvents');\n\nconst isRebalancing = e => e.type === 'REBALANCE_IN_PROGRESS' || e.type === 'NOT_COORDINATOR_FOR_GROUP';\n\nconst isKafkaJSError = e => e instanceof KafkaJSError;\n\nconst isSameOffset = (offsetA, offsetB) => Long.fromValue(offsetA).equals(Long.fromValue(offsetB));\n\nconst CONSUMING_START = 'consuming-start';\nconst CONSUMING_STOP = 'consuming-stop';\nmodule.exports = class Runner extends EventEmitter {\n  /**\n   * @param {object} options\n   * @param {import(\"../../types\").Logger} options.logger\n   * @param {import(\"./consumerGroup\")} options.consumerGroup\n   * @param {import(\"../instrumentation/emitter\")} options.instrumentationEmitter\n   * @param {boolean} [options.eachBatchAutoResolve=true]\n   * @param {number} [options.partitionsConsumedConcurrently]\n   * @param {(payload: import(\"../../types\").EachBatchPayload) => Promise<void>} options.eachBatch\n   * @param {(payload: import(\"../../types\").EachMessagePayload) => Promise<void>} options.eachMessage\n   * @param {number} [options.heartbeatInterval]\n   * @param {(reason: Error) => void} options.onCrash\n   * @param {import(\"../../types\").RetryOptions} [options.retry]\n   * @param {boolean} [options.autoCommit=true]\n   */\n  constructor({\n    logger,\n    consumerGroup,\n    instrumentationEmitter,\n    eachBatchAutoResolve = true,\n    partitionsConsumedConcurrently,\n    eachBatch,\n    eachMessage,\n    heartbeatInterval,\n    onCrash,\n    retry,\n    autoCommit = true\n  }) {\n    super();\n    this.logger = logger.namespace('Runner');\n    this.consumerGroup = consumerGroup;\n    this.instrumentationEmitter = instrumentationEmitter;\n    this.eachBatchAutoResolve = eachBatchAutoResolve;\n    this.eachBatch = eachBatch;\n    this.eachMessage = eachMessage;\n    this.heartbeatInterval = heartbeatInterval;\n    this.retrier = createRetry(Object.assign({}, retry));\n    this.onCrash = onCrash;\n    this.autoCommit = autoCommit;\n    this.partitionsConsumedConcurrently = partitionsConsumedConcurrently;\n    this.running = false;\n    this.consuming = false;\n  }\n\n  get consuming() {\n    return this._consuming;\n  }\n\n  set consuming(value) {\n    if (this._consuming !== value) {\n      this._consuming = value;\n      this.emit(value ? CONSUMING_START : CONSUMING_STOP);\n    }\n  }\n\n  async join() {\n    await this.consumerGroup.joinAndSync();\n    this.running = true;\n  }\n\n  async scheduleJoin() {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId\n      });\n      return;\n    }\n\n    return this.join().catch(this.onCrash);\n  }\n\n  async start() {\n    if (this.running) {\n      return;\n    }\n\n    try {\n      await this.consumerGroup.connect();\n      await this.join();\n      this.running = true;\n      this.scheduleFetch();\n    } catch (e) {\n      this.onCrash(e);\n    }\n  }\n\n  async stop() {\n    if (!this.running) {\n      return;\n    }\n\n    this.logger.debug('stop consumer group', {\n      groupId: this.consumerGroup.groupId,\n      memberId: this.consumerGroup.memberId\n    });\n    this.running = false;\n\n    try {\n      await this.waitForConsumer();\n      await this.consumerGroup.leave();\n    } catch (e) {}\n  }\n\n  waitForConsumer() {\n    return new Promise(resolve => {\n      if (!this.consuming) {\n        return resolve();\n      }\n\n      this.logger.debug('waiting for consumer to finish...', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId\n      });\n      this.once(CONSUMING_STOP, () => resolve());\n    });\n  }\n\n  async processEachMessage(batch) {\n    const {\n      topic,\n      partition\n    } = batch;\n\n    for (const message of batch.messages) {\n      if (!this.running || this.consumerGroup.hasSeekOffset({\n        topic,\n        partition\n      })) {\n        break;\n      }\n\n      try {\n        await this.eachMessage({\n          topic,\n          partition,\n          message\n        });\n      } catch (e) {\n        if (!isKafkaJSError(e)) {\n          this.logger.error(`Error when calling eachMessage`, {\n            topic,\n            partition,\n            offset: message.offset,\n            stack: e.stack,\n            error: e\n          });\n        } // In case of errors, commit the previously consumed offsets unless autoCommit is disabled\n\n\n        await this.autoCommitOffsets();\n        throw e;\n      }\n\n      this.consumerGroup.resolveOffset({\n        topic,\n        partition,\n        offset: message.offset\n      });\n      await this.consumerGroup.heartbeat({\n        interval: this.heartbeatInterval\n      });\n      await this.consumerGroup.commitOffsetsIfNecessary();\n    }\n  }\n\n  async processEachBatch(batch) {\n    const {\n      topic,\n      partition\n    } = batch;\n    const lastFilteredMessage = batch.messages[batch.messages.length - 1];\n\n    try {\n      await this.eachBatch({\n        batch,\n        resolveOffset: offset => {\n          /**\n           * The transactional producer generates a control record after committing the transaction.\n           * The control record is the last record on the RecordBatch, and it is filtered before it\n           * reaches the eachBatch callback. When disabling auto-resolve, the user-land code won't\n           * be able to resolve the control record offset, since it never reaches the callback,\n           * causing stuck consumers as the consumer will never move the offset marker.\n           *\n           * When the last offset of the batch is resolved, we should automatically resolve\n           * the control record offset as this entry doesn't have any meaning to the user-land code,\n           * and won't interfere with the stream processing.\n           *\n           * @see https://github.com/apache/kafka/blob/9aa660786e46c1efbf5605a6a69136a1dac6edb9/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L1499-L1505\n           */\n          const offsetToResolve = lastFilteredMessage && isSameOffset(offset, lastFilteredMessage.offset) ? batch.lastOffset() : offset;\n          this.consumerGroup.resolveOffset({\n            topic,\n            partition,\n            offset: offsetToResolve\n          });\n        },\n        heartbeat: async () => {\n          await this.consumerGroup.heartbeat({\n            interval: this.heartbeatInterval\n          });\n        },\n\n        /**\n         * Commit offsets if provided. Otherwise commit most recent resolved offsets\n         * if the autoCommit conditions are met.\n         *\n         * @param {OffsetsByTopicPartition} [offsets] Optional.\n         */\n        commitOffsetsIfNecessary: async offsets => {\n          return offsets ? this.consumerGroup.commitOffsets(offsets) : this.consumerGroup.commitOffsetsIfNecessary();\n        },\n        uncommittedOffsets: () => this.consumerGroup.uncommittedOffsets(),\n        isRunning: () => this.running,\n        isStale: () => this.consumerGroup.hasSeekOffset({\n          topic,\n          partition\n        })\n      });\n    } catch (e) {\n      if (!isKafkaJSError(e)) {\n        this.logger.error(`Error when calling eachBatch`, {\n          topic,\n          partition,\n          offset: batch.firstOffset(),\n          stack: e.stack,\n          error: e\n        });\n      } // eachBatch has a special resolveOffset which can be used\n      // to keep track of the messages\n\n\n      await this.autoCommitOffsets();\n      throw e;\n    } // resolveOffset for the last offset can be disabled to allow the users of eachBatch to\n    // stop their consumers without resolving unprocessed offsets (issues/18)\n\n\n    if (this.eachBatchAutoResolve) {\n      this.consumerGroup.resolveOffset({\n        topic,\n        partition,\n        offset: batch.lastOffset()\n      });\n    }\n  }\n\n  async fetch() {\n    const startFetch = Date.now();\n    this.instrumentationEmitter.emit(FETCH_START, {});\n    const iterator = await this.consumerGroup.fetch();\n    this.instrumentationEmitter.emit(FETCH, {\n      /**\n       * PR #570 removed support for the number of batches in this instrumentation event;\n       * The new implementation uses an async generation to deliver the batches, which makes\n       * this number impossible to get. The number is set to 0 to keep the event backward\n       * compatible until we bump KafkaJS to version 2, following the end of node 8 LTS.\n       *\n       * @since 2019-11-29\n       */\n      numberOfBatches: 0,\n      duration: Date.now() - startFetch\n    });\n\n    const onBatch = async batch => {\n      const startBatchProcess = Date.now();\n      const payload = {\n        topic: batch.topic,\n        partition: batch.partition,\n        highWatermark: batch.highWatermark,\n        offsetLag: batch.offsetLag(),\n\n        /**\n         * @since 2019-06-24 (>= 1.8.0)\n         *\n         * offsetLag returns the lag based on the latest offset in the batch, to\n         * keep the event backward compatible we just introduced \"offsetLagLow\"\n         * which calculates the lag based on the first offset in the batch\n         */\n        offsetLagLow: batch.offsetLagLow(),\n        batchSize: batch.messages.length,\n        firstOffset: batch.firstOffset(),\n        lastOffset: batch.lastOffset()\n      };\n      this.instrumentationEmitter.emit(START_BATCH_PROCESS, payload);\n\n      if (this.eachMessage) {\n        await this.processEachMessage(batch);\n      } else if (this.eachBatch) {\n        await this.processEachBatch(batch);\n      }\n\n      this.instrumentationEmitter.emit(END_BATCH_PROCESS, { ...payload,\n        duration: Date.now() - startBatchProcess\n      });\n    };\n\n    const {\n      lock,\n      unlock,\n      unlockWithError\n    } = barrier();\n    const concurrently = limitConcurrency({\n      limit: this.partitionsConsumedConcurrently\n    });\n    let requestsCompleted = false;\n    let numberOfExecutions = 0;\n    let expectedNumberOfExecutions = 0;\n    const enqueuedTasks = [];\n\n    while (true) {\n      const result = iterator.next();\n\n      if (result.done) {\n        break;\n      }\n\n      if (!this.running) {\n        result.value.catch(error => {\n          this.logger.debug('Ignoring error in fetch request while stopping runner', {\n            error: error.message || error,\n            stack: error.stack\n          });\n        });\n        continue;\n      }\n\n      enqueuedTasks.push(async () => {\n        const batches = await result.value;\n        expectedNumberOfExecutions += batches.length;\n        batches.map(batch => concurrently(async () => {\n          try {\n            if (!this.running) {\n              return;\n            }\n\n            if (batch.isEmpty()) {\n              return;\n            }\n\n            await onBatch(batch);\n            await this.consumerGroup.heartbeat({\n              interval: this.heartbeatInterval\n            });\n          } catch (e) {\n            unlockWithError(e);\n          } finally {\n            numberOfExecutions++;\n\n            if (requestsCompleted && numberOfExecutions === expectedNumberOfExecutions) {\n              unlock();\n            }\n          }\n        }).catch(unlockWithError));\n      });\n    }\n\n    await Promise.all(enqueuedTasks.map(fn => fn()));\n    requestsCompleted = true;\n\n    if (expectedNumberOfExecutions === numberOfExecutions) {\n      unlock();\n    }\n\n    const error = await lock;\n\n    if (error) {\n      throw error;\n    }\n\n    await this.autoCommitOffsets();\n    await this.consumerGroup.heartbeat({\n      interval: this.heartbeatInterval\n    });\n  }\n\n  async scheduleFetch() {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId\n      });\n      return;\n    }\n\n    return this.retrier(async (bail, retryCount, retryTime) => {\n      try {\n        this.consuming = true;\n        await this.fetch();\n        this.consuming = false;\n\n        if (this.running) {\n          setImmediate(() => this.scheduleFetch());\n        }\n      } catch (e) {\n        if (!this.running) {\n          this.logger.debug('consumer not running, exiting', {\n            error: e.message,\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId\n          });\n          return;\n        }\n\n        if (isRebalancing(e)) {\n          this.logger.error('The group is rebalancing, re-joining', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n            retryCount,\n            retryTime\n          });\n          await this.join();\n          setImmediate(() => this.scheduleFetch());\n          return;\n        }\n\n        if (e.type === 'UNKNOWN_MEMBER_ID') {\n          this.logger.error('The coordinator is not aware of this member, re-joining the group', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n            retryCount,\n            retryTime\n          });\n          this.consumerGroup.memberId = null;\n          await this.join();\n          setImmediate(() => this.scheduleFetch());\n          return;\n        }\n\n        if (e.name === 'KafkaJSOffsetOutOfRange') {\n          setImmediate(() => this.scheduleFetch());\n          return;\n        }\n\n        if (e.name === 'KafkaJSNotImplemented') {\n          return bail(e);\n        }\n\n        this.logger.debug('Error while fetching data, trying again...', {\n          groupId: this.consumerGroup.groupId,\n          memberId: this.consumerGroup.memberId,\n          error: e.message,\n          stack: e.stack,\n          retryCount,\n          retryTime\n        });\n        throw e;\n      } finally {\n        this.consuming = false;\n      }\n    }).catch(this.onCrash);\n  }\n\n  autoCommitOffsets() {\n    if (this.autoCommit) {\n      return this.consumerGroup.commitOffsets();\n    }\n  }\n\n  autoCommitOffsetsIfNecessary() {\n    if (this.autoCommit) {\n      return this.consumerGroup.commitOffsetsIfNecessary();\n    }\n  }\n\n  commitOffsets(offsets) {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n        offsets\n      });\n      return;\n    }\n\n    return this.retrier(async (bail, retryCount, retryTime) => {\n      try {\n        await this.consumerGroup.commitOffsets(offsets);\n      } catch (e) {\n        if (!this.running) {\n          this.logger.debug('consumer not running, exiting', {\n            error: e.message,\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            offsets\n          });\n          return;\n        }\n\n        if (isRebalancing(e)) {\n          this.logger.error('The group is rebalancing, re-joining', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n            retryCount,\n            retryTime\n          });\n          setImmediate(() => this.scheduleJoin());\n          bail(new KafkaJSError(e));\n        }\n\n        if (e.type === 'UNKNOWN_MEMBER_ID') {\n          this.logger.error('The coordinator is not aware of this member, re-joining the group', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n            retryCount,\n            retryTime\n          });\n          this.consumerGroup.memberId = null;\n          setImmediate(() => this.scheduleJoin());\n          bail(new KafkaJSError(e));\n        }\n\n        if (e.name === 'KafkaJSNotImplemented') {\n          return bail(e);\n        }\n\n        this.logger.debug('Error while committing offsets, trying again...', {\n          groupId: this.consumerGroup.groupId,\n          memberId: this.consumerGroup.memberId,\n          error: e.message,\n          stack: e.stack,\n          retryCount,\n          retryTime,\n          offsets\n        });\n        throw e;\n      }\n    });\n  }\n\n};","map":{"version":3,"sources":["/Users/gagekrumbach/Documents/call-center-manage/node_modules/kafkajs/src/consumer/runner.js"],"names":["EventEmitter","require","Long","createRetry","limitConcurrency","KafkaJSError","barrier","events","FETCH","FETCH_START","START_BATCH_PROCESS","END_BATCH_PROCESS","isRebalancing","e","type","isKafkaJSError","isSameOffset","offsetA","offsetB","fromValue","equals","CONSUMING_START","CONSUMING_STOP","module","exports","Runner","constructor","logger","consumerGroup","instrumentationEmitter","eachBatchAutoResolve","partitionsConsumedConcurrently","eachBatch","eachMessage","heartbeatInterval","onCrash","retry","autoCommit","namespace","retrier","Object","assign","running","consuming","_consuming","value","emit","join","joinAndSync","scheduleJoin","debug","groupId","memberId","catch","start","connect","scheduleFetch","stop","waitForConsumer","leave","Promise","resolve","once","processEachMessage","batch","topic","partition","message","messages","hasSeekOffset","error","offset","stack","autoCommitOffsets","resolveOffset","heartbeat","interval","commitOffsetsIfNecessary","processEachBatch","lastFilteredMessage","length","offsetToResolve","lastOffset","offsets","commitOffsets","uncommittedOffsets","isRunning","isStale","firstOffset","fetch","startFetch","Date","now","iterator","numberOfBatches","duration","onBatch","startBatchProcess","payload","highWatermark","offsetLag","offsetLagLow","batchSize","lock","unlock","unlockWithError","concurrently","limit","requestsCompleted","numberOfExecutions","expectedNumberOfExecutions","enqueuedTasks","result","next","done","push","batches","map","isEmpty","all","fn","bail","retryCount","retryTime","setImmediate","name","autoCommitOffsetsIfNecessary"],"mappings":"AAAA,MAAMA,YAAY,GAAGC,OAAO,CAAC,QAAD,CAA5B;;AACA,MAAMC,IAAI,GAAGD,OAAO,CAAC,eAAD,CAApB;;AACA,MAAME,WAAW,GAAGF,OAAO,CAAC,UAAD,CAA3B;;AACA,MAAMG,gBAAgB,GAAGH,OAAO,CAAC,sBAAD,CAAhC;;AACA,MAAM;AAAEI,EAAAA;AAAF,IAAmBJ,OAAO,CAAC,WAAD,CAAhC;;AACA,MAAMK,OAAO,GAAGL,OAAO,CAAC,WAAD,CAAvB;;AAEA,MAAM;AACJM,EAAAA,MAAM,EAAE;AAAEC,IAAAA,KAAF;AAASC,IAAAA,WAAT;AAAsBC,IAAAA,mBAAtB;AAA2CC,IAAAA;AAA3C;AADJ,IAEFV,OAAO,CAAC,yBAAD,CAFX;;AAIA,MAAMW,aAAa,GAAGC,CAAC,IACrBA,CAAC,CAACC,IAAF,KAAW,uBAAX,IAAsCD,CAAC,CAACC,IAAF,KAAW,2BADnD;;AAGA,MAAMC,cAAc,GAAGF,CAAC,IAAIA,CAAC,YAAYR,YAAzC;;AACA,MAAMW,YAAY,GAAG,CAACC,OAAD,EAAUC,OAAV,KAAsBhB,IAAI,CAACiB,SAAL,CAAeF,OAAf,EAAwBG,MAAxB,CAA+BlB,IAAI,CAACiB,SAAL,CAAeD,OAAf,CAA/B,CAA3C;;AACA,MAAMG,eAAe,GAAG,iBAAxB;AACA,MAAMC,cAAc,GAAG,gBAAvB;AAEAC,MAAM,CAACC,OAAP,GAAiB,MAAMC,MAAN,SAAqBzB,YAArB,CAAkC;AACjD;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACE0B,EAAAA,WAAW,CAAC;AACVC,IAAAA,MADU;AAEVC,IAAAA,aAFU;AAGVC,IAAAA,sBAHU;AAIVC,IAAAA,oBAAoB,GAAG,IAJb;AAKVC,IAAAA,8BALU;AAMVC,IAAAA,SANU;AAOVC,IAAAA,WAPU;AAQVC,IAAAA,iBARU;AASVC,IAAAA,OATU;AAUVC,IAAAA,KAVU;AAWVC,IAAAA,UAAU,GAAG;AAXH,GAAD,EAYR;AACD;AACA,SAAKV,MAAL,GAAcA,MAAM,CAACW,SAAP,CAAiB,QAAjB,CAAd;AACA,SAAKV,aAAL,GAAqBA,aAArB;AACA,SAAKC,sBAAL,GAA8BA,sBAA9B;AACA,SAAKC,oBAAL,GAA4BA,oBAA5B;AACA,SAAKE,SAAL,GAAiBA,SAAjB;AACA,SAAKC,WAAL,GAAmBA,WAAnB;AACA,SAAKC,iBAAL,GAAyBA,iBAAzB;AACA,SAAKK,OAAL,GAAepC,WAAW,CAACqC,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBL,KAAlB,CAAD,CAA1B;AACA,SAAKD,OAAL,GAAeA,OAAf;AACA,SAAKE,UAAL,GAAkBA,UAAlB;AACA,SAAKN,8BAAL,GAAsCA,8BAAtC;AAEA,SAAKW,OAAL,GAAe,KAAf;AACA,SAAKC,SAAL,GAAiB,KAAjB;AACD;;AAED,MAAIA,SAAJ,GAAgB;AACd,WAAO,KAAKC,UAAZ;AACD;;AAED,MAAID,SAAJ,CAAcE,KAAd,EAAqB;AACnB,QAAI,KAAKD,UAAL,KAAoBC,KAAxB,EAA+B;AAC7B,WAAKD,UAAL,GAAkBC,KAAlB;AACA,WAAKC,IAAL,CAAUD,KAAK,GAAGxB,eAAH,GAAqBC,cAApC;AACD;AACF;;AAED,QAAMyB,IAAN,GAAa;AACX,UAAM,KAAKnB,aAAL,CAAmBoB,WAAnB,EAAN;AACA,SAAKN,OAAL,GAAe,IAAf;AACD;;AAED,QAAMO,YAAN,GAAqB;AACnB,QAAI,CAAC,KAAKP,OAAV,EAAmB;AACjB,WAAKf,MAAL,CAAYuB,KAAZ,CAAkB,+BAAlB,EAAmD;AACjDC,QAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADqB;AAEjDC,QAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB;AAFoB,OAAnD;AAIA;AACD;;AAED,WAAO,KAAKL,IAAL,GAAYM,KAAZ,CAAkB,KAAKlB,OAAvB,CAAP;AACD;;AAED,QAAMmB,KAAN,GAAc;AACZ,QAAI,KAAKZ,OAAT,EAAkB;AAChB;AACD;;AAED,QAAI;AACF,YAAM,KAAKd,aAAL,CAAmB2B,OAAnB,EAAN;AACA,YAAM,KAAKR,IAAL,EAAN;AAEA,WAAKL,OAAL,GAAe,IAAf;AACA,WAAKc,aAAL;AACD,KAND,CAME,OAAO3C,CAAP,EAAU;AACV,WAAKsB,OAAL,CAAatB,CAAb;AACD;AACF;;AAED,QAAM4C,IAAN,GAAa;AACX,QAAI,CAAC,KAAKf,OAAV,EAAmB;AACjB;AACD;;AAED,SAAKf,MAAL,CAAYuB,KAAZ,CAAkB,qBAAlB,EAAyC;AACvCC,MAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADW;AAEvCC,MAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB;AAFU,KAAzC;AAKA,SAAKV,OAAL,GAAe,KAAf;;AAEA,QAAI;AACF,YAAM,KAAKgB,eAAL,EAAN;AACA,YAAM,KAAK9B,aAAL,CAAmB+B,KAAnB,EAAN;AACD,KAHD,CAGE,OAAO9C,CAAP,EAAU,CAAE;AACf;;AAED6C,EAAAA,eAAe,GAAG;AAChB,WAAO,IAAIE,OAAJ,CAAYC,OAAO,IAAI;AAC5B,UAAI,CAAC,KAAKlB,SAAV,EAAqB;AACnB,eAAOkB,OAAO,EAAd;AACD;;AAED,WAAKlC,MAAL,CAAYuB,KAAZ,CAAkB,mCAAlB,EAAuD;AACrDC,QAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADyB;AAErDC,QAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB;AAFwB,OAAvD;AAKA,WAAKU,IAAL,CAAUxC,cAAV,EAA0B,MAAMuC,OAAO,EAAvC;AACD,KAXM,CAAP;AAYD;;AAED,QAAME,kBAAN,CAAyBC,KAAzB,EAAgC;AAC9B,UAAM;AAAEC,MAAAA,KAAF;AAASC,MAAAA;AAAT,QAAuBF,KAA7B;;AAEA,SAAK,MAAMG,OAAX,IAAsBH,KAAK,CAACI,QAA5B,EAAsC;AACpC,UAAI,CAAC,KAAK1B,OAAN,IAAiB,KAAKd,aAAL,CAAmByC,aAAnB,CAAiC;AAAEJ,QAAAA,KAAF;AAASC,QAAAA;AAAT,OAAjC,CAArB,EAA6E;AAC3E;AACD;;AAED,UAAI;AACF,cAAM,KAAKjC,WAAL,CAAiB;AAAEgC,UAAAA,KAAF;AAASC,UAAAA,SAAT;AAAoBC,UAAAA;AAApB,SAAjB,CAAN;AACD,OAFD,CAEE,OAAOtD,CAAP,EAAU;AACV,YAAI,CAACE,cAAc,CAACF,CAAD,CAAnB,EAAwB;AACtB,eAAKc,MAAL,CAAY2C,KAAZ,CAAmB,gCAAnB,EAAoD;AAClDL,YAAAA,KADkD;AAElDC,YAAAA,SAFkD;AAGlDK,YAAAA,MAAM,EAAEJ,OAAO,CAACI,MAHkC;AAIlDC,YAAAA,KAAK,EAAE3D,CAAC,CAAC2D,KAJyC;AAKlDF,YAAAA,KAAK,EAAEzD;AAL2C,WAApD;AAOD,SATS,CAWV;;;AACA,cAAM,KAAK4D,iBAAL,EAAN;AACA,cAAM5D,CAAN;AACD;;AAED,WAAKe,aAAL,CAAmB8C,aAAnB,CAAiC;AAAET,QAAAA,KAAF;AAASC,QAAAA,SAAT;AAAoBK,QAAAA,MAAM,EAAEJ,OAAO,CAACI;AAApC,OAAjC;AACA,YAAM,KAAK3C,aAAL,CAAmB+C,SAAnB,CAA6B;AAAEC,QAAAA,QAAQ,EAAE,KAAK1C;AAAjB,OAA7B,CAAN;AACA,YAAM,KAAKN,aAAL,CAAmBiD,wBAAnB,EAAN;AACD;AACF;;AAED,QAAMC,gBAAN,CAAuBd,KAAvB,EAA8B;AAC5B,UAAM;AAAEC,MAAAA,KAAF;AAASC,MAAAA;AAAT,QAAuBF,KAA7B;AACA,UAAMe,mBAAmB,GAAGf,KAAK,CAACI,QAAN,CAAeJ,KAAK,CAACI,QAAN,CAAeY,MAAf,GAAwB,CAAvC,CAA5B;;AAEA,QAAI;AACF,YAAM,KAAKhD,SAAL,CAAe;AACnBgC,QAAAA,KADmB;AAEnBU,QAAAA,aAAa,EAAEH,MAAM,IAAI;AACvB;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACU,gBAAMU,eAAe,GACnBF,mBAAmB,IAAI/D,YAAY,CAACuD,MAAD,EAASQ,mBAAmB,CAACR,MAA7B,CAAnC,GACIP,KAAK,CAACkB,UAAN,EADJ,GAEIX,MAHN;AAKA,eAAK3C,aAAL,CAAmB8C,aAAnB,CAAiC;AAAET,YAAAA,KAAF;AAASC,YAAAA,SAAT;AAAoBK,YAAAA,MAAM,EAAEU;AAA5B,WAAjC;AACD,SAtBkB;AAuBnBN,QAAAA,SAAS,EAAE,YAAY;AACrB,gBAAM,KAAK/C,aAAL,CAAmB+C,SAAnB,CAA6B;AAAEC,YAAAA,QAAQ,EAAE,KAAK1C;AAAjB,WAA7B,CAAN;AACD,SAzBkB;;AA0BnB;AACR;AACA;AACA;AACA;AACA;AACQ2C,QAAAA,wBAAwB,EAAE,MAAMM,OAAN,IAAiB;AACzC,iBAAOA,OAAO,GACV,KAAKvD,aAAL,CAAmBwD,aAAnB,CAAiCD,OAAjC,CADU,GAEV,KAAKvD,aAAL,CAAmBiD,wBAAnB,EAFJ;AAGD,SApCkB;AAqCnBQ,QAAAA,kBAAkB,EAAE,MAAM,KAAKzD,aAAL,CAAmByD,kBAAnB,EArCP;AAsCnBC,QAAAA,SAAS,EAAE,MAAM,KAAK5C,OAtCH;AAuCnB6C,QAAAA,OAAO,EAAE,MAAM,KAAK3D,aAAL,CAAmByC,aAAnB,CAAiC;AAAEJ,UAAAA,KAAF;AAASC,UAAAA;AAAT,SAAjC;AAvCI,OAAf,CAAN;AAyCD,KA1CD,CA0CE,OAAOrD,CAAP,EAAU;AACV,UAAI,CAACE,cAAc,CAACF,CAAD,CAAnB,EAAwB;AACtB,aAAKc,MAAL,CAAY2C,KAAZ,CAAmB,8BAAnB,EAAkD;AAChDL,UAAAA,KADgD;AAEhDC,UAAAA,SAFgD;AAGhDK,UAAAA,MAAM,EAAEP,KAAK,CAACwB,WAAN,EAHwC;AAIhDhB,UAAAA,KAAK,EAAE3D,CAAC,CAAC2D,KAJuC;AAKhDF,UAAAA,KAAK,EAAEzD;AALyC,SAAlD;AAOD,OATS,CAWV;AACA;;;AACA,YAAM,KAAK4D,iBAAL,EAAN;AACA,YAAM5D,CAAN;AACD,KA7D2B,CA+D5B;AACA;;;AACA,QAAI,KAAKiB,oBAAT,EAA+B;AAC7B,WAAKF,aAAL,CAAmB8C,aAAnB,CAAiC;AAAET,QAAAA,KAAF;AAASC,QAAAA,SAAT;AAAoBK,QAAAA,MAAM,EAAEP,KAAK,CAACkB,UAAN;AAA5B,OAAjC;AACD;AACF;;AAED,QAAMO,KAAN,GAAc;AACZ,UAAMC,UAAU,GAAGC,IAAI,CAACC,GAAL,EAAnB;AAEA,SAAK/D,sBAAL,CAA4BiB,IAA5B,CAAiCrC,WAAjC,EAA8C,EAA9C;AAEA,UAAMoF,QAAQ,GAAG,MAAM,KAAKjE,aAAL,CAAmB6D,KAAnB,EAAvB;AAEA,SAAK5D,sBAAL,CAA4BiB,IAA5B,CAAiCtC,KAAjC,EAAwC;AACtC;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACMsF,MAAAA,eAAe,EAAE,CATqB;AAUtCC,MAAAA,QAAQ,EAAEJ,IAAI,CAACC,GAAL,KAAaF;AAVe,KAAxC;;AAaA,UAAMM,OAAO,GAAG,MAAMhC,KAAN,IAAe;AAC7B,YAAMiC,iBAAiB,GAAGN,IAAI,CAACC,GAAL,EAA1B;AACA,YAAMM,OAAO,GAAG;AACdjC,QAAAA,KAAK,EAAED,KAAK,CAACC,KADC;AAEdC,QAAAA,SAAS,EAAEF,KAAK,CAACE,SAFH;AAGdiC,QAAAA,aAAa,EAAEnC,KAAK,CAACmC,aAHP;AAIdC,QAAAA,SAAS,EAAEpC,KAAK,CAACoC,SAAN,EAJG;;AAKd;AACR;AACA;AACA;AACA;AACA;AACA;AACQC,QAAAA,YAAY,EAAErC,KAAK,CAACqC,YAAN,EAZA;AAadC,QAAAA,SAAS,EAAEtC,KAAK,CAACI,QAAN,CAAeY,MAbZ;AAcdQ,QAAAA,WAAW,EAAExB,KAAK,CAACwB,WAAN,EAdC;AAedN,QAAAA,UAAU,EAAElB,KAAK,CAACkB,UAAN;AAfE,OAAhB;AAkBA,WAAKrD,sBAAL,CAA4BiB,IAA5B,CAAiCpC,mBAAjC,EAAsDwF,OAAtD;;AAEA,UAAI,KAAKjE,WAAT,EAAsB;AACpB,cAAM,KAAK8B,kBAAL,CAAwBC,KAAxB,CAAN;AACD,OAFD,MAEO,IAAI,KAAKhC,SAAT,EAAoB;AACzB,cAAM,KAAK8C,gBAAL,CAAsBd,KAAtB,CAAN;AACD;;AAED,WAAKnC,sBAAL,CAA4BiB,IAA5B,CAAiCnC,iBAAjC,EAAoD,EAClD,GAAGuF,OAD+C;AAElDH,QAAAA,QAAQ,EAAEJ,IAAI,CAACC,GAAL,KAAaK;AAF2B,OAApD;AAID,KAhCD;;AAkCA,UAAM;AAAEM,MAAAA,IAAF;AAAQC,MAAAA,MAAR;AAAgBC,MAAAA;AAAhB,QAAoCnG,OAAO,EAAjD;AACA,UAAMoG,YAAY,GAAGtG,gBAAgB,CAAC;AAAEuG,MAAAA,KAAK,EAAE,KAAK5E;AAAd,KAAD,CAArC;AAEA,QAAI6E,iBAAiB,GAAG,KAAxB;AACA,QAAIC,kBAAkB,GAAG,CAAzB;AACA,QAAIC,0BAA0B,GAAG,CAAjC;AACA,UAAMC,aAAa,GAAG,EAAtB;;AAEA,WAAO,IAAP,EAAa;AACX,YAAMC,MAAM,GAAGnB,QAAQ,CAACoB,IAAT,EAAf;;AAEA,UAAID,MAAM,CAACE,IAAX,EAAiB;AACf;AACD;;AAED,UAAI,CAAC,KAAKxE,OAAV,EAAmB;AACjBsE,QAAAA,MAAM,CAACnE,KAAP,CAAaQ,KAAb,CAAmBiB,KAAK,IAAI;AAC1B,eAAK3C,MAAL,CAAYuB,KAAZ,CAAkB,uDAAlB,EAA2E;AACzEoB,YAAAA,KAAK,EAAEA,KAAK,CAACH,OAAN,IAAiBG,KADiD;AAEzEE,YAAAA,KAAK,EAAEF,KAAK,CAACE;AAF4D,WAA3E;AAID,SALD;AAOA;AACD;;AAEDuC,MAAAA,aAAa,CAACI,IAAd,CAAmB,YAAY;AAC7B,cAAMC,OAAO,GAAG,MAAMJ,MAAM,CAACnE,KAA7B;AACAiE,QAAAA,0BAA0B,IAAIM,OAAO,CAACpC,MAAtC;AAEAoC,QAAAA,OAAO,CAACC,GAAR,CAAYrD,KAAK,IACf0C,YAAY,CAAC,YAAY;AACvB,cAAI;AACF,gBAAI,CAAC,KAAKhE,OAAV,EAAmB;AACjB;AACD;;AAED,gBAAIsB,KAAK,CAACsD,OAAN,EAAJ,EAAqB;AACnB;AACD;;AAED,kBAAMtB,OAAO,CAAChC,KAAD,CAAb;AACA,kBAAM,KAAKpC,aAAL,CAAmB+C,SAAnB,CAA6B;AAAEC,cAAAA,QAAQ,EAAE,KAAK1C;AAAjB,aAA7B,CAAN;AACD,WAXD,CAWE,OAAOrB,CAAP,EAAU;AACV4F,YAAAA,eAAe,CAAC5F,CAAD,CAAf;AACD,WAbD,SAaU;AACRgG,YAAAA,kBAAkB;;AAClB,gBAAID,iBAAiB,IAAIC,kBAAkB,KAAKC,0BAAhD,EAA4E;AAC1EN,cAAAA,MAAM;AACP;AACF;AACF,SApBW,CAAZ,CAoBGnD,KApBH,CAoBSoD,eApBT,CADF;AAuBD,OA3BD;AA4BD;;AAED,UAAM7C,OAAO,CAAC2D,GAAR,CAAYR,aAAa,CAACM,GAAd,CAAkBG,EAAE,IAAIA,EAAE,EAA1B,CAAZ,CAAN;AACAZ,IAAAA,iBAAiB,GAAG,IAApB;;AAEA,QAAIE,0BAA0B,KAAKD,kBAAnC,EAAuD;AACrDL,MAAAA,MAAM;AACP;;AAED,UAAMlC,KAAK,GAAG,MAAMiC,IAApB;;AACA,QAAIjC,KAAJ,EAAW;AACT,YAAMA,KAAN;AACD;;AAED,UAAM,KAAKG,iBAAL,EAAN;AACA,UAAM,KAAK7C,aAAL,CAAmB+C,SAAnB,CAA6B;AAAEC,MAAAA,QAAQ,EAAE,KAAK1C;AAAjB,KAA7B,CAAN;AACD;;AAED,QAAMsB,aAAN,GAAsB;AACpB,QAAI,CAAC,KAAKd,OAAV,EAAmB;AACjB,WAAKf,MAAL,CAAYuB,KAAZ,CAAkB,+BAAlB,EAAmD;AACjDC,QAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADqB;AAEjDC,QAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB;AAFoB,OAAnD;AAKA;AACD;;AAED,WAAO,KAAKb,OAAL,CAAa,OAAOkF,IAAP,EAAaC,UAAb,EAAyBC,SAAzB,KAAuC;AACzD,UAAI;AACF,aAAKhF,SAAL,GAAiB,IAAjB;AACA,cAAM,KAAK8C,KAAL,EAAN;AACA,aAAK9C,SAAL,GAAiB,KAAjB;;AAEA,YAAI,KAAKD,OAAT,EAAkB;AAChBkF,UAAAA,YAAY,CAAC,MAAM,KAAKpE,aAAL,EAAP,CAAZ;AACD;AACF,OARD,CAQE,OAAO3C,CAAP,EAAU;AACV,YAAI,CAAC,KAAK6B,OAAV,EAAmB;AACjB,eAAKf,MAAL,CAAYuB,KAAZ,CAAkB,+BAAlB,EAAmD;AACjDoB,YAAAA,KAAK,EAAEzD,CAAC,CAACsD,OADwC;AAEjDhB,YAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OAFqB;AAGjDC,YAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB;AAHoB,WAAnD;AAKA;AACD;;AAED,YAAIxC,aAAa,CAACC,CAAD,CAAjB,EAAsB;AACpB,eAAKc,MAAL,CAAY2C,KAAZ,CAAkB,sCAAlB,EAA0D;AACxDnB,YAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OAD4B;AAExDC,YAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB,QAF2B;AAGxDkB,YAAAA,KAAK,EAAEzD,CAAC,CAACsD,OAH+C;AAIxDuD,YAAAA,UAJwD;AAKxDC,YAAAA;AALwD,WAA1D;AAQA,gBAAM,KAAK5E,IAAL,EAAN;AACA6E,UAAAA,YAAY,CAAC,MAAM,KAAKpE,aAAL,EAAP,CAAZ;AACA;AACD;;AAED,YAAI3C,CAAC,CAACC,IAAF,KAAW,mBAAf,EAAoC;AAClC,eAAKa,MAAL,CAAY2C,KAAZ,CAAkB,mEAAlB,EAAuF;AACrFnB,YAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADyD;AAErFC,YAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB,QAFwD;AAGrFkB,YAAAA,KAAK,EAAEzD,CAAC,CAACsD,OAH4E;AAIrFuD,YAAAA,UAJqF;AAKrFC,YAAAA;AALqF,WAAvF;AAQA,eAAK/F,aAAL,CAAmBwB,QAAnB,GAA8B,IAA9B;AACA,gBAAM,KAAKL,IAAL,EAAN;AACA6E,UAAAA,YAAY,CAAC,MAAM,KAAKpE,aAAL,EAAP,CAAZ;AACA;AACD;;AAED,YAAI3C,CAAC,CAACgH,IAAF,KAAW,yBAAf,EAA0C;AACxCD,UAAAA,YAAY,CAAC,MAAM,KAAKpE,aAAL,EAAP,CAAZ;AACA;AACD;;AAED,YAAI3C,CAAC,CAACgH,IAAF,KAAW,uBAAf,EAAwC;AACtC,iBAAOJ,IAAI,CAAC5G,CAAD,CAAX;AACD;;AAED,aAAKc,MAAL,CAAYuB,KAAZ,CAAkB,4CAAlB,EAAgE;AAC9DC,UAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADkC;AAE9DC,UAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB,QAFiC;AAG9DkB,UAAAA,KAAK,EAAEzD,CAAC,CAACsD,OAHqD;AAI9DK,UAAAA,KAAK,EAAE3D,CAAC,CAAC2D,KAJqD;AAK9DkD,UAAAA,UAL8D;AAM9DC,UAAAA;AAN8D,SAAhE;AASA,cAAM9G,CAAN;AACD,OAlED,SAkEU;AACR,aAAK8B,SAAL,GAAiB,KAAjB;AACD;AACF,KAtEM,EAsEJU,KAtEI,CAsEE,KAAKlB,OAtEP,CAAP;AAuED;;AAEDsC,EAAAA,iBAAiB,GAAG;AAClB,QAAI,KAAKpC,UAAT,EAAqB;AACnB,aAAO,KAAKT,aAAL,CAAmBwD,aAAnB,EAAP;AACD;AACF;;AAED0C,EAAAA,4BAA4B,GAAG;AAC7B,QAAI,KAAKzF,UAAT,EAAqB;AACnB,aAAO,KAAKT,aAAL,CAAmBiD,wBAAnB,EAAP;AACD;AACF;;AAEDO,EAAAA,aAAa,CAACD,OAAD,EAAU;AACrB,QAAI,CAAC,KAAKzC,OAAV,EAAmB;AACjB,WAAKf,MAAL,CAAYuB,KAAZ,CAAkB,+BAAlB,EAAmD;AACjDC,QAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADqB;AAEjDC,QAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB,QAFoB;AAGjD+B,QAAAA;AAHiD,OAAnD;AAKA;AACD;;AAED,WAAO,KAAK5C,OAAL,CAAa,OAAOkF,IAAP,EAAaC,UAAb,EAAyBC,SAAzB,KAAuC;AACzD,UAAI;AACF,cAAM,KAAK/F,aAAL,CAAmBwD,aAAnB,CAAiCD,OAAjC,CAAN;AACD,OAFD,CAEE,OAAOtE,CAAP,EAAU;AACV,YAAI,CAAC,KAAK6B,OAAV,EAAmB;AACjB,eAAKf,MAAL,CAAYuB,KAAZ,CAAkB,+BAAlB,EAAmD;AACjDoB,YAAAA,KAAK,EAAEzD,CAAC,CAACsD,OADwC;AAEjDhB,YAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OAFqB;AAGjDC,YAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB,QAHoB;AAIjD+B,YAAAA;AAJiD,WAAnD;AAMA;AACD;;AAED,YAAIvE,aAAa,CAACC,CAAD,CAAjB,EAAsB;AACpB,eAAKc,MAAL,CAAY2C,KAAZ,CAAkB,sCAAlB,EAA0D;AACxDnB,YAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OAD4B;AAExDC,YAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB,QAF2B;AAGxDkB,YAAAA,KAAK,EAAEzD,CAAC,CAACsD,OAH+C;AAIxDuD,YAAAA,UAJwD;AAKxDC,YAAAA;AALwD,WAA1D;AAQAC,UAAAA,YAAY,CAAC,MAAM,KAAK3E,YAAL,EAAP,CAAZ;AAEAwE,UAAAA,IAAI,CAAC,IAAIpH,YAAJ,CAAiBQ,CAAjB,CAAD,CAAJ;AACD;;AAED,YAAIA,CAAC,CAACC,IAAF,KAAW,mBAAf,EAAoC;AAClC,eAAKa,MAAL,CAAY2C,KAAZ,CAAkB,mEAAlB,EAAuF;AACrFnB,YAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADyD;AAErFC,YAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB,QAFwD;AAGrFkB,YAAAA,KAAK,EAAEzD,CAAC,CAACsD,OAH4E;AAIrFuD,YAAAA,UAJqF;AAKrFC,YAAAA;AALqF,WAAvF;AAQA,eAAK/F,aAAL,CAAmBwB,QAAnB,GAA8B,IAA9B;AACAwE,UAAAA,YAAY,CAAC,MAAM,KAAK3E,YAAL,EAAP,CAAZ;AAEAwE,UAAAA,IAAI,CAAC,IAAIpH,YAAJ,CAAiBQ,CAAjB,CAAD,CAAJ;AACD;;AAED,YAAIA,CAAC,CAACgH,IAAF,KAAW,uBAAf,EAAwC;AACtC,iBAAOJ,IAAI,CAAC5G,CAAD,CAAX;AACD;;AAED,aAAKc,MAAL,CAAYuB,KAAZ,CAAkB,iDAAlB,EAAqE;AACnEC,UAAAA,OAAO,EAAE,KAAKvB,aAAL,CAAmBuB,OADuC;AAEnEC,UAAAA,QAAQ,EAAE,KAAKxB,aAAL,CAAmBwB,QAFsC;AAGnEkB,UAAAA,KAAK,EAAEzD,CAAC,CAACsD,OAH0D;AAInEK,UAAAA,KAAK,EAAE3D,CAAC,CAAC2D,KAJ0D;AAKnEkD,UAAAA,UALmE;AAMnEC,UAAAA,SANmE;AAOnExC,UAAAA;AAPmE,SAArE;AAUA,cAAMtE,CAAN;AACD;AACF,KA3DM,CAAP;AA4DD;;AAngBgD,CAAnD","sourcesContent":["const EventEmitter = require('events')\nconst Long = require('../utils/long')\nconst createRetry = require('../retry')\nconst limitConcurrency = require('../utils/concurrency')\nconst { KafkaJSError } = require('../errors')\nconst barrier = require('./barrier')\n\nconst {\n  events: { FETCH, FETCH_START, START_BATCH_PROCESS, END_BATCH_PROCESS },\n} = require('./instrumentationEvents')\n\nconst isRebalancing = e =>\n  e.type === 'REBALANCE_IN_PROGRESS' || e.type === 'NOT_COORDINATOR_FOR_GROUP'\n\nconst isKafkaJSError = e => e instanceof KafkaJSError\nconst isSameOffset = (offsetA, offsetB) => Long.fromValue(offsetA).equals(Long.fromValue(offsetB))\nconst CONSUMING_START = 'consuming-start'\nconst CONSUMING_STOP = 'consuming-stop'\n\nmodule.exports = class Runner extends EventEmitter {\n  /**\n   * @param {object} options\n   * @param {import(\"../../types\").Logger} options.logger\n   * @param {import(\"./consumerGroup\")} options.consumerGroup\n   * @param {import(\"../instrumentation/emitter\")} options.instrumentationEmitter\n   * @param {boolean} [options.eachBatchAutoResolve=true]\n   * @param {number} [options.partitionsConsumedConcurrently]\n   * @param {(payload: import(\"../../types\").EachBatchPayload) => Promise<void>} options.eachBatch\n   * @param {(payload: import(\"../../types\").EachMessagePayload) => Promise<void>} options.eachMessage\n   * @param {number} [options.heartbeatInterval]\n   * @param {(reason: Error) => void} options.onCrash\n   * @param {import(\"../../types\").RetryOptions} [options.retry]\n   * @param {boolean} [options.autoCommit=true]\n   */\n  constructor({\n    logger,\n    consumerGroup,\n    instrumentationEmitter,\n    eachBatchAutoResolve = true,\n    partitionsConsumedConcurrently,\n    eachBatch,\n    eachMessage,\n    heartbeatInterval,\n    onCrash,\n    retry,\n    autoCommit = true,\n  }) {\n    super()\n    this.logger = logger.namespace('Runner')\n    this.consumerGroup = consumerGroup\n    this.instrumentationEmitter = instrumentationEmitter\n    this.eachBatchAutoResolve = eachBatchAutoResolve\n    this.eachBatch = eachBatch\n    this.eachMessage = eachMessage\n    this.heartbeatInterval = heartbeatInterval\n    this.retrier = createRetry(Object.assign({}, retry))\n    this.onCrash = onCrash\n    this.autoCommit = autoCommit\n    this.partitionsConsumedConcurrently = partitionsConsumedConcurrently\n\n    this.running = false\n    this.consuming = false\n  }\n\n  get consuming() {\n    return this._consuming\n  }\n\n  set consuming(value) {\n    if (this._consuming !== value) {\n      this._consuming = value\n      this.emit(value ? CONSUMING_START : CONSUMING_STOP)\n    }\n  }\n\n  async join() {\n    await this.consumerGroup.joinAndSync()\n    this.running = true\n  }\n\n  async scheduleJoin() {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n      })\n      return\n    }\n\n    return this.join().catch(this.onCrash)\n  }\n\n  async start() {\n    if (this.running) {\n      return\n    }\n\n    try {\n      await this.consumerGroup.connect()\n      await this.join()\n\n      this.running = true\n      this.scheduleFetch()\n    } catch (e) {\n      this.onCrash(e)\n    }\n  }\n\n  async stop() {\n    if (!this.running) {\n      return\n    }\n\n    this.logger.debug('stop consumer group', {\n      groupId: this.consumerGroup.groupId,\n      memberId: this.consumerGroup.memberId,\n    })\n\n    this.running = false\n\n    try {\n      await this.waitForConsumer()\n      await this.consumerGroup.leave()\n    } catch (e) {}\n  }\n\n  waitForConsumer() {\n    return new Promise(resolve => {\n      if (!this.consuming) {\n        return resolve()\n      }\n\n      this.logger.debug('waiting for consumer to finish...', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n      })\n\n      this.once(CONSUMING_STOP, () => resolve())\n    })\n  }\n\n  async processEachMessage(batch) {\n    const { topic, partition } = batch\n\n    for (const message of batch.messages) {\n      if (!this.running || this.consumerGroup.hasSeekOffset({ topic, partition })) {\n        break\n      }\n\n      try {\n        await this.eachMessage({ topic, partition, message })\n      } catch (e) {\n        if (!isKafkaJSError(e)) {\n          this.logger.error(`Error when calling eachMessage`, {\n            topic,\n            partition,\n            offset: message.offset,\n            stack: e.stack,\n            error: e,\n          })\n        }\n\n        // In case of errors, commit the previously consumed offsets unless autoCommit is disabled\n        await this.autoCommitOffsets()\n        throw e\n      }\n\n      this.consumerGroup.resolveOffset({ topic, partition, offset: message.offset })\n      await this.consumerGroup.heartbeat({ interval: this.heartbeatInterval })\n      await this.consumerGroup.commitOffsetsIfNecessary()\n    }\n  }\n\n  async processEachBatch(batch) {\n    const { topic, partition } = batch\n    const lastFilteredMessage = batch.messages[batch.messages.length - 1]\n\n    try {\n      await this.eachBatch({\n        batch,\n        resolveOffset: offset => {\n          /**\n           * The transactional producer generates a control record after committing the transaction.\n           * The control record is the last record on the RecordBatch, and it is filtered before it\n           * reaches the eachBatch callback. When disabling auto-resolve, the user-land code won't\n           * be able to resolve the control record offset, since it never reaches the callback,\n           * causing stuck consumers as the consumer will never move the offset marker.\n           *\n           * When the last offset of the batch is resolved, we should automatically resolve\n           * the control record offset as this entry doesn't have any meaning to the user-land code,\n           * and won't interfere with the stream processing.\n           *\n           * @see https://github.com/apache/kafka/blob/9aa660786e46c1efbf5605a6a69136a1dac6edb9/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L1499-L1505\n           */\n          const offsetToResolve =\n            lastFilteredMessage && isSameOffset(offset, lastFilteredMessage.offset)\n              ? batch.lastOffset()\n              : offset\n\n          this.consumerGroup.resolveOffset({ topic, partition, offset: offsetToResolve })\n        },\n        heartbeat: async () => {\n          await this.consumerGroup.heartbeat({ interval: this.heartbeatInterval })\n        },\n        /**\n         * Commit offsets if provided. Otherwise commit most recent resolved offsets\n         * if the autoCommit conditions are met.\n         *\n         * @param {OffsetsByTopicPartition} [offsets] Optional.\n         */\n        commitOffsetsIfNecessary: async offsets => {\n          return offsets\n            ? this.consumerGroup.commitOffsets(offsets)\n            : this.consumerGroup.commitOffsetsIfNecessary()\n        },\n        uncommittedOffsets: () => this.consumerGroup.uncommittedOffsets(),\n        isRunning: () => this.running,\n        isStale: () => this.consumerGroup.hasSeekOffset({ topic, partition }),\n      })\n    } catch (e) {\n      if (!isKafkaJSError(e)) {\n        this.logger.error(`Error when calling eachBatch`, {\n          topic,\n          partition,\n          offset: batch.firstOffset(),\n          stack: e.stack,\n          error: e,\n        })\n      }\n\n      // eachBatch has a special resolveOffset which can be used\n      // to keep track of the messages\n      await this.autoCommitOffsets()\n      throw e\n    }\n\n    // resolveOffset for the last offset can be disabled to allow the users of eachBatch to\n    // stop their consumers without resolving unprocessed offsets (issues/18)\n    if (this.eachBatchAutoResolve) {\n      this.consumerGroup.resolveOffset({ topic, partition, offset: batch.lastOffset() })\n    }\n  }\n\n  async fetch() {\n    const startFetch = Date.now()\n\n    this.instrumentationEmitter.emit(FETCH_START, {})\n\n    const iterator = await this.consumerGroup.fetch()\n\n    this.instrumentationEmitter.emit(FETCH, {\n      /**\n       * PR #570 removed support for the number of batches in this instrumentation event;\n       * The new implementation uses an async generation to deliver the batches, which makes\n       * this number impossible to get. The number is set to 0 to keep the event backward\n       * compatible until we bump KafkaJS to version 2, following the end of node 8 LTS.\n       *\n       * @since 2019-11-29\n       */\n      numberOfBatches: 0,\n      duration: Date.now() - startFetch,\n    })\n\n    const onBatch = async batch => {\n      const startBatchProcess = Date.now()\n      const payload = {\n        topic: batch.topic,\n        partition: batch.partition,\n        highWatermark: batch.highWatermark,\n        offsetLag: batch.offsetLag(),\n        /**\n         * @since 2019-06-24 (>= 1.8.0)\n         *\n         * offsetLag returns the lag based on the latest offset in the batch, to\n         * keep the event backward compatible we just introduced \"offsetLagLow\"\n         * which calculates the lag based on the first offset in the batch\n         */\n        offsetLagLow: batch.offsetLagLow(),\n        batchSize: batch.messages.length,\n        firstOffset: batch.firstOffset(),\n        lastOffset: batch.lastOffset(),\n      }\n\n      this.instrumentationEmitter.emit(START_BATCH_PROCESS, payload)\n\n      if (this.eachMessage) {\n        await this.processEachMessage(batch)\n      } else if (this.eachBatch) {\n        await this.processEachBatch(batch)\n      }\n\n      this.instrumentationEmitter.emit(END_BATCH_PROCESS, {\n        ...payload,\n        duration: Date.now() - startBatchProcess,\n      })\n    }\n\n    const { lock, unlock, unlockWithError } = barrier()\n    const concurrently = limitConcurrency({ limit: this.partitionsConsumedConcurrently })\n\n    let requestsCompleted = false\n    let numberOfExecutions = 0\n    let expectedNumberOfExecutions = 0\n    const enqueuedTasks = []\n\n    while (true) {\n      const result = iterator.next()\n\n      if (result.done) {\n        break\n      }\n\n      if (!this.running) {\n        result.value.catch(error => {\n          this.logger.debug('Ignoring error in fetch request while stopping runner', {\n            error: error.message || error,\n            stack: error.stack,\n          })\n        })\n\n        continue\n      }\n\n      enqueuedTasks.push(async () => {\n        const batches = await result.value\n        expectedNumberOfExecutions += batches.length\n\n        batches.map(batch =>\n          concurrently(async () => {\n            try {\n              if (!this.running) {\n                return\n              }\n\n              if (batch.isEmpty()) {\n                return\n              }\n\n              await onBatch(batch)\n              await this.consumerGroup.heartbeat({ interval: this.heartbeatInterval })\n            } catch (e) {\n              unlockWithError(e)\n            } finally {\n              numberOfExecutions++\n              if (requestsCompleted && numberOfExecutions === expectedNumberOfExecutions) {\n                unlock()\n              }\n            }\n          }).catch(unlockWithError)\n        )\n      })\n    }\n\n    await Promise.all(enqueuedTasks.map(fn => fn()))\n    requestsCompleted = true\n\n    if (expectedNumberOfExecutions === numberOfExecutions) {\n      unlock()\n    }\n\n    const error = await lock\n    if (error) {\n      throw error\n    }\n\n    await this.autoCommitOffsets()\n    await this.consumerGroup.heartbeat({ interval: this.heartbeatInterval })\n  }\n\n  async scheduleFetch() {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n      })\n\n      return\n    }\n\n    return this.retrier(async (bail, retryCount, retryTime) => {\n      try {\n        this.consuming = true\n        await this.fetch()\n        this.consuming = false\n\n        if (this.running) {\n          setImmediate(() => this.scheduleFetch())\n        }\n      } catch (e) {\n        if (!this.running) {\n          this.logger.debug('consumer not running, exiting', {\n            error: e.message,\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n          })\n          return\n        }\n\n        if (isRebalancing(e)) {\n          this.logger.error('The group is rebalancing, re-joining', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n            retryCount,\n            retryTime,\n          })\n\n          await this.join()\n          setImmediate(() => this.scheduleFetch())\n          return\n        }\n\n        if (e.type === 'UNKNOWN_MEMBER_ID') {\n          this.logger.error('The coordinator is not aware of this member, re-joining the group', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n            retryCount,\n            retryTime,\n          })\n\n          this.consumerGroup.memberId = null\n          await this.join()\n          setImmediate(() => this.scheduleFetch())\n          return\n        }\n\n        if (e.name === 'KafkaJSOffsetOutOfRange') {\n          setImmediate(() => this.scheduleFetch())\n          return\n        }\n\n        if (e.name === 'KafkaJSNotImplemented') {\n          return bail(e)\n        }\n\n        this.logger.debug('Error while fetching data, trying again...', {\n          groupId: this.consumerGroup.groupId,\n          memberId: this.consumerGroup.memberId,\n          error: e.message,\n          stack: e.stack,\n          retryCount,\n          retryTime,\n        })\n\n        throw e\n      } finally {\n        this.consuming = false\n      }\n    }).catch(this.onCrash)\n  }\n\n  autoCommitOffsets() {\n    if (this.autoCommit) {\n      return this.consumerGroup.commitOffsets()\n    }\n  }\n\n  autoCommitOffsetsIfNecessary() {\n    if (this.autoCommit) {\n      return this.consumerGroup.commitOffsetsIfNecessary()\n    }\n  }\n\n  commitOffsets(offsets) {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n        offsets,\n      })\n      return\n    }\n\n    return this.retrier(async (bail, retryCount, retryTime) => {\n      try {\n        await this.consumerGroup.commitOffsets(offsets)\n      } catch (e) {\n        if (!this.running) {\n          this.logger.debug('consumer not running, exiting', {\n            error: e.message,\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            offsets,\n          })\n          return\n        }\n\n        if (isRebalancing(e)) {\n          this.logger.error('The group is rebalancing, re-joining', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n            retryCount,\n            retryTime,\n          })\n\n          setImmediate(() => this.scheduleJoin())\n\n          bail(new KafkaJSError(e))\n        }\n\n        if (e.type === 'UNKNOWN_MEMBER_ID') {\n          this.logger.error('The coordinator is not aware of this member, re-joining the group', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n            retryCount,\n            retryTime,\n          })\n\n          this.consumerGroup.memberId = null\n          setImmediate(() => this.scheduleJoin())\n\n          bail(new KafkaJSError(e))\n        }\n\n        if (e.name === 'KafkaJSNotImplemented') {\n          return bail(e)\n        }\n\n        this.logger.debug('Error while committing offsets, trying again...', {\n          groupId: this.consumerGroup.groupId,\n          memberId: this.consumerGroup.memberId,\n          error: e.message,\n          stack: e.stack,\n          retryCount,\n          retryTime,\n          offsets,\n        })\n\n        throw e\n      }\n    })\n  }\n}\n"]},"metadata":{},"sourceType":"script"}