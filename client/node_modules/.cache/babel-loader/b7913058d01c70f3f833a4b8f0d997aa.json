{"ast":null,"code":"const flatten = require('../utils/flatten');\n\nconst {\n  KafkaJSMetadataNotLoaded\n} = require('../errors');\n\nconst {\n  staleMetadata\n} = require('../protocol/error');\n\nconst groupMessagesPerPartition = require('./groupMessagesPerPartition');\n\nconst createTopicData = require('./createTopicData');\n\nconst responseSerializer = require('./responseSerializer');\n\nconst {\n  keys\n} = Object;\n\nmodule.exports = ({\n  logger,\n  cluster,\n  partitioner,\n  eosManager,\n  retrier\n}) => {\n  return async ({\n    acks,\n    timeout,\n    compression,\n    topicMessages\n  }) => {\n    const responsePerBroker = new Map();\n\n    const createProducerRequests = async responsePerBroker => {\n      const topicMetadata = new Map();\n      await cluster.refreshMetadataIfNecessary();\n\n      for (const {\n        topic,\n        messages\n      } of topicMessages) {\n        const partitionMetadata = cluster.findTopicPartitionMetadata(topic);\n\n        if (partitionMetadata.length === 0) {\n          logger.debug('Producing to topic without metadata', {\n            topic,\n            targetTopics: Array.from(cluster.targetTopics)\n          });\n          throw new KafkaJSMetadataNotLoaded('Producing to topic without metadata');\n        }\n\n        const messagesPerPartition = groupMessagesPerPartition({\n          topic,\n          partitionMetadata,\n          messages,\n          partitioner\n        });\n        const partitions = keys(messagesPerPartition);\n        const sequencePerPartition = partitions.reduce((result, partition) => {\n          result[partition] = eosManager.getSequence(topic, partition);\n          return result;\n        }, {});\n        const partitionsPerLeader = cluster.findLeaderForPartitions(topic, partitions);\n        const leaders = keys(partitionsPerLeader);\n        topicMetadata.set(topic, {\n          partitionsPerLeader,\n          messagesPerPartition,\n          sequencePerPartition\n        });\n\n        for (const nodeId of leaders) {\n          const broker = await cluster.findBroker({\n            nodeId\n          });\n\n          if (!responsePerBroker.has(broker)) {\n            responsePerBroker.set(broker, null);\n          }\n        }\n      }\n\n      const brokers = Array.from(responsePerBroker.keys());\n      const brokersWithoutResponse = brokers.filter(broker => !responsePerBroker.get(broker));\n      return brokersWithoutResponse.map(async broker => {\n        const entries = Array.from(topicMetadata.entries());\n        const topicDataForBroker = entries.filter(([_, {\n          partitionsPerLeader\n        }]) => !!partitionsPerLeader[broker.nodeId]).map(([topic, {\n          partitionsPerLeader,\n          messagesPerPartition,\n          sequencePerPartition\n        }]) => ({\n          topic,\n          partitions: partitionsPerLeader[broker.nodeId],\n          sequencePerPartition,\n          messagesPerPartition\n        }));\n        const topicData = createTopicData(topicDataForBroker);\n\n        try {\n          if (eosManager.isTransactional()) {\n            await eosManager.addPartitionsToTransaction(topicData);\n          }\n\n          const response = await broker.produce({\n            transactionalId: eosManager.isTransactional() ? eosManager.getTransactionalId() : undefined,\n            producerId: eosManager.getProducerId(),\n            producerEpoch: eosManager.getProducerEpoch(),\n            acks,\n            timeout,\n            compression,\n            topicData\n          });\n          const expectResponse = acks !== 0;\n          const formattedResponse = expectResponse ? responseSerializer(response) : [];\n          formattedResponse.forEach(({\n            topicName,\n            partition\n          }) => {\n            const increment = topicMetadata.get(topicName).messagesPerPartition[partition].length;\n            eosManager.updateSequence(topicName, partition, increment);\n          });\n          responsePerBroker.set(broker, formattedResponse);\n        } catch (e) {\n          responsePerBroker.delete(broker);\n          throw e;\n        }\n      });\n    };\n\n    return retrier(async (bail, retryCount, retryTime) => {\n      const topics = topicMessages.map(({\n        topic\n      }) => topic);\n      await cluster.addMultipleTargetTopics(topics);\n\n      try {\n        const requests = await createProducerRequests(responsePerBroker);\n        await Promise.all(requests);\n        const responses = Array.from(responsePerBroker.values());\n        return flatten(responses);\n      } catch (e) {\n        if (e.name === 'KafkaJSConnectionClosedError') {\n          cluster.removeBroker({\n            host: e.host,\n            port: e.port\n          });\n        }\n\n        if (!cluster.isConnected()) {\n          logger.debug(`Cluster has disconnected, reconnecting: ${e.message}`, {\n            retryCount,\n            retryTime\n          });\n          await cluster.connect();\n          await cluster.refreshMetadata();\n          throw e;\n        } // This is necessary in case the metadata is stale and the number of partitions\n        // for this topic has increased in the meantime\n\n\n        if (staleMetadata(e) || e.name === 'KafkaJSMetadataNotLoaded' || e.name === 'KafkaJSConnectionError' || e.name === 'KafkaJSConnectionClosedError' || e.name === 'KafkaJSProtocolError' && e.retriable) {\n          logger.error(`Failed to send messages: ${e.message}`, {\n            retryCount,\n            retryTime\n          });\n          await cluster.refreshMetadata();\n          throw e;\n        }\n\n        logger.error(`${e.message}`, {\n          retryCount,\n          retryTime\n        });\n        if (e.retriable) throw e;\n        bail(e);\n      }\n    });\n  };\n};","map":{"version":3,"sources":["/Users/gagekrumbach/Documents/call-center-manage/node_modules/kafkajs/src/producer/sendMessages.js"],"names":["flatten","require","KafkaJSMetadataNotLoaded","staleMetadata","groupMessagesPerPartition","createTopicData","responseSerializer","keys","Object","module","exports","logger","cluster","partitioner","eosManager","retrier","acks","timeout","compression","topicMessages","responsePerBroker","Map","createProducerRequests","topicMetadata","refreshMetadataIfNecessary","topic","messages","partitionMetadata","findTopicPartitionMetadata","length","debug","targetTopics","Array","from","messagesPerPartition","partitions","sequencePerPartition","reduce","result","partition","getSequence","partitionsPerLeader","findLeaderForPartitions","leaders","set","nodeId","broker","findBroker","has","brokers","brokersWithoutResponse","filter","get","map","entries","topicDataForBroker","_","topicData","isTransactional","addPartitionsToTransaction","response","produce","transactionalId","getTransactionalId","undefined","producerId","getProducerId","producerEpoch","getProducerEpoch","expectResponse","formattedResponse","forEach","topicName","increment","updateSequence","e","delete","bail","retryCount","retryTime","topics","addMultipleTargetTopics","requests","Promise","all","responses","values","name","removeBroker","host","port","isConnected","message","connect","refreshMetadata","retriable","error"],"mappings":"AAAA,MAAMA,OAAO,GAAGC,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAM;AAAEC,EAAAA;AAAF,IAA+BD,OAAO,CAAC,WAAD,CAA5C;;AACA,MAAM;AAAEE,EAAAA;AAAF,IAAoBF,OAAO,CAAC,mBAAD,CAAjC;;AACA,MAAMG,yBAAyB,GAAGH,OAAO,CAAC,6BAAD,CAAzC;;AACA,MAAMI,eAAe,GAAGJ,OAAO,CAAC,mBAAD,CAA/B;;AACA,MAAMK,kBAAkB,GAAGL,OAAO,CAAC,sBAAD,CAAlC;;AAEA,MAAM;AAAEM,EAAAA;AAAF,IAAWC,MAAjB;;AAEAC,MAAM,CAACC,OAAP,GAAiB,CAAC;AAAEC,EAAAA,MAAF;AAAUC,EAAAA,OAAV;AAAmBC,EAAAA,WAAnB;AAAgCC,EAAAA,UAAhC;AAA4CC,EAAAA;AAA5C,CAAD,KAA2D;AAC1E,SAAO,OAAO;AAAEC,IAAAA,IAAF;AAAQC,IAAAA,OAAR;AAAiBC,IAAAA,WAAjB;AAA8BC,IAAAA;AAA9B,GAAP,KAAyD;AAC9D,UAAMC,iBAAiB,GAAG,IAAIC,GAAJ,EAA1B;;AAEA,UAAMC,sBAAsB,GAAG,MAAMF,iBAAN,IAA2B;AACxD,YAAMG,aAAa,GAAG,IAAIF,GAAJ,EAAtB;AAEA,YAAMT,OAAO,CAACY,0BAAR,EAAN;;AAEA,WAAK,MAAM;AAAEC,QAAAA,KAAF;AAASC,QAAAA;AAAT,OAAX,IAAkCP,aAAlC,EAAiD;AAC/C,cAAMQ,iBAAiB,GAAGf,OAAO,CAACgB,0BAAR,CAAmCH,KAAnC,CAA1B;;AAEA,YAAIE,iBAAiB,CAACE,MAAlB,KAA6B,CAAjC,EAAoC;AAClClB,UAAAA,MAAM,CAACmB,KAAP,CAAa,qCAAb,EAAoD;AAClDL,YAAAA,KADkD;AAElDM,YAAAA,YAAY,EAAEC,KAAK,CAACC,IAAN,CAAWrB,OAAO,CAACmB,YAAnB;AAFoC,WAApD;AAKA,gBAAM,IAAI7B,wBAAJ,CAA6B,qCAA7B,CAAN;AACD;;AAED,cAAMgC,oBAAoB,GAAG9B,yBAAyB,CAAC;AACrDqB,UAAAA,KADqD;AAErDE,UAAAA,iBAFqD;AAGrDD,UAAAA,QAHqD;AAIrDb,UAAAA;AAJqD,SAAD,CAAtD;AAOA,cAAMsB,UAAU,GAAG5B,IAAI,CAAC2B,oBAAD,CAAvB;AACA,cAAME,oBAAoB,GAAGD,UAAU,CAACE,MAAX,CAAkB,CAACC,MAAD,EAASC,SAAT,KAAuB;AACpED,UAAAA,MAAM,CAACC,SAAD,CAAN,GAAoBzB,UAAU,CAAC0B,WAAX,CAAuBf,KAAvB,EAA8Bc,SAA9B,CAApB;AACA,iBAAOD,MAAP;AACD,SAH4B,EAG1B,EAH0B,CAA7B;AAKA,cAAMG,mBAAmB,GAAG7B,OAAO,CAAC8B,uBAAR,CAAgCjB,KAAhC,EAAuCU,UAAvC,CAA5B;AACA,cAAMQ,OAAO,GAAGpC,IAAI,CAACkC,mBAAD,CAApB;AAEAlB,QAAAA,aAAa,CAACqB,GAAd,CAAkBnB,KAAlB,EAAyB;AACvBgB,UAAAA,mBADuB;AAEvBP,UAAAA,oBAFuB;AAGvBE,UAAAA;AAHuB,SAAzB;;AAMA,aAAK,MAAMS,MAAX,IAAqBF,OAArB,EAA8B;AAC5B,gBAAMG,MAAM,GAAG,MAAMlC,OAAO,CAACmC,UAAR,CAAmB;AAAEF,YAAAA;AAAF,WAAnB,CAArB;;AACA,cAAI,CAACzB,iBAAiB,CAAC4B,GAAlB,CAAsBF,MAAtB,CAAL,EAAoC;AAClC1B,YAAAA,iBAAiB,CAACwB,GAAlB,CAAsBE,MAAtB,EAA8B,IAA9B;AACD;AACF;AACF;;AAED,YAAMG,OAAO,GAAGjB,KAAK,CAACC,IAAN,CAAWb,iBAAiB,CAACb,IAAlB,EAAX,CAAhB;AACA,YAAM2C,sBAAsB,GAAGD,OAAO,CAACE,MAAR,CAAeL,MAAM,IAAI,CAAC1B,iBAAiB,CAACgC,GAAlB,CAAsBN,MAAtB,CAA1B,CAA/B;AAEA,aAAOI,sBAAsB,CAACG,GAAvB,CAA2B,MAAMP,MAAN,IAAgB;AAChD,cAAMQ,OAAO,GAAGtB,KAAK,CAACC,IAAN,CAAWV,aAAa,CAAC+B,OAAd,EAAX,CAAhB;AACA,cAAMC,kBAAkB,GAAGD,OAAO,CAC/BH,MADwB,CACjB,CAAC,CAACK,CAAD,EAAI;AAAEf,UAAAA;AAAF,SAAJ,CAAD,KAAkC,CAAC,CAACA,mBAAmB,CAACK,MAAM,CAACD,MAAR,CADtC,EAExBQ,GAFwB,CAEpB,CAAC,CAAC5B,KAAD,EAAQ;AAAEgB,UAAAA,mBAAF;AAAuBP,UAAAA,oBAAvB;AAA6CE,UAAAA;AAA7C,SAAR,CAAD,MAAmF;AACtFX,UAAAA,KADsF;AAEtFU,UAAAA,UAAU,EAAEM,mBAAmB,CAACK,MAAM,CAACD,MAAR,CAFuD;AAGtFT,UAAAA,oBAHsF;AAItFF,UAAAA;AAJsF,SAAnF,CAFoB,CAA3B;AASA,cAAMuB,SAAS,GAAGpD,eAAe,CAACkD,kBAAD,CAAjC;;AAEA,YAAI;AACF,cAAIzC,UAAU,CAAC4C,eAAX,EAAJ,EAAkC;AAChC,kBAAM5C,UAAU,CAAC6C,0BAAX,CAAsCF,SAAtC,CAAN;AACD;;AAED,gBAAMG,QAAQ,GAAG,MAAMd,MAAM,CAACe,OAAP,CAAe;AACpCC,YAAAA,eAAe,EAAEhD,UAAU,CAAC4C,eAAX,KACb5C,UAAU,CAACiD,kBAAX,EADa,GAEbC,SAHgC;AAIpCC,YAAAA,UAAU,EAAEnD,UAAU,CAACoD,aAAX,EAJwB;AAKpCC,YAAAA,aAAa,EAAErD,UAAU,CAACsD,gBAAX,EALqB;AAMpCpD,YAAAA,IANoC;AAOpCC,YAAAA,OAPoC;AAQpCC,YAAAA,WARoC;AASpCuC,YAAAA;AAToC,WAAf,CAAvB;AAYA,gBAAMY,cAAc,GAAGrD,IAAI,KAAK,CAAhC;AACA,gBAAMsD,iBAAiB,GAAGD,cAAc,GAAG/D,kBAAkB,CAACsD,QAAD,CAArB,GAAkC,EAA1E;AAEAU,UAAAA,iBAAiB,CAACC,OAAlB,CAA0B,CAAC;AAAEC,YAAAA,SAAF;AAAajC,YAAAA;AAAb,WAAD,KAA8B;AACtD,kBAAMkC,SAAS,GAAGlD,aAAa,CAAC6B,GAAd,CAAkBoB,SAAlB,EAA6BtC,oBAA7B,CAAkDK,SAAlD,EAA6DV,MAA/E;AAEAf,YAAAA,UAAU,CAAC4D,cAAX,CAA0BF,SAA1B,EAAqCjC,SAArC,EAAgDkC,SAAhD;AACD,WAJD;AAMArD,UAAAA,iBAAiB,CAACwB,GAAlB,CAAsBE,MAAtB,EAA8BwB,iBAA9B;AACD,SA3BD,CA2BE,OAAOK,CAAP,EAAU;AACVvD,UAAAA,iBAAiB,CAACwD,MAAlB,CAAyB9B,MAAzB;AACA,gBAAM6B,CAAN;AACD;AACF,OA5CM,CAAP;AA6CD,KA/FD;;AAiGA,WAAO5D,OAAO,CAAC,OAAO8D,IAAP,EAAaC,UAAb,EAAyBC,SAAzB,KAAuC;AACpD,YAAMC,MAAM,GAAG7D,aAAa,CAACkC,GAAd,CAAkB,CAAC;AAAE5B,QAAAA;AAAF,OAAD,KAAeA,KAAjC,CAAf;AACA,YAAMb,OAAO,CAACqE,uBAAR,CAAgCD,MAAhC,CAAN;;AAEA,UAAI;AACF,cAAME,QAAQ,GAAG,MAAM5D,sBAAsB,CAACF,iBAAD,CAA7C;AACA,cAAM+D,OAAO,CAACC,GAAR,CAAYF,QAAZ,CAAN;AACA,cAAMG,SAAS,GAAGrD,KAAK,CAACC,IAAN,CAAWb,iBAAiB,CAACkE,MAAlB,EAAX,CAAlB;AACA,eAAOtF,OAAO,CAACqF,SAAD,CAAd;AACD,OALD,CAKE,OAAOV,CAAP,EAAU;AACV,YAAIA,CAAC,CAACY,IAAF,KAAW,8BAAf,EAA+C;AAC7C3E,UAAAA,OAAO,CAAC4E,YAAR,CAAqB;AAAEC,YAAAA,IAAI,EAAEd,CAAC,CAACc,IAAV;AAAgBC,YAAAA,IAAI,EAAEf,CAAC,CAACe;AAAxB,WAArB;AACD;;AAED,YAAI,CAAC9E,OAAO,CAAC+E,WAAR,EAAL,EAA4B;AAC1BhF,UAAAA,MAAM,CAACmB,KAAP,CAAc,2CAA0C6C,CAAC,CAACiB,OAAQ,EAAlE,EAAqE;AACnEd,YAAAA,UADmE;AAEnEC,YAAAA;AAFmE,WAArE;AAIA,gBAAMnE,OAAO,CAACiF,OAAR,EAAN;AACA,gBAAMjF,OAAO,CAACkF,eAAR,EAAN;AACA,gBAAMnB,CAAN;AACD,SAbS,CAeV;AACA;;;AACA,YACExE,aAAa,CAACwE,CAAD,CAAb,IACAA,CAAC,CAACY,IAAF,KAAW,0BADX,IAEAZ,CAAC,CAACY,IAAF,KAAW,wBAFX,IAGAZ,CAAC,CAACY,IAAF,KAAW,8BAHX,IAICZ,CAAC,CAACY,IAAF,KAAW,sBAAX,IAAqCZ,CAAC,CAACoB,SAL1C,EAME;AACApF,UAAAA,MAAM,CAACqF,KAAP,CAAc,4BAA2BrB,CAAC,CAACiB,OAAQ,EAAnD,EAAsD;AAAEd,YAAAA,UAAF;AAAcC,YAAAA;AAAd,WAAtD;AACA,gBAAMnE,OAAO,CAACkF,eAAR,EAAN;AACA,gBAAMnB,CAAN;AACD;;AAEDhE,QAAAA,MAAM,CAACqF,KAAP,CAAc,GAAErB,CAAC,CAACiB,OAAQ,EAA1B,EAA6B;AAAEd,UAAAA,UAAF;AAAcC,UAAAA;AAAd,SAA7B;AACA,YAAIJ,CAAC,CAACoB,SAAN,EAAiB,MAAMpB,CAAN;AACjBE,QAAAA,IAAI,CAACF,CAAD,CAAJ;AACD;AACF,KA1Ca,CAAd;AA2CD,GA/ID;AAgJD,CAjJD","sourcesContent":["const flatten = require('../utils/flatten')\nconst { KafkaJSMetadataNotLoaded } = require('../errors')\nconst { staleMetadata } = require('../protocol/error')\nconst groupMessagesPerPartition = require('./groupMessagesPerPartition')\nconst createTopicData = require('./createTopicData')\nconst responseSerializer = require('./responseSerializer')\n\nconst { keys } = Object\n\nmodule.exports = ({ logger, cluster, partitioner, eosManager, retrier }) => {\n  return async ({ acks, timeout, compression, topicMessages }) => {\n    const responsePerBroker = new Map()\n\n    const createProducerRequests = async responsePerBroker => {\n      const topicMetadata = new Map()\n\n      await cluster.refreshMetadataIfNecessary()\n\n      for (const { topic, messages } of topicMessages) {\n        const partitionMetadata = cluster.findTopicPartitionMetadata(topic)\n\n        if (partitionMetadata.length === 0) {\n          logger.debug('Producing to topic without metadata', {\n            topic,\n            targetTopics: Array.from(cluster.targetTopics),\n          })\n\n          throw new KafkaJSMetadataNotLoaded('Producing to topic without metadata')\n        }\n\n        const messagesPerPartition = groupMessagesPerPartition({\n          topic,\n          partitionMetadata,\n          messages,\n          partitioner,\n        })\n\n        const partitions = keys(messagesPerPartition)\n        const sequencePerPartition = partitions.reduce((result, partition) => {\n          result[partition] = eosManager.getSequence(topic, partition)\n          return result\n        }, {})\n\n        const partitionsPerLeader = cluster.findLeaderForPartitions(topic, partitions)\n        const leaders = keys(partitionsPerLeader)\n\n        topicMetadata.set(topic, {\n          partitionsPerLeader,\n          messagesPerPartition,\n          sequencePerPartition,\n        })\n\n        for (const nodeId of leaders) {\n          const broker = await cluster.findBroker({ nodeId })\n          if (!responsePerBroker.has(broker)) {\n            responsePerBroker.set(broker, null)\n          }\n        }\n      }\n\n      const brokers = Array.from(responsePerBroker.keys())\n      const brokersWithoutResponse = brokers.filter(broker => !responsePerBroker.get(broker))\n\n      return brokersWithoutResponse.map(async broker => {\n        const entries = Array.from(topicMetadata.entries())\n        const topicDataForBroker = entries\n          .filter(([_, { partitionsPerLeader }]) => !!partitionsPerLeader[broker.nodeId])\n          .map(([topic, { partitionsPerLeader, messagesPerPartition, sequencePerPartition }]) => ({\n            topic,\n            partitions: partitionsPerLeader[broker.nodeId],\n            sequencePerPartition,\n            messagesPerPartition,\n          }))\n\n        const topicData = createTopicData(topicDataForBroker)\n\n        try {\n          if (eosManager.isTransactional()) {\n            await eosManager.addPartitionsToTransaction(topicData)\n          }\n\n          const response = await broker.produce({\n            transactionalId: eosManager.isTransactional()\n              ? eosManager.getTransactionalId()\n              : undefined,\n            producerId: eosManager.getProducerId(),\n            producerEpoch: eosManager.getProducerEpoch(),\n            acks,\n            timeout,\n            compression,\n            topicData,\n          })\n\n          const expectResponse = acks !== 0\n          const formattedResponse = expectResponse ? responseSerializer(response) : []\n\n          formattedResponse.forEach(({ topicName, partition }) => {\n            const increment = topicMetadata.get(topicName).messagesPerPartition[partition].length\n\n            eosManager.updateSequence(topicName, partition, increment)\n          })\n\n          responsePerBroker.set(broker, formattedResponse)\n        } catch (e) {\n          responsePerBroker.delete(broker)\n          throw e\n        }\n      })\n    }\n\n    return retrier(async (bail, retryCount, retryTime) => {\n      const topics = topicMessages.map(({ topic }) => topic)\n      await cluster.addMultipleTargetTopics(topics)\n\n      try {\n        const requests = await createProducerRequests(responsePerBroker)\n        await Promise.all(requests)\n        const responses = Array.from(responsePerBroker.values())\n        return flatten(responses)\n      } catch (e) {\n        if (e.name === 'KafkaJSConnectionClosedError') {\n          cluster.removeBroker({ host: e.host, port: e.port })\n        }\n\n        if (!cluster.isConnected()) {\n          logger.debug(`Cluster has disconnected, reconnecting: ${e.message}`, {\n            retryCount,\n            retryTime,\n          })\n          await cluster.connect()\n          await cluster.refreshMetadata()\n          throw e\n        }\n\n        // This is necessary in case the metadata is stale and the number of partitions\n        // for this topic has increased in the meantime\n        if (\n          staleMetadata(e) ||\n          e.name === 'KafkaJSMetadataNotLoaded' ||\n          e.name === 'KafkaJSConnectionError' ||\n          e.name === 'KafkaJSConnectionClosedError' ||\n          (e.name === 'KafkaJSProtocolError' && e.retriable)\n        ) {\n          logger.error(`Failed to send messages: ${e.message}`, { retryCount, retryTime })\n          await cluster.refreshMetadata()\n          throw e\n        }\n\n        logger.error(`${e.message}`, { retryCount, retryTime })\n        if (e.retriable) throw e\n        bail(e)\n      }\n    })\n  }\n}\n"]},"metadata":{},"sourceType":"script"}