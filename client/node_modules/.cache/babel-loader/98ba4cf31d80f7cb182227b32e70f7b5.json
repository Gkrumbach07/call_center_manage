{"ast":null,"code":"const flatten = require('../utils/flatten');\n\nconst sleep = require('../utils/sleep');\n\nconst BufferedAsyncIterator = require('../utils/bufferedAsyncIterator');\n\nconst websiteUrl = require('../utils/websiteUrl');\n\nconst arrayDiff = require('../utils/arrayDiff');\n\nconst createRetry = require('../retry');\n\nconst OffsetManager = require('./offsetManager');\n\nconst Batch = require('./batch');\n\nconst SeekOffsets = require('./seekOffsets');\n\nconst SubscriptionState = require('./subscriptionState');\n\nconst {\n  events: {\n    GROUP_JOIN,\n    HEARTBEAT,\n    CONNECT,\n    RECEIVED_UNSUBSCRIBED_TOPICS\n  }\n} = require('./instrumentationEvents');\n\nconst {\n  MemberAssignment\n} = require('./assignerProtocol');\n\nconst {\n  KafkaJSError,\n  KafkaJSNonRetriableError,\n  KafkaJSStaleTopicMetadataAssignment\n} = require('../errors');\n\nconst {\n  keys\n} = Object;\nconst STALE_METADATA_ERRORS = ['LEADER_NOT_AVAILABLE', // Fetch before v9 uses NOT_LEADER_FOR_PARTITION\n'NOT_LEADER_FOR_PARTITION', // Fetch after v9 uses {FENCED,UNKNOWN}_LEADER_EPOCH\n'FENCED_LEADER_EPOCH', 'UNKNOWN_LEADER_EPOCH', 'UNKNOWN_TOPIC_OR_PARTITION'];\n\nconst isRebalancing = e => e.type === 'REBALANCE_IN_PROGRESS' || e.type === 'NOT_COORDINATOR_FOR_GROUP';\n\nconst PRIVATE = {\n  JOIN: Symbol('private:ConsumerGroup:join'),\n  SYNC: Symbol('private:ConsumerGroup:sync')\n};\nmodule.exports = class ConsumerGroup {\n  constructor({\n    retry,\n    cluster,\n    groupId,\n    topics,\n    topicConfigurations,\n    logger,\n    instrumentationEmitter,\n    assigners,\n    sessionTimeout,\n    rebalanceTimeout,\n    maxBytesPerPartition,\n    minBytes,\n    maxBytes,\n    maxWaitTimeInMs,\n    autoCommitInterval,\n    autoCommitThreshold,\n    isolationLevel,\n    rackId,\n    metadataMaxAge\n  }) {\n    /** @type {import(\"../../types\").Cluster} */\n    this.cluster = cluster;\n    this.groupId = groupId;\n    this.topics = topics;\n    this.topicsSubscribed = topics;\n    this.topicConfigurations = topicConfigurations;\n    this.logger = logger.namespace('ConsumerGroup');\n    this.instrumentationEmitter = instrumentationEmitter;\n    this.retrier = createRetry(Object.assign({}, retry));\n    this.assigners = assigners;\n    this.sessionTimeout = sessionTimeout;\n    this.rebalanceTimeout = rebalanceTimeout;\n    this.maxBytesPerPartition = maxBytesPerPartition;\n    this.minBytes = minBytes;\n    this.maxBytes = maxBytes;\n    this.maxWaitTime = maxWaitTimeInMs;\n    this.autoCommitInterval = autoCommitInterval;\n    this.autoCommitThreshold = autoCommitThreshold;\n    this.isolationLevel = isolationLevel;\n    this.rackId = rackId;\n    this.metadataMaxAge = metadataMaxAge;\n    this.seekOffset = new SeekOffsets();\n    this.coordinator = null;\n    this.generationId = null;\n    this.leaderId = null;\n    this.memberId = null;\n    this.members = null;\n    this.groupProtocol = null;\n    this.partitionsPerSubscribedTopic = null;\n    /**\n     * Preferred read replica per topic and partition\n     *\n     * Each of the partitions tracks the preferred read replica (`nodeId`) and a timestamp\n     * until when that preference is valid.\n     *\n     * @type {{[topicName: string]: {[partition: number]: {nodeId: number, expireAt: number}}}}\n     */\n\n    this.preferredReadReplicasPerTopicPartition = {};\n    this.offsetManager = null;\n    this.subscriptionState = new SubscriptionState();\n    this.lastRequest = Date.now();\n  }\n\n  isLeader() {\n    return this.leaderId && this.memberId === this.leaderId;\n  }\n\n  async connect() {\n    await this.cluster.connect();\n    this.instrumentationEmitter.emit(CONNECT);\n    await this.cluster.refreshMetadataIfNecessary();\n  }\n\n  async [PRIVATE.JOIN]() {\n    const {\n      groupId,\n      sessionTimeout,\n      rebalanceTimeout\n    } = this;\n    this.coordinator = await this.cluster.findGroupCoordinator({\n      groupId\n    });\n    const groupData = await this.coordinator.joinGroup({\n      groupId,\n      sessionTimeout,\n      rebalanceTimeout,\n      memberId: this.memberId || '',\n      groupProtocols: this.assigners.map(assigner => assigner.protocol({\n        topics: this.topicsSubscribed\n      }))\n    });\n    this.generationId = groupData.generationId;\n    this.leaderId = groupData.leaderId;\n    this.memberId = groupData.memberId;\n    this.members = groupData.members;\n    this.groupProtocol = groupData.groupProtocol;\n  }\n\n  async leave() {\n    const {\n      groupId,\n      memberId\n    } = this;\n\n    if (memberId) {\n      await this.coordinator.leaveGroup({\n        groupId,\n        memberId\n      });\n      this.memberId = null;\n    }\n  }\n\n  async [PRIVATE.SYNC]() {\n    let assignment = [];\n    const {\n      groupId,\n      generationId,\n      memberId,\n      members,\n      groupProtocol,\n      topics,\n      topicsSubscribed,\n      coordinator\n    } = this;\n\n    if (this.isLeader()) {\n      this.logger.debug('Chosen as group leader', {\n        groupId,\n        generationId,\n        memberId,\n        topics\n      });\n      const assigner = this.assigners.find(({\n        name\n      }) => name === groupProtocol);\n\n      if (!assigner) {\n        throw new KafkaJSNonRetriableError(`Unsupported partition assigner \"${groupProtocol}\", the assigner wasn't found in the assigners list`);\n      }\n\n      await this.cluster.refreshMetadata();\n      assignment = await assigner.assign({\n        members,\n        topics: topicsSubscribed\n      });\n      this.logger.debug('Group assignment', {\n        groupId,\n        generationId,\n        groupProtocol,\n        assignment,\n        topics: topicsSubscribed\n      });\n    } // Keep track of the partitions for the subscribed topics\n\n\n    this.partitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic();\n    const {\n      memberAssignment\n    } = await this.coordinator.syncGroup({\n      groupId,\n      generationId,\n      memberId,\n      groupAssignment: assignment\n    });\n    const decodedMemberAssignment = MemberAssignment.decode(memberAssignment);\n    const decodedAssignment = decodedMemberAssignment != null ? decodedMemberAssignment.assignment : {};\n    this.logger.debug('Received assignment', {\n      groupId,\n      generationId,\n      memberId,\n      memberAssignment: decodedAssignment\n    });\n    const assignedTopics = keys(decodedAssignment);\n    const topicsNotSubscribed = arrayDiff(assignedTopics, topicsSubscribed);\n\n    if (topicsNotSubscribed.length > 0) {\n      const payload = {\n        groupId,\n        generationId,\n        memberId,\n        assignedTopics,\n        topicsSubscribed,\n        topicsNotSubscribed\n      };\n      this.instrumentationEmitter.emit(RECEIVED_UNSUBSCRIBED_TOPICS, payload);\n      this.logger.warn('Consumer group received unsubscribed topics', { ...payload,\n        helpUrl: websiteUrl('docs/faq', 'why-am-i-receiving-messages-for-topics-i-m-not-subscribed-to')\n      });\n    } // Remove unsubscribed topics from the list\n\n\n    const safeAssignment = arrayDiff(assignedTopics, topicsNotSubscribed);\n    const currentMemberAssignment = safeAssignment.map(topic => ({\n      topic,\n      partitions: decodedAssignment[topic]\n    })); // Check if the consumer is aware of all assigned partitions\n\n    for (const assignment of currentMemberAssignment) {\n      const {\n        topic,\n        partitions: assignedPartitions\n      } = assignment;\n      const knownPartitions = this.partitionsPerSubscribedTopic.get(topic);\n      const isAwareOfAllAssignedPartitions = assignedPartitions.every(partition => knownPartitions.includes(partition));\n\n      if (!isAwareOfAllAssignedPartitions) {\n        this.logger.warn('Consumer is not aware of all assigned partitions, refreshing metadata', {\n          groupId,\n          generationId,\n          memberId,\n          topic,\n          knownPartitions,\n          assignedPartitions\n        }); // If the consumer is not aware of all assigned partitions, refresh metadata\n        // and update the list of partitions per subscribed topic. It's enough to perform\n        // this operation once since refresh metadata will update metadata for all topics\n\n        await this.cluster.refreshMetadata();\n        this.partitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic();\n        break;\n      }\n    }\n\n    this.topics = currentMemberAssignment.map(({\n      topic\n    }) => topic);\n    this.subscriptionState.assign(currentMemberAssignment);\n    this.offsetManager = new OffsetManager({\n      cluster: this.cluster,\n      topicConfigurations: this.topicConfigurations,\n      instrumentationEmitter: this.instrumentationEmitter,\n      memberAssignment: currentMemberAssignment.reduce((partitionsByTopic, {\n        topic,\n        partitions\n      }) => ({ ...partitionsByTopic,\n        [topic]: partitions\n      }), {}),\n      autoCommitInterval: this.autoCommitInterval,\n      autoCommitThreshold: this.autoCommitThreshold,\n      coordinator,\n      groupId,\n      generationId,\n      memberId\n    });\n  }\n\n  joinAndSync() {\n    const startJoin = Date.now();\n    return this.retrier(async bail => {\n      try {\n        await this[PRIVATE.JOIN]();\n        await this[PRIVATE.SYNC]();\n        const memberAssignment = this.assigned().reduce((result, {\n          topic,\n          partitions\n        }) => ({ ...result,\n          [topic]: partitions\n        }), {});\n        const payload = {\n          groupId: this.groupId,\n          memberId: this.memberId,\n          leaderId: this.leaderId,\n          isLeader: this.isLeader(),\n          memberAssignment,\n          groupProtocol: this.groupProtocol,\n          duration: Date.now() - startJoin\n        };\n        this.instrumentationEmitter.emit(GROUP_JOIN, payload);\n        this.logger.info('Consumer has joined the group', payload);\n      } catch (e) {\n        if (isRebalancing(e)) {\n          // Rebalance in progress isn't a retriable protocol error since the consumer\n          // has to go through find coordinator and join again before it can\n          // actually retry the operation. We wrap the original error in a retriable error\n          // here instead in order to restart the join + sync sequence using the retrier.\n          throw new KafkaJSError(e);\n        }\n\n        bail(e);\n      }\n    });\n  }\n\n  resetOffset({\n    topic,\n    partition\n  }) {\n    this.offsetManager.resetOffset({\n      topic,\n      partition\n    });\n  }\n\n  resolveOffset({\n    topic,\n    partition,\n    offset\n  }) {\n    this.offsetManager.resolveOffset({\n      topic,\n      partition,\n      offset\n    });\n  }\n  /**\n   * Update the consumer offset for the given topic/partition. This will be used\n   * on the next fetch. If this API is invoked for the same topic/partition more\n   * than once, the latest offset will be used on the next fetch.\n   *\n   * @param {string} topic\n   * @param {number} partition\n   * @param {string} offset\n   */\n\n\n  seek({\n    topic,\n    partition,\n    offset\n  }) {\n    this.seekOffset.set(topic, partition, offset);\n  }\n\n  pause(topicPartitions) {\n    this.logger.info(`Pausing fetching from ${topicPartitions.length} topics`, {\n      topicPartitions\n    });\n    this.subscriptionState.pause(topicPartitions);\n  }\n\n  resume(topicPartitions) {\n    this.logger.info(`Resuming fetching from ${topicPartitions.length} topics`, {\n      topicPartitions\n    });\n    this.subscriptionState.resume(topicPartitions);\n  }\n\n  assigned() {\n    return this.subscriptionState.assigned();\n  }\n\n  paused() {\n    return this.subscriptionState.paused();\n  }\n\n  async commitOffsetsIfNecessary() {\n    await this.offsetManager.commitOffsetsIfNecessary();\n  }\n\n  async commitOffsets(offsets) {\n    await this.offsetManager.commitOffsets(offsets);\n  }\n\n  uncommittedOffsets() {\n    return this.offsetManager.uncommittedOffsets();\n  }\n\n  async heartbeat({\n    interval\n  }) {\n    const {\n      groupId,\n      generationId,\n      memberId\n    } = this;\n    const now = Date.now();\n\n    if (memberId && now >= this.lastRequest + interval) {\n      const payload = {\n        groupId,\n        memberId,\n        groupGenerationId: generationId\n      };\n      await this.coordinator.heartbeat(payload);\n      this.instrumentationEmitter.emit(HEARTBEAT, payload);\n      this.lastRequest = Date.now();\n    }\n  }\n\n  async fetch() {\n    try {\n      const {\n        topics,\n        maxBytesPerPartition,\n        maxWaitTime,\n        minBytes,\n        maxBytes\n      } = this;\n      /** @type {{[nodeId: string]: {topic: string, partitions: { partition: number; fetchOffset: string; maxBytes: number }[]}[]}} */\n\n      const requestsPerNode = {};\n      await this.cluster.refreshMetadataIfNecessary();\n      this.checkForStaleAssignment();\n\n      while (this.seekOffset.size > 0) {\n        const seekEntry = this.seekOffset.pop();\n        this.logger.debug('Seek offset', {\n          groupId: this.groupId,\n          memberId: this.memberId,\n          seek: seekEntry\n        });\n        await this.offsetManager.seek(seekEntry);\n      }\n\n      const pausedTopicPartitions = this.subscriptionState.paused();\n      const activeTopicPartitions = this.subscriptionState.active();\n      const activePartitions = flatten(activeTopicPartitions.map(({\n        partitions\n      }) => partitions));\n      const activeTopics = activeTopicPartitions.filter(({\n        partitions\n      }) => partitions.length > 0).map(({\n        topic\n      }) => topic);\n\n      if (activePartitions.length === 0) {\n        this.logger.debug(`No active topic partitions, sleeping for ${this.maxWaitTime}ms`, {\n          topics,\n          activeTopicPartitions,\n          pausedTopicPartitions\n        });\n        await sleep(this.maxWaitTime);\n        return BufferedAsyncIterator([]);\n      }\n\n      await this.offsetManager.resolveOffsets();\n      this.logger.debug(`Fetching from ${activePartitions.length} partitions for ${activeTopics.length} out of ${topics.length} topics`, {\n        topics,\n        activeTopicPartitions,\n        pausedTopicPartitions\n      });\n\n      for (const topicPartition of activeTopicPartitions) {\n        const partitionsPerNode = this.findReadReplicaForPartitions(topicPartition.topic, topicPartition.partitions);\n        const nodeIds = keys(partitionsPerNode);\n        const committedOffsets = this.offsetManager.committedOffsets();\n\n        for (const nodeId of nodeIds) {\n          const partitions = partitionsPerNode[nodeId].filter(partition => {\n            /**\n             * When recovering from OffsetOutOfRange, each partition can recover\n             * concurrently, which invalidates resolved and committed offsets as part\n             * of the recovery mechanism (see OffsetManager.clearOffsets). In concurrent\n             * scenarios this can initiate a new fetch with invalid offsets.\n             *\n             * This was further highlighted by https://github.com/tulios/kafkajs/pull/570,\n             * which increased concurrency, making this more likely to happen.\n             *\n             * This is solved by only making requests for partitions with initialized offsets.\n             *\n             * See the following pull request which explains the context of the problem:\n             * @issue https://github.com/tulios/kafkajs/pull/578\n             */\n            return committedOffsets[topicPartition.topic][partition] != null;\n          }).map(partition => ({\n            partition,\n            fetchOffset: this.offsetManager.nextOffset(topicPartition.topic, partition).toString(),\n            maxBytes: maxBytesPerPartition\n          }));\n          requestsPerNode[nodeId] = requestsPerNode[nodeId] || [];\n          requestsPerNode[nodeId].push({\n            topic: topicPartition.topic,\n            partitions\n          });\n        }\n      }\n\n      const requests = keys(requestsPerNode).map(async nodeId => {\n        const broker = await this.cluster.findBroker({\n          nodeId\n        });\n        const {\n          responses\n        } = await broker.fetch({\n          maxWaitTime,\n          minBytes,\n          maxBytes,\n          isolationLevel: this.isolationLevel,\n          topics: requestsPerNode[nodeId],\n          rackId: this.rackId\n        });\n        const batchesPerPartition = responses.map(({\n          topicName,\n          partitions\n        }) => {\n          const topicRequestData = requestsPerNode[nodeId].find(({\n            topic\n          }) => topic === topicName);\n          let preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topicName];\n\n          if (!preferredReadReplicas) {\n            this.preferredReadReplicasPerTopicPartition[topicName] = preferredReadReplicas = {};\n          }\n\n          return partitions.filter(partitionData => !this.seekOffset.has(topicName, partitionData.partition) && !this.subscriptionState.isPaused(topicName, partitionData.partition)).map(partitionData => {\n            const {\n              partition,\n              preferredReadReplica\n            } = partitionData;\n\n            if (preferredReadReplica != null && preferredReadReplica !== -1) {\n              const {\n                nodeId: currentPreferredReadReplica\n              } = preferredReadReplicas[partition] || {};\n\n              if (currentPreferredReadReplica !== preferredReadReplica) {\n                this.logger.info(`Preferred read replica is now ${preferredReadReplica}`, {\n                  groupId: this.groupId,\n                  memberId: this.memberId,\n                  topic: topicName,\n                  partition\n                });\n              }\n\n              preferredReadReplicas[partition] = {\n                nodeId: preferredReadReplica,\n                expireAt: Date.now() + this.metadataMaxAge\n              };\n            }\n\n            const partitionRequestData = topicRequestData.partitions.find(({\n              partition\n            }) => partition === partitionData.partition);\n            const fetchedOffset = partitionRequestData.fetchOffset;\n            const batch = new Batch(topicName, fetchedOffset, partitionData);\n            /**\n             * Resolve the offset to skip the control batch since `eachBatch` or `eachMessage` callbacks\n             * won't process empty batches\n             *\n             * @see https://github.com/apache/kafka/blob/9aa660786e46c1efbf5605a6a69136a1dac6edb9/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L1499-L1505\n             */\n\n            if (batch.isEmptyControlRecord() || batch.isEmptyDueToLogCompactedMessages()) {\n              this.resolveOffset({\n                topic: batch.topic,\n                partition: batch.partition,\n                offset: batch.lastOffset()\n              });\n            }\n\n            return batch;\n          });\n        });\n        return flatten(batchesPerPartition);\n      }); // fetch can generate empty requests when the consumer group receives an assignment\n      // with more topics than the subscribed, so to prevent a busy loop we wait the\n      // configured max wait time\n\n      if (requests.length === 0) {\n        await sleep(this.maxWaitTime);\n        return BufferedAsyncIterator([]);\n      }\n\n      return BufferedAsyncIterator(requests, e => this.recoverFromFetch(e));\n    } catch (e) {\n      await this.recoverFromFetch(e);\n    }\n  }\n\n  async recoverFromFetch(e) {\n    if (STALE_METADATA_ERRORS.includes(e.type) || e.name === 'KafkaJSTopicMetadataNotLoaded') {\n      this.logger.debug('Stale cluster metadata, refreshing...', {\n        groupId: this.groupId,\n        memberId: this.memberId,\n        error: e.message\n      });\n      await this.cluster.refreshMetadata();\n      await this.joinAndSync();\n      throw new KafkaJSError(e.message);\n    }\n\n    if (e.name === 'KafkaJSStaleTopicMetadataAssignment') {\n      this.logger.warn(`${e.message}, resync group`, {\n        groupId: this.groupId,\n        memberId: this.memberId,\n        topic: e.topic,\n        unknownPartitions: e.unknownPartitions\n      });\n      await this.joinAndSync();\n    }\n\n    if (e.name === 'KafkaJSOffsetOutOfRange') {\n      await this.recoverFromOffsetOutOfRange(e);\n    }\n\n    if (e.name === 'KafkaJSConnectionClosedError') {\n      this.cluster.removeBroker({\n        host: e.host,\n        port: e.port\n      });\n    }\n\n    if (e.name === 'KafkaJSBrokerNotFound' || e.name === 'KafkaJSConnectionClosedError') {\n      this.logger.debug(`${e.message}, refreshing metadata and retrying...`);\n      await this.cluster.refreshMetadata();\n    }\n\n    throw e;\n  }\n\n  async recoverFromOffsetOutOfRange(e) {\n    // If we are fetching from a follower try with the leader before resetting offsets\n    const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[e.topic];\n\n    if (preferredReadReplicas && typeof preferredReadReplicas[e.partition] === 'number') {\n      this.logger.info('Offset out of range while fetching from follower, retrying with leader', {\n        topic: e.topic,\n        partition: e.partition,\n        groupId: this.groupId,\n        memberId: this.memberId\n      });\n      delete preferredReadReplicas[e.partition];\n    } else {\n      this.logger.error('Offset out of range, resetting to default offset', {\n        topic: e.topic,\n        partition: e.partition,\n        groupId: this.groupId,\n        memberId: this.memberId\n      });\n      await this.offsetManager.setDefaultOffset({\n        topic: e.topic,\n        partition: e.partition\n      });\n    }\n  }\n\n  generatePartitionsPerSubscribedTopic() {\n    const map = new Map();\n\n    for (const topic of this.topicsSubscribed) {\n      const partitions = this.cluster.findTopicPartitionMetadata(topic).map(m => m.partitionId).sort();\n      map.set(topic, partitions);\n    }\n\n    return map;\n  }\n\n  checkForStaleAssignment() {\n    if (!this.partitionsPerSubscribedTopic) {\n      return;\n    }\n\n    const newPartitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic();\n\n    for (const [topic, partitions] of newPartitionsPerSubscribedTopic) {\n      const diff = arrayDiff(partitions, this.partitionsPerSubscribedTopic.get(topic));\n\n      if (diff.length > 0) {\n        throw new KafkaJSStaleTopicMetadataAssignment('Topic has been updated', {\n          topic,\n          unknownPartitions: diff\n        });\n      }\n    }\n  }\n\n  hasSeekOffset({\n    topic,\n    partition\n  }) {\n    return this.seekOffset.has(topic, partition);\n  }\n  /**\n   * For each of the partitions find the best nodeId to read it from\n   *\n   * @param {string} topic\n   * @param {number[]} partitions\n   * @returns {{[nodeId: number]: number[]}} per-node assignment of partitions\n   * @see Cluster~findLeaderForPartitions\n   */\n  // Invariant: The resulting object has each partition referenced exactly once\n\n\n  findReadReplicaForPartitions(topic, partitions) {\n    const partitionMetadata = this.cluster.findTopicPartitionMetadata(topic);\n    const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topic];\n    return partitions.reduce((result, id) => {\n      const partitionId = parseInt(id, 10);\n      const metadata = partitionMetadata.find(p => p.partitionId === partitionId);\n\n      if (!metadata) {\n        return result;\n      }\n\n      if (metadata.leader == null) {\n        throw new KafkaJSError('Invalid partition metadata', {\n          topic,\n          partitionId,\n          metadata\n        });\n      } // Pick the preferred replica if there is one, and it isn't known to be offline, otherwise the leader.\n\n\n      let nodeId = metadata.leader;\n\n      if (preferredReadReplicas) {\n        const {\n          nodeId: preferredReadReplica,\n          expireAt\n        } = preferredReadReplicas[partitionId] || {};\n\n        if (Date.now() >= expireAt) {\n          this.logger.debug('Preferred read replica information has expired, using leader', {\n            topic,\n            partitionId,\n            groupId: this.groupId,\n            memberId: this.memberId,\n            preferredReadReplica,\n            leader: metadata.leader\n          }); // Drop the entry\n\n          delete preferredReadReplicas[partitionId];\n        } else if (preferredReadReplica != null) {\n          // Valid entry, check whether it is not offline\n          // Note that we don't delete the preference here, and rather hope that eventually that replica comes online again\n          const offlineReplicas = metadata.offlineReplicas;\n\n          if (Array.isArray(offlineReplicas) && offlineReplicas.includes(nodeId)) {\n            this.logger.debug('Preferred read replica is offline, using leader', {\n              topic,\n              partitionId,\n              groupId: this.groupId,\n              memberId: this.memberId,\n              preferredReadReplica,\n              leader: metadata.leader\n            });\n          } else {\n            nodeId = preferredReadReplica;\n          }\n        }\n      }\n\n      const current = result[nodeId] || [];\n      return { ...result,\n        [nodeId]: [...current, partitionId]\n      };\n    }, {});\n  }\n\n};","map":{"version":3,"sources":["/Users/gagekrumbach/Documents/call-center-manage/node_modules/kafkajs/src/consumer/consumerGroup.js"],"names":["flatten","require","sleep","BufferedAsyncIterator","websiteUrl","arrayDiff","createRetry","OffsetManager","Batch","SeekOffsets","SubscriptionState","events","GROUP_JOIN","HEARTBEAT","CONNECT","RECEIVED_UNSUBSCRIBED_TOPICS","MemberAssignment","KafkaJSError","KafkaJSNonRetriableError","KafkaJSStaleTopicMetadataAssignment","keys","Object","STALE_METADATA_ERRORS","isRebalancing","e","type","PRIVATE","JOIN","Symbol","SYNC","module","exports","ConsumerGroup","constructor","retry","cluster","groupId","topics","topicConfigurations","logger","instrumentationEmitter","assigners","sessionTimeout","rebalanceTimeout","maxBytesPerPartition","minBytes","maxBytes","maxWaitTimeInMs","autoCommitInterval","autoCommitThreshold","isolationLevel","rackId","metadataMaxAge","topicsSubscribed","namespace","retrier","assign","maxWaitTime","seekOffset","coordinator","generationId","leaderId","memberId","members","groupProtocol","partitionsPerSubscribedTopic","preferredReadReplicasPerTopicPartition","offsetManager","subscriptionState","lastRequest","Date","now","isLeader","connect","emit","refreshMetadataIfNecessary","findGroupCoordinator","groupData","joinGroup","groupProtocols","map","assigner","protocol","leave","leaveGroup","assignment","debug","find","name","refreshMetadata","generatePartitionsPerSubscribedTopic","memberAssignment","syncGroup","groupAssignment","decodedMemberAssignment","decode","decodedAssignment","assignedTopics","topicsNotSubscribed","length","payload","warn","helpUrl","safeAssignment","currentMemberAssignment","topic","partitions","assignedPartitions","knownPartitions","get","isAwareOfAllAssignedPartitions","every","partition","includes","reduce","partitionsByTopic","joinAndSync","startJoin","bail","assigned","result","duration","info","resetOffset","resolveOffset","offset","seek","set","pause","topicPartitions","resume","paused","commitOffsetsIfNecessary","commitOffsets","offsets","uncommittedOffsets","heartbeat","interval","groupGenerationId","fetch","requestsPerNode","checkForStaleAssignment","size","seekEntry","pop","pausedTopicPartitions","activeTopicPartitions","active","activePartitions","activeTopics","filter","resolveOffsets","topicPartition","partitionsPerNode","findReadReplicaForPartitions","nodeIds","committedOffsets","nodeId","fetchOffset","nextOffset","toString","push","requests","broker","findBroker","responses","batchesPerPartition","topicName","topicRequestData","preferredReadReplicas","partitionData","has","isPaused","preferredReadReplica","currentPreferredReadReplica","expireAt","partitionRequestData","fetchedOffset","batch","isEmptyControlRecord","isEmptyDueToLogCompactedMessages","lastOffset","recoverFromFetch","error","message","unknownPartitions","recoverFromOffsetOutOfRange","removeBroker","host","port","setDefaultOffset","Map","findTopicPartitionMetadata","m","partitionId","sort","newPartitionsPerSubscribedTopic","diff","hasSeekOffset","partitionMetadata","id","parseInt","metadata","p","leader","offlineReplicas","Array","isArray","current"],"mappings":"AAAA,MAAMA,OAAO,GAAGC,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAMC,KAAK,GAAGD,OAAO,CAAC,gBAAD,CAArB;;AACA,MAAME,qBAAqB,GAAGF,OAAO,CAAC,gCAAD,CAArC;;AACA,MAAMG,UAAU,GAAGH,OAAO,CAAC,qBAAD,CAA1B;;AACA,MAAMI,SAAS,GAAGJ,OAAO,CAAC,oBAAD,CAAzB;;AACA,MAAMK,WAAW,GAAGL,OAAO,CAAC,UAAD,CAA3B;;AAEA,MAAMM,aAAa,GAAGN,OAAO,CAAC,iBAAD,CAA7B;;AACA,MAAMO,KAAK,GAAGP,OAAO,CAAC,SAAD,CAArB;;AACA,MAAMQ,WAAW,GAAGR,OAAO,CAAC,eAAD,CAA3B;;AACA,MAAMS,iBAAiB,GAAGT,OAAO,CAAC,qBAAD,CAAjC;;AACA,MAAM;AACJU,EAAAA,MAAM,EAAE;AAAEC,IAAAA,UAAF;AAAcC,IAAAA,SAAd;AAAyBC,IAAAA,OAAzB;AAAkCC,IAAAA;AAAlC;AADJ,IAEFd,OAAO,CAAC,yBAAD,CAFX;;AAGA,MAAM;AAAEe,EAAAA;AAAF,IAAuBf,OAAO,CAAC,oBAAD,CAApC;;AACA,MAAM;AACJgB,EAAAA,YADI;AAEJC,EAAAA,wBAFI;AAGJC,EAAAA;AAHI,IAIFlB,OAAO,CAAC,WAAD,CAJX;;AAMA,MAAM;AAAEmB,EAAAA;AAAF,IAAWC,MAAjB;AAEA,MAAMC,qBAAqB,GAAG,CAC5B,sBAD4B,EAE5B;AACA,0BAH4B,EAI5B;AACA,qBAL4B,EAM5B,sBAN4B,EAO5B,4BAP4B,CAA9B;;AAUA,MAAMC,aAAa,GAAGC,CAAC,IACrBA,CAAC,CAACC,IAAF,KAAW,uBAAX,IAAsCD,CAAC,CAACC,IAAF,KAAW,2BADnD;;AAGA,MAAMC,OAAO,GAAG;AACdC,EAAAA,IAAI,EAAEC,MAAM,CAAC,4BAAD,CADE;AAEdC,EAAAA,IAAI,EAAED,MAAM,CAAC,4BAAD;AAFE,CAAhB;AAKAE,MAAM,CAACC,OAAP,GAAiB,MAAMC,aAAN,CAAoB;AACnCC,EAAAA,WAAW,CAAC;AACVC,IAAAA,KADU;AAEVC,IAAAA,OAFU;AAGVC,IAAAA,OAHU;AAIVC,IAAAA,MAJU;AAKVC,IAAAA,mBALU;AAMVC,IAAAA,MANU;AAOVC,IAAAA,sBAPU;AAQVC,IAAAA,SARU;AASVC,IAAAA,cATU;AAUVC,IAAAA,gBAVU;AAWVC,IAAAA,oBAXU;AAYVC,IAAAA,QAZU;AAaVC,IAAAA,QAbU;AAcVC,IAAAA,eAdU;AAeVC,IAAAA,kBAfU;AAgBVC,IAAAA,mBAhBU;AAiBVC,IAAAA,cAjBU;AAkBVC,IAAAA,MAlBU;AAmBVC,IAAAA;AAnBU,GAAD,EAoBR;AACD;AACA,SAAKjB,OAAL,GAAeA,OAAf;AACA,SAAKC,OAAL,GAAeA,OAAf;AACA,SAAKC,MAAL,GAAcA,MAAd;AACA,SAAKgB,gBAAL,GAAwBhB,MAAxB;AACA,SAAKC,mBAAL,GAA2BA,mBAA3B;AACA,SAAKC,MAAL,GAAcA,MAAM,CAACe,SAAP,CAAiB,eAAjB,CAAd;AACA,SAAKd,sBAAL,GAA8BA,sBAA9B;AACA,SAAKe,OAAL,GAAejD,WAAW,CAACe,MAAM,CAACmC,MAAP,CAAc,EAAd,EAAkBtB,KAAlB,CAAD,CAA1B;AACA,SAAKO,SAAL,GAAiBA,SAAjB;AACA,SAAKC,cAAL,GAAsBA,cAAtB;AACA,SAAKC,gBAAL,GAAwBA,gBAAxB;AACA,SAAKC,oBAAL,GAA4BA,oBAA5B;AACA,SAAKC,QAAL,GAAgBA,QAAhB;AACA,SAAKC,QAAL,GAAgBA,QAAhB;AACA,SAAKW,WAAL,GAAmBV,eAAnB;AACA,SAAKC,kBAAL,GAA0BA,kBAA1B;AACA,SAAKC,mBAAL,GAA2BA,mBAA3B;AACA,SAAKC,cAAL,GAAsBA,cAAtB;AACA,SAAKC,MAAL,GAAcA,MAAd;AACA,SAAKC,cAAL,GAAsBA,cAAtB;AAEA,SAAKM,UAAL,GAAkB,IAAIjD,WAAJ,EAAlB;AACA,SAAKkD,WAAL,GAAmB,IAAnB;AACA,SAAKC,YAAL,GAAoB,IAApB;AACA,SAAKC,QAAL,GAAgB,IAAhB;AACA,SAAKC,QAAL,GAAgB,IAAhB;AACA,SAAKC,OAAL,GAAe,IAAf;AACA,SAAKC,aAAL,GAAqB,IAArB;AAEA,SAAKC,4BAAL,GAAoC,IAApC;AACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AACI,SAAKC,sCAAL,GAA8C,EAA9C;AACA,SAAKC,aAAL,GAAqB,IAArB;AACA,SAAKC,iBAAL,GAAyB,IAAI1D,iBAAJ,EAAzB;AAEA,SAAK2D,WAAL,GAAmBC,IAAI,CAACC,GAAL,EAAnB;AACD;;AAEDC,EAAAA,QAAQ,GAAG;AACT,WAAO,KAAKX,QAAL,IAAiB,KAAKC,QAAL,KAAkB,KAAKD,QAA/C;AACD;;AAED,QAAMY,OAAN,GAAgB;AACd,UAAM,KAAKtC,OAAL,CAAasC,OAAb,EAAN;AACA,SAAKjC,sBAAL,CAA4BkC,IAA5B,CAAiC5D,OAAjC;AACA,UAAM,KAAKqB,OAAL,CAAawC,0BAAb,EAAN;AACD;;AAED,SAAOjD,OAAO,CAACC,IAAf,IAAuB;AACrB,UAAM;AAAES,MAAAA,OAAF;AAAWM,MAAAA,cAAX;AAA2BC,MAAAA;AAA3B,QAAgD,IAAtD;AAEA,SAAKgB,WAAL,GAAmB,MAAM,KAAKxB,OAAL,CAAayC,oBAAb,CAAkC;AAAExC,MAAAA;AAAF,KAAlC,CAAzB;AAEA,UAAMyC,SAAS,GAAG,MAAM,KAAKlB,WAAL,CAAiBmB,SAAjB,CAA2B;AACjD1C,MAAAA,OADiD;AAEjDM,MAAAA,cAFiD;AAGjDC,MAAAA,gBAHiD;AAIjDmB,MAAAA,QAAQ,EAAE,KAAKA,QAAL,IAAiB,EAJsB;AAKjDiB,MAAAA,cAAc,EAAE,KAAKtC,SAAL,CAAeuC,GAAf,CAAmBC,QAAQ,IACzCA,QAAQ,CAACC,QAAT,CAAkB;AAChB7C,QAAAA,MAAM,EAAE,KAAKgB;AADG,OAAlB,CADc;AALiC,KAA3B,CAAxB;AAYA,SAAKO,YAAL,GAAoBiB,SAAS,CAACjB,YAA9B;AACA,SAAKC,QAAL,GAAgBgB,SAAS,CAAChB,QAA1B;AACA,SAAKC,QAAL,GAAgBe,SAAS,CAACf,QAA1B;AACA,SAAKC,OAAL,GAAec,SAAS,CAACd,OAAzB;AACA,SAAKC,aAAL,GAAqBa,SAAS,CAACb,aAA/B;AACD;;AAED,QAAMmB,KAAN,GAAc;AACZ,UAAM;AAAE/C,MAAAA,OAAF;AAAW0B,MAAAA;AAAX,QAAwB,IAA9B;;AACA,QAAIA,QAAJ,EAAc;AACZ,YAAM,KAAKH,WAAL,CAAiByB,UAAjB,CAA4B;AAAEhD,QAAAA,OAAF;AAAW0B,QAAAA;AAAX,OAA5B,CAAN;AACA,WAAKA,QAAL,GAAgB,IAAhB;AACD;AACF;;AAED,SAAOpC,OAAO,CAACG,IAAf,IAAuB;AACrB,QAAIwD,UAAU,GAAG,EAAjB;AACA,UAAM;AACJjD,MAAAA,OADI;AAEJwB,MAAAA,YAFI;AAGJE,MAAAA,QAHI;AAIJC,MAAAA,OAJI;AAKJC,MAAAA,aALI;AAMJ3B,MAAAA,MANI;AAOJgB,MAAAA,gBAPI;AAQJM,MAAAA;AARI,QASF,IATJ;;AAWA,QAAI,KAAKa,QAAL,EAAJ,EAAqB;AACnB,WAAKjC,MAAL,CAAY+C,KAAZ,CAAkB,wBAAlB,EAA4C;AAAElD,QAAAA,OAAF;AAAWwB,QAAAA,YAAX;AAAyBE,QAAAA,QAAzB;AAAmCzB,QAAAA;AAAnC,OAA5C;AACA,YAAM4C,QAAQ,GAAG,KAAKxC,SAAL,CAAe8C,IAAf,CAAoB,CAAC;AAAEC,QAAAA;AAAF,OAAD,KAAcA,IAAI,KAAKxB,aAA3C,CAAjB;;AAEA,UAAI,CAACiB,QAAL,EAAe;AACb,cAAM,IAAI/D,wBAAJ,CACH,mCAAkC8C,aAAc,oDAD7C,CAAN;AAGD;;AAED,YAAM,KAAK7B,OAAL,CAAasD,eAAb,EAAN;AACAJ,MAAAA,UAAU,GAAG,MAAMJ,QAAQ,CAACzB,MAAT,CAAgB;AAAEO,QAAAA,OAAF;AAAW1B,QAAAA,MAAM,EAAEgB;AAAnB,OAAhB,CAAnB;AAEA,WAAKd,MAAL,CAAY+C,KAAZ,CAAkB,kBAAlB,EAAsC;AACpClD,QAAAA,OADoC;AAEpCwB,QAAAA,YAFoC;AAGpCI,QAAAA,aAHoC;AAIpCqB,QAAAA,UAJoC;AAKpChD,QAAAA,MAAM,EAAEgB;AAL4B,OAAtC;AAOD,KAjCoB,CAmCrB;;;AACA,SAAKY,4BAAL,GAAoC,KAAKyB,oCAAL,EAApC;AACA,UAAM;AAAEC,MAAAA;AAAF,QAAuB,MAAM,KAAKhC,WAAL,CAAiBiC,SAAjB,CAA2B;AAC5DxD,MAAAA,OAD4D;AAE5DwB,MAAAA,YAF4D;AAG5DE,MAAAA,QAH4D;AAI5D+B,MAAAA,eAAe,EAAER;AAJ2C,KAA3B,CAAnC;AAOA,UAAMS,uBAAuB,GAAG9E,gBAAgB,CAAC+E,MAAjB,CAAwBJ,gBAAxB,CAAhC;AACA,UAAMK,iBAAiB,GACrBF,uBAAuB,IAAI,IAA3B,GAAkCA,uBAAuB,CAACT,UAA1D,GAAuE,EADzE;AAGA,SAAK9C,MAAL,CAAY+C,KAAZ,CAAkB,qBAAlB,EAAyC;AACvClD,MAAAA,OADuC;AAEvCwB,MAAAA,YAFuC;AAGvCE,MAAAA,QAHuC;AAIvC6B,MAAAA,gBAAgB,EAAEK;AAJqB,KAAzC;AAOA,UAAMC,cAAc,GAAG7E,IAAI,CAAC4E,iBAAD,CAA3B;AACA,UAAME,mBAAmB,GAAG7F,SAAS,CAAC4F,cAAD,EAAiB5C,gBAAjB,CAArC;;AAEA,QAAI6C,mBAAmB,CAACC,MAApB,GAA6B,CAAjC,EAAoC;AAClC,YAAMC,OAAO,GAAG;AACdhE,QAAAA,OADc;AAEdwB,QAAAA,YAFc;AAGdE,QAAAA,QAHc;AAIdmC,QAAAA,cAJc;AAKd5C,QAAAA,gBALc;AAMd6C,QAAAA;AANc,OAAhB;AASA,WAAK1D,sBAAL,CAA4BkC,IAA5B,CAAiC3D,4BAAjC,EAA+DqF,OAA/D;AACA,WAAK7D,MAAL,CAAY8D,IAAZ,CAAiB,6CAAjB,EAAgE,EAC9D,GAAGD,OAD2D;AAE9DE,QAAAA,OAAO,EAAElG,UAAU,CACjB,UADiB,EAEjB,8DAFiB;AAF2C,OAAhE;AAOD,KA5EoB,CA8ErB;;;AACA,UAAMmG,cAAc,GAAGlG,SAAS,CAAC4F,cAAD,EAAiBC,mBAAjB,CAAhC;AACA,UAAMM,uBAAuB,GAAGD,cAAc,CAACvB,GAAf,CAAmByB,KAAK,KAAK;AAC3DA,MAAAA,KAD2D;AAE3DC,MAAAA,UAAU,EAAEV,iBAAiB,CAACS,KAAD;AAF8B,KAAL,CAAxB,CAAhC,CAhFqB,CAqFrB;;AACA,SAAK,MAAMpB,UAAX,IAAyBmB,uBAAzB,EAAkD;AAChD,YAAM;AAAEC,QAAAA,KAAF;AAASC,QAAAA,UAAU,EAAEC;AAArB,UAA4CtB,UAAlD;AACA,YAAMuB,eAAe,GAAG,KAAK3C,4BAAL,CAAkC4C,GAAlC,CAAsCJ,KAAtC,CAAxB;AACA,YAAMK,8BAA8B,GAAGH,kBAAkB,CAACI,KAAnB,CAAyBC,SAAS,IACvEJ,eAAe,CAACK,QAAhB,CAAyBD,SAAzB,CADqC,CAAvC;;AAIA,UAAI,CAACF,8BAAL,EAAqC;AACnC,aAAKvE,MAAL,CAAY8D,IAAZ,CAAiB,uEAAjB,EAA0F;AACxFjE,UAAAA,OADwF;AAExFwB,UAAAA,YAFwF;AAGxFE,UAAAA,QAHwF;AAIxF2C,UAAAA,KAJwF;AAKxFG,UAAAA,eALwF;AAMxFD,UAAAA;AANwF,SAA1F,EADmC,CAUnC;AACA;AACA;;AACA,cAAM,KAAKxE,OAAL,CAAasD,eAAb,EAAN;AACA,aAAKxB,4BAAL,GAAoC,KAAKyB,oCAAL,EAApC;AACA;AACD;AACF;;AAED,SAAKrD,MAAL,GAAcmE,uBAAuB,CAACxB,GAAxB,CAA4B,CAAC;AAAEyB,MAAAA;AAAF,KAAD,KAAeA,KAA3C,CAAd;AACA,SAAKrC,iBAAL,CAAuBZ,MAAvB,CAA8BgD,uBAA9B;AACA,SAAKrC,aAAL,GAAqB,IAAI5D,aAAJ,CAAkB;AACrC4B,MAAAA,OAAO,EAAE,KAAKA,OADuB;AAErCG,MAAAA,mBAAmB,EAAE,KAAKA,mBAFW;AAGrCE,MAAAA,sBAAsB,EAAE,KAAKA,sBAHQ;AAIrCmD,MAAAA,gBAAgB,EAAEa,uBAAuB,CAACU,MAAxB,CAChB,CAACC,iBAAD,EAAoB;AAAEV,QAAAA,KAAF;AAASC,QAAAA;AAAT,OAApB,MAA+C,EAC7C,GAAGS,iBAD0C;AAE7C,SAACV,KAAD,GAASC;AAFoC,OAA/C,CADgB,EAKhB,EALgB,CAJmB;AAWrC1D,MAAAA,kBAAkB,EAAE,KAAKA,kBAXY;AAYrCC,MAAAA,mBAAmB,EAAE,KAAKA,mBAZW;AAarCU,MAAAA,WAbqC;AAcrCvB,MAAAA,OAdqC;AAerCwB,MAAAA,YAfqC;AAgBrCE,MAAAA;AAhBqC,KAAlB,CAArB;AAkBD;;AAEDsD,EAAAA,WAAW,GAAG;AACZ,UAAMC,SAAS,GAAG/C,IAAI,CAACC,GAAL,EAAlB;AACA,WAAO,KAAKhB,OAAL,CAAa,MAAM+D,IAAN,IAAc;AAChC,UAAI;AACF,cAAM,KAAK5F,OAAO,CAACC,IAAb,GAAN;AACA,cAAM,KAAKD,OAAO,CAACG,IAAb,GAAN;AAEA,cAAM8D,gBAAgB,GAAG,KAAK4B,QAAL,GAAgBL,MAAhB,CACvB,CAACM,MAAD,EAAS;AAAEf,UAAAA,KAAF;AAASC,UAAAA;AAAT,SAAT,MAAoC,EAAE,GAAGc,MAAL;AAAa,WAACf,KAAD,GAASC;AAAtB,SAApC,CADuB,EAEvB,EAFuB,CAAzB;AAKA,cAAMN,OAAO,GAAG;AACdhE,UAAAA,OAAO,EAAE,KAAKA,OADA;AAEd0B,UAAAA,QAAQ,EAAE,KAAKA,QAFD;AAGdD,UAAAA,QAAQ,EAAE,KAAKA,QAHD;AAIdW,UAAAA,QAAQ,EAAE,KAAKA,QAAL,EAJI;AAKdmB,UAAAA,gBALc;AAMd3B,UAAAA,aAAa,EAAE,KAAKA,aANN;AAOdyD,UAAAA,QAAQ,EAAEnD,IAAI,CAACC,GAAL,KAAa8C;AAPT,SAAhB;AAUA,aAAK7E,sBAAL,CAA4BkC,IAA5B,CAAiC9D,UAAjC,EAA6CwF,OAA7C;AACA,aAAK7D,MAAL,CAAYmF,IAAZ,CAAiB,+BAAjB,EAAkDtB,OAAlD;AACD,OArBD,CAqBE,OAAO5E,CAAP,EAAU;AACV,YAAID,aAAa,CAACC,CAAD,CAAjB,EAAsB;AACpB;AACA;AACA;AACA;AACA,gBAAM,IAAIP,YAAJ,CAAiBO,CAAjB,CAAN;AACD;;AAED8F,QAAAA,IAAI,CAAC9F,CAAD,CAAJ;AACD;AACF,KAjCM,CAAP;AAkCD;;AAEDmG,EAAAA,WAAW,CAAC;AAAElB,IAAAA,KAAF;AAASO,IAAAA;AAAT,GAAD,EAAuB;AAChC,SAAK7C,aAAL,CAAmBwD,WAAnB,CAA+B;AAAElB,MAAAA,KAAF;AAASO,MAAAA;AAAT,KAA/B;AACD;;AAEDY,EAAAA,aAAa,CAAC;AAAEnB,IAAAA,KAAF;AAASO,IAAAA,SAAT;AAAoBa,IAAAA;AAApB,GAAD,EAA+B;AAC1C,SAAK1D,aAAL,CAAmByD,aAAnB,CAAiC;AAAEnB,MAAAA,KAAF;AAASO,MAAAA,SAAT;AAAoBa,MAAAA;AAApB,KAAjC;AACD;AAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACEC,EAAAA,IAAI,CAAC;AAAErB,IAAAA,KAAF;AAASO,IAAAA,SAAT;AAAoBa,IAAAA;AAApB,GAAD,EAA+B;AACjC,SAAKnE,UAAL,CAAgBqE,GAAhB,CAAoBtB,KAApB,EAA2BO,SAA3B,EAAsCa,MAAtC;AACD;;AAEDG,EAAAA,KAAK,CAACC,eAAD,EAAkB;AACrB,SAAK1F,MAAL,CAAYmF,IAAZ,CAAkB,yBAAwBO,eAAe,CAAC9B,MAAO,SAAjE,EAA2E;AACzE8B,MAAAA;AADyE,KAA3E;AAGA,SAAK7D,iBAAL,CAAuB4D,KAAvB,CAA6BC,eAA7B;AACD;;AAEDC,EAAAA,MAAM,CAACD,eAAD,EAAkB;AACtB,SAAK1F,MAAL,CAAYmF,IAAZ,CAAkB,0BAAyBO,eAAe,CAAC9B,MAAO,SAAlE,EAA4E;AAC1E8B,MAAAA;AAD0E,KAA5E;AAGA,SAAK7D,iBAAL,CAAuB8D,MAAvB,CAA8BD,eAA9B;AACD;;AAEDV,EAAAA,QAAQ,GAAG;AACT,WAAO,KAAKnD,iBAAL,CAAuBmD,QAAvB,EAAP;AACD;;AAEDY,EAAAA,MAAM,GAAG;AACP,WAAO,KAAK/D,iBAAL,CAAuB+D,MAAvB,EAAP;AACD;;AAED,QAAMC,wBAAN,GAAiC;AAC/B,UAAM,KAAKjE,aAAL,CAAmBiE,wBAAnB,EAAN;AACD;;AAED,QAAMC,aAAN,CAAoBC,OAApB,EAA6B;AAC3B,UAAM,KAAKnE,aAAL,CAAmBkE,aAAnB,CAAiCC,OAAjC,CAAN;AACD;;AAEDC,EAAAA,kBAAkB,GAAG;AACnB,WAAO,KAAKpE,aAAL,CAAmBoE,kBAAnB,EAAP;AACD;;AAED,QAAMC,SAAN,CAAgB;AAAEC,IAAAA;AAAF,GAAhB,EAA8B;AAC5B,UAAM;AAAErG,MAAAA,OAAF;AAAWwB,MAAAA,YAAX;AAAyBE,MAAAA;AAAzB,QAAsC,IAA5C;AACA,UAAMS,GAAG,GAAGD,IAAI,CAACC,GAAL,EAAZ;;AAEA,QAAIT,QAAQ,IAAIS,GAAG,IAAI,KAAKF,WAAL,GAAmBoE,QAA1C,EAAoD;AAClD,YAAMrC,OAAO,GAAG;AACdhE,QAAAA,OADc;AAEd0B,QAAAA,QAFc;AAGd4E,QAAAA,iBAAiB,EAAE9E;AAHL,OAAhB;AAMA,YAAM,KAAKD,WAAL,CAAiB6E,SAAjB,CAA2BpC,OAA3B,CAAN;AACA,WAAK5D,sBAAL,CAA4BkC,IAA5B,CAAiC7D,SAAjC,EAA4CuF,OAA5C;AACA,WAAK/B,WAAL,GAAmBC,IAAI,CAACC,GAAL,EAAnB;AACD;AACF;;AAED,QAAMoE,KAAN,GAAc;AACZ,QAAI;AACF,YAAM;AAAEtG,QAAAA,MAAF;AAAUO,QAAAA,oBAAV;AAAgCa,QAAAA,WAAhC;AAA6CZ,QAAAA,QAA7C;AAAuDC,QAAAA;AAAvD,UAAoE,IAA1E;AACA;;AACA,YAAM8F,eAAe,GAAG,EAAxB;AAEA,YAAM,KAAKzG,OAAL,CAAawC,0BAAb,EAAN;AACA,WAAKkE,uBAAL;;AAEA,aAAO,KAAKnF,UAAL,CAAgBoF,IAAhB,GAAuB,CAA9B,EAAiC;AAC/B,cAAMC,SAAS,GAAG,KAAKrF,UAAL,CAAgBsF,GAAhB,EAAlB;AACA,aAAKzG,MAAL,CAAY+C,KAAZ,CAAkB,aAAlB,EAAiC;AAC/BlD,UAAAA,OAAO,EAAE,KAAKA,OADiB;AAE/B0B,UAAAA,QAAQ,EAAE,KAAKA,QAFgB;AAG/BgE,UAAAA,IAAI,EAAEiB;AAHyB,SAAjC;AAKA,cAAM,KAAK5E,aAAL,CAAmB2D,IAAnB,CAAwBiB,SAAxB,CAAN;AACD;;AAED,YAAME,qBAAqB,GAAG,KAAK7E,iBAAL,CAAuB+D,MAAvB,EAA9B;AACA,YAAMe,qBAAqB,GAAG,KAAK9E,iBAAL,CAAuB+E,MAAvB,EAA9B;AAEA,YAAMC,gBAAgB,GAAGpJ,OAAO,CAACkJ,qBAAqB,CAAClE,GAAtB,CAA0B,CAAC;AAAE0B,QAAAA;AAAF,OAAD,KAAoBA,UAA9C,CAAD,CAAhC;AACA,YAAM2C,YAAY,GAAGH,qBAAqB,CACvCI,MADkB,CACX,CAAC;AAAE5C,QAAAA;AAAF,OAAD,KAAoBA,UAAU,CAACP,MAAX,GAAoB,CAD7B,EAElBnB,GAFkB,CAEd,CAAC;AAAEyB,QAAAA;AAAF,OAAD,KAAeA,KAFD,CAArB;;AAIA,UAAI2C,gBAAgB,CAACjD,MAAjB,KAA4B,CAAhC,EAAmC;AACjC,aAAK5D,MAAL,CAAY+C,KAAZ,CAAmB,4CAA2C,KAAK7B,WAAY,IAA/E,EAAoF;AAClFpB,UAAAA,MADkF;AAElF6G,UAAAA,qBAFkF;AAGlFD,UAAAA;AAHkF,SAApF;AAMA,cAAM/I,KAAK,CAAC,KAAKuD,WAAN,CAAX;AACA,eAAOtD,qBAAqB,CAAC,EAAD,CAA5B;AACD;;AAED,YAAM,KAAKgE,aAAL,CAAmBoF,cAAnB,EAAN;AAEA,WAAKhH,MAAL,CAAY+C,KAAZ,CACG,iBAAgB8D,gBAAgB,CAACjD,MAAO,mBAAkBkD,YAAY,CAAClD,MAAO,WAAU9D,MAAM,CAAC8D,MAAO,SADzG,EAEE;AACE9D,QAAAA,MADF;AAEE6G,QAAAA,qBAFF;AAGED,QAAAA;AAHF,OAFF;;AASA,WAAK,MAAMO,cAAX,IAA6BN,qBAA7B,EAAoD;AAClD,cAAMO,iBAAiB,GAAG,KAAKC,4BAAL,CACxBF,cAAc,CAAC/C,KADS,EAExB+C,cAAc,CAAC9C,UAFS,CAA1B;AAKA,cAAMiD,OAAO,GAAGvI,IAAI,CAACqI,iBAAD,CAApB;AACA,cAAMG,gBAAgB,GAAG,KAAKzF,aAAL,CAAmByF,gBAAnB,EAAzB;;AAEA,aAAK,MAAMC,MAAX,IAAqBF,OAArB,EAA8B;AAC5B,gBAAMjD,UAAU,GAAG+C,iBAAiB,CAACI,MAAD,CAAjB,CAChBP,MADgB,CACTtC,SAAS,IAAI;AACnB;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACc,mBAAO4C,gBAAgB,CAACJ,cAAc,CAAC/C,KAAhB,CAAhB,CAAuCO,SAAvC,KAAqD,IAA5D;AACD,WAjBgB,EAkBhBhC,GAlBgB,CAkBZgC,SAAS,KAAK;AACjBA,YAAAA,SADiB;AAEjB8C,YAAAA,WAAW,EAAE,KAAK3F,aAAL,CACV4F,UADU,CACCP,cAAc,CAAC/C,KADhB,EACuBO,SADvB,EAEVgD,QAFU,EAFI;AAKjBlH,YAAAA,QAAQ,EAAEF;AALO,WAAL,CAlBG,CAAnB;AA0BAgG,UAAAA,eAAe,CAACiB,MAAD,CAAf,GAA0BjB,eAAe,CAACiB,MAAD,CAAf,IAA2B,EAArD;AACAjB,UAAAA,eAAe,CAACiB,MAAD,CAAf,CAAwBI,IAAxB,CAA6B;AAAExD,YAAAA,KAAK,EAAE+C,cAAc,CAAC/C,KAAxB;AAA+BC,YAAAA;AAA/B,WAA7B;AACD;AACF;;AAED,YAAMwD,QAAQ,GAAG9I,IAAI,CAACwH,eAAD,CAAJ,CAAsB5D,GAAtB,CAA0B,MAAM6E,MAAN,IAAgB;AACzD,cAAMM,MAAM,GAAG,MAAM,KAAKhI,OAAL,CAAaiI,UAAb,CAAwB;AAAEP,UAAAA;AAAF,SAAxB,CAArB;AACA,cAAM;AAAEQ,UAAAA;AAAF,YAAgB,MAAMF,MAAM,CAACxB,KAAP,CAAa;AACvClF,UAAAA,WADuC;AAEvCZ,UAAAA,QAFuC;AAGvCC,UAAAA,QAHuC;AAIvCI,UAAAA,cAAc,EAAE,KAAKA,cAJkB;AAKvCb,UAAAA,MAAM,EAAEuG,eAAe,CAACiB,MAAD,CALgB;AAMvC1G,UAAAA,MAAM,EAAE,KAAKA;AAN0B,SAAb,CAA5B;AASA,cAAMmH,mBAAmB,GAAGD,SAAS,CAACrF,GAAV,CAAc,CAAC;AAAEuF,UAAAA,SAAF;AAAa7D,UAAAA;AAAb,SAAD,KAA+B;AACvE,gBAAM8D,gBAAgB,GAAG5B,eAAe,CAACiB,MAAD,CAAf,CAAwBtE,IAAxB,CAA6B,CAAC;AAAEkB,YAAAA;AAAF,WAAD,KAAeA,KAAK,KAAK8D,SAAtD,CAAzB;AACA,cAAIE,qBAAqB,GAAG,KAAKvG,sCAAL,CAA4CqG,SAA5C,CAA5B;;AACA,cAAI,CAACE,qBAAL,EAA4B;AAC1B,iBAAKvG,sCAAL,CAA4CqG,SAA5C,IAAyDE,qBAAqB,GAAG,EAAjF;AACD;;AAED,iBAAO/D,UAAU,CACd4C,MADI,CAEHoB,aAAa,IACX,CAAC,KAAKhH,UAAL,CAAgBiH,GAAhB,CAAoBJ,SAApB,EAA+BG,aAAa,CAAC1D,SAA7C,CAAD,IACA,CAAC,KAAK5C,iBAAL,CAAuBwG,QAAvB,CAAgCL,SAAhC,EAA2CG,aAAa,CAAC1D,SAAzD,CAJA,EAMJhC,GANI,CAMA0F,aAAa,IAAI;AACpB,kBAAM;AAAE1D,cAAAA,SAAF;AAAa6D,cAAAA;AAAb,gBAAsCH,aAA5C;;AACA,gBAAIG,oBAAoB,IAAI,IAAxB,IAAgCA,oBAAoB,KAAK,CAAC,CAA9D,EAAiE;AAC/D,oBAAM;AAAEhB,gBAAAA,MAAM,EAAEiB;AAAV,kBACJL,qBAAqB,CAACzD,SAAD,CAArB,IAAoC,EADtC;;AAEA,kBAAI8D,2BAA2B,KAAKD,oBAApC,EAA0D;AACxD,qBAAKtI,MAAL,CAAYmF,IAAZ,CAAkB,iCAAgCmD,oBAAqB,EAAvE,EAA0E;AACxEzI,kBAAAA,OAAO,EAAE,KAAKA,OAD0D;AAExE0B,kBAAAA,QAAQ,EAAE,KAAKA,QAFyD;AAGxE2C,kBAAAA,KAAK,EAAE8D,SAHiE;AAIxEvD,kBAAAA;AAJwE,iBAA1E;AAMD;;AACDyD,cAAAA,qBAAqB,CAACzD,SAAD,CAArB,GAAmC;AACjC6C,gBAAAA,MAAM,EAAEgB,oBADyB;AAEjCE,gBAAAA,QAAQ,EAAEzG,IAAI,CAACC,GAAL,KAAa,KAAKnB;AAFK,eAAnC;AAID;;AAED,kBAAM4H,oBAAoB,GAAGR,gBAAgB,CAAC9D,UAAjB,CAA4BnB,IAA5B,CAC3B,CAAC;AAAEyB,cAAAA;AAAF,aAAD,KAAmBA,SAAS,KAAK0D,aAAa,CAAC1D,SADpB,CAA7B;AAIA,kBAAMiE,aAAa,GAAGD,oBAAoB,CAAClB,WAA3C;AACA,kBAAMoB,KAAK,GAAG,IAAI1K,KAAJ,CAAU+J,SAAV,EAAqBU,aAArB,EAAoCP,aAApC,CAAd;AAEA;AACd;AACA;AACA;AACA;AACA;;AACc,gBAAIQ,KAAK,CAACC,oBAAN,MAAgCD,KAAK,CAACE,gCAAN,EAApC,EAA8E;AAC5E,mBAAKxD,aAAL,CAAmB;AACjBnB,gBAAAA,KAAK,EAAEyE,KAAK,CAACzE,KADI;AAEjBO,gBAAAA,SAAS,EAAEkE,KAAK,CAAClE,SAFA;AAGjBa,gBAAAA,MAAM,EAAEqD,KAAK,CAACG,UAAN;AAHS,eAAnB;AAKD;;AAED,mBAAOH,KAAP;AACD,WA/CI,CAAP;AAgDD,SAvD2B,CAA5B;AAyDA,eAAOlL,OAAO,CAACsK,mBAAD,CAAd;AACD,OArEgB,CAAjB,CAzFE,CAgKF;AACA;AACA;;AACA,UAAIJ,QAAQ,CAAC/D,MAAT,KAAoB,CAAxB,EAA2B;AACzB,cAAMjG,KAAK,CAAC,KAAKuD,WAAN,CAAX;AACA,eAAOtD,qBAAqB,CAAC,EAAD,CAA5B;AACD;;AAED,aAAOA,qBAAqB,CAAC+J,QAAD,EAAW1I,CAAC,IAAI,KAAK8J,gBAAL,CAAsB9J,CAAtB,CAAhB,CAA5B;AACD,KAzKD,CAyKE,OAAOA,CAAP,EAAU;AACV,YAAM,KAAK8J,gBAAL,CAAsB9J,CAAtB,CAAN;AACD;AACF;;AAED,QAAM8J,gBAAN,CAAuB9J,CAAvB,EAA0B;AACxB,QAAIF,qBAAqB,CAAC2F,QAAtB,CAA+BzF,CAAC,CAACC,IAAjC,KAA0CD,CAAC,CAACgE,IAAF,KAAW,+BAAzD,EAA0F;AACxF,WAAKjD,MAAL,CAAY+C,KAAZ,CAAkB,uCAAlB,EAA2D;AACzDlD,QAAAA,OAAO,EAAE,KAAKA,OAD2C;AAEzD0B,QAAAA,QAAQ,EAAE,KAAKA,QAF0C;AAGzDyH,QAAAA,KAAK,EAAE/J,CAAC,CAACgK;AAHgD,OAA3D;AAMA,YAAM,KAAKrJ,OAAL,CAAasD,eAAb,EAAN;AACA,YAAM,KAAK2B,WAAL,EAAN;AACA,YAAM,IAAInG,YAAJ,CAAiBO,CAAC,CAACgK,OAAnB,CAAN;AACD;;AAED,QAAIhK,CAAC,CAACgE,IAAF,KAAW,qCAAf,EAAsD;AACpD,WAAKjD,MAAL,CAAY8D,IAAZ,CAAkB,GAAE7E,CAAC,CAACgK,OAAQ,gBAA9B,EAA+C;AAC7CpJ,QAAAA,OAAO,EAAE,KAAKA,OAD+B;AAE7C0B,QAAAA,QAAQ,EAAE,KAAKA,QAF8B;AAG7C2C,QAAAA,KAAK,EAAEjF,CAAC,CAACiF,KAHoC;AAI7CgF,QAAAA,iBAAiB,EAAEjK,CAAC,CAACiK;AAJwB,OAA/C;AAOA,YAAM,KAAKrE,WAAL,EAAN;AACD;;AAED,QAAI5F,CAAC,CAACgE,IAAF,KAAW,yBAAf,EAA0C;AACxC,YAAM,KAAKkG,2BAAL,CAAiClK,CAAjC,CAAN;AACD;;AAED,QAAIA,CAAC,CAACgE,IAAF,KAAW,8BAAf,EAA+C;AAC7C,WAAKrD,OAAL,CAAawJ,YAAb,CAA0B;AAAEC,QAAAA,IAAI,EAAEpK,CAAC,CAACoK,IAAV;AAAgBC,QAAAA,IAAI,EAAErK,CAAC,CAACqK;AAAxB,OAA1B;AACD;;AAED,QAAIrK,CAAC,CAACgE,IAAF,KAAW,uBAAX,IAAsChE,CAAC,CAACgE,IAAF,KAAW,8BAArD,EAAqF;AACnF,WAAKjD,MAAL,CAAY+C,KAAZ,CAAmB,GAAE9D,CAAC,CAACgK,OAAQ,uCAA/B;AACA,YAAM,KAAKrJ,OAAL,CAAasD,eAAb,EAAN;AACD;;AAED,UAAMjE,CAAN;AACD;;AAED,QAAMkK,2BAAN,CAAkClK,CAAlC,EAAqC;AACnC;AACA,UAAMiJ,qBAAqB,GAAG,KAAKvG,sCAAL,CAA4C1C,CAAC,CAACiF,KAA9C,CAA9B;;AACA,QAAIgE,qBAAqB,IAAI,OAAOA,qBAAqB,CAACjJ,CAAC,CAACwF,SAAH,CAA5B,KAA8C,QAA3E,EAAqF;AACnF,WAAKzE,MAAL,CAAYmF,IAAZ,CAAiB,wEAAjB,EAA2F;AACzFjB,QAAAA,KAAK,EAAEjF,CAAC,CAACiF,KADgF;AAEzFO,QAAAA,SAAS,EAAExF,CAAC,CAACwF,SAF4E;AAGzF5E,QAAAA,OAAO,EAAE,KAAKA,OAH2E;AAIzF0B,QAAAA,QAAQ,EAAE,KAAKA;AAJ0E,OAA3F;AAMA,aAAO2G,qBAAqB,CAACjJ,CAAC,CAACwF,SAAH,CAA5B;AACD,KARD,MAQO;AACL,WAAKzE,MAAL,CAAYgJ,KAAZ,CAAkB,kDAAlB,EAAsE;AACpE9E,QAAAA,KAAK,EAAEjF,CAAC,CAACiF,KAD2D;AAEpEO,QAAAA,SAAS,EAAExF,CAAC,CAACwF,SAFuD;AAGpE5E,QAAAA,OAAO,EAAE,KAAKA,OAHsD;AAIpE0B,QAAAA,QAAQ,EAAE,KAAKA;AAJqD,OAAtE;AAOA,YAAM,KAAKK,aAAL,CAAmB2H,gBAAnB,CAAoC;AACxCrF,QAAAA,KAAK,EAAEjF,CAAC,CAACiF,KAD+B;AAExCO,QAAAA,SAAS,EAAExF,CAAC,CAACwF;AAF2B,OAApC,CAAN;AAID;AACF;;AAEDtB,EAAAA,oCAAoC,GAAG;AACrC,UAAMV,GAAG,GAAG,IAAI+G,GAAJ,EAAZ;;AAEA,SAAK,MAAMtF,KAAX,IAAoB,KAAKpD,gBAAzB,EAA2C;AACzC,YAAMqD,UAAU,GAAG,KAAKvE,OAAL,CAChB6J,0BADgB,CACWvF,KADX,EAEhBzB,GAFgB,CAEZiH,CAAC,IAAIA,CAAC,CAACC,WAFK,EAGhBC,IAHgB,EAAnB;AAKAnH,MAAAA,GAAG,CAAC+C,GAAJ,CAAQtB,KAAR,EAAeC,UAAf;AACD;;AAED,WAAO1B,GAAP;AACD;;AAED6D,EAAAA,uBAAuB,GAAG;AACxB,QAAI,CAAC,KAAK5E,4BAAV,EAAwC;AACtC;AACD;;AAED,UAAMmI,+BAA+B,GAAG,KAAK1G,oCAAL,EAAxC;;AAEA,SAAK,MAAM,CAACe,KAAD,EAAQC,UAAR,CAAX,IAAkC0F,+BAAlC,EAAmE;AACjE,YAAMC,IAAI,GAAGhM,SAAS,CAACqG,UAAD,EAAa,KAAKzC,4BAAL,CAAkC4C,GAAlC,CAAsCJ,KAAtC,CAAb,CAAtB;;AAEA,UAAI4F,IAAI,CAAClG,MAAL,GAAc,CAAlB,EAAqB;AACnB,cAAM,IAAIhF,mCAAJ,CAAwC,wBAAxC,EAAkE;AACtEsF,UAAAA,KADsE;AAEtEgF,UAAAA,iBAAiB,EAAEY;AAFmD,SAAlE,CAAN;AAID;AACF;AACF;;AAEDC,EAAAA,aAAa,CAAC;AAAE7F,IAAAA,KAAF;AAASO,IAAAA;AAAT,GAAD,EAAuB;AAClC,WAAO,KAAKtD,UAAL,CAAgBiH,GAAhB,CAAoBlE,KAApB,EAA2BO,SAA3B,CAAP;AACD;AAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACE;;;AACA0C,EAAAA,4BAA4B,CAACjD,KAAD,EAAQC,UAAR,EAAoB;AAC9C,UAAM6F,iBAAiB,GAAG,KAAKpK,OAAL,CAAa6J,0BAAb,CAAwCvF,KAAxC,CAA1B;AACA,UAAMgE,qBAAqB,GAAG,KAAKvG,sCAAL,CAA4CuC,KAA5C,CAA9B;AACA,WAAOC,UAAU,CAACQ,MAAX,CAAkB,CAACM,MAAD,EAASgF,EAAT,KAAgB;AACvC,YAAMN,WAAW,GAAGO,QAAQ,CAACD,EAAD,EAAK,EAAL,CAA5B;AACA,YAAME,QAAQ,GAAGH,iBAAiB,CAAChH,IAAlB,CAAuBoH,CAAC,IAAIA,CAAC,CAACT,WAAF,KAAkBA,WAA9C,CAAjB;;AACA,UAAI,CAACQ,QAAL,EAAe;AACb,eAAOlF,MAAP;AACD;;AAED,UAAIkF,QAAQ,CAACE,MAAT,IAAmB,IAAvB,EAA6B;AAC3B,cAAM,IAAI3L,YAAJ,CAAiB,4BAAjB,EAA+C;AAAEwF,UAAAA,KAAF;AAASyF,UAAAA,WAAT;AAAsBQ,UAAAA;AAAtB,SAA/C,CAAN;AACD,OATsC,CAWvC;;;AACA,UAAI7C,MAAM,GAAG6C,QAAQ,CAACE,MAAtB;;AACA,UAAInC,qBAAJ,EAA2B;AACzB,cAAM;AAAEZ,UAAAA,MAAM,EAAEgB,oBAAV;AAAgCE,UAAAA;AAAhC,YAA6CN,qBAAqB,CAACyB,WAAD,CAArB,IAAsC,EAAzF;;AACA,YAAI5H,IAAI,CAACC,GAAL,MAAcwG,QAAlB,EAA4B;AAC1B,eAAKxI,MAAL,CAAY+C,KAAZ,CAAkB,8DAAlB,EAAkF;AAChFmB,YAAAA,KADgF;AAEhFyF,YAAAA,WAFgF;AAGhF9J,YAAAA,OAAO,EAAE,KAAKA,OAHkE;AAIhF0B,YAAAA,QAAQ,EAAE,KAAKA,QAJiE;AAKhF+G,YAAAA,oBALgF;AAMhF+B,YAAAA,MAAM,EAAEF,QAAQ,CAACE;AAN+D,WAAlF,EAD0B,CAS1B;;AACA,iBAAOnC,qBAAqB,CAACyB,WAAD,CAA5B;AACD,SAXD,MAWO,IAAIrB,oBAAoB,IAAI,IAA5B,EAAkC;AACvC;AACA;AACA,gBAAMgC,eAAe,GAAGH,QAAQ,CAACG,eAAjC;;AACA,cAAIC,KAAK,CAACC,OAAN,CAAcF,eAAd,KAAkCA,eAAe,CAAC5F,QAAhB,CAAyB4C,MAAzB,CAAtC,EAAwE;AACtE,iBAAKtH,MAAL,CAAY+C,KAAZ,CAAkB,iDAAlB,EAAqE;AACnEmB,cAAAA,KADmE;AAEnEyF,cAAAA,WAFmE;AAGnE9J,cAAAA,OAAO,EAAE,KAAKA,OAHqD;AAInE0B,cAAAA,QAAQ,EAAE,KAAKA,QAJoD;AAKnE+G,cAAAA,oBALmE;AAMnE+B,cAAAA,MAAM,EAAEF,QAAQ,CAACE;AANkD,aAArE;AAQD,WATD,MASO;AACL/C,YAAAA,MAAM,GAAGgB,oBAAT;AACD;AACF;AACF;;AACD,YAAMmC,OAAO,GAAGxF,MAAM,CAACqC,MAAD,CAAN,IAAkB,EAAlC;AACA,aAAO,EAAE,GAAGrC,MAAL;AAAa,SAACqC,MAAD,GAAU,CAAC,GAAGmD,OAAJ,EAAad,WAAb;AAAvB,OAAP;AACD,KA9CM,EA8CJ,EA9CI,CAAP;AA+CD;;AAprBkC,CAArC","sourcesContent":["const flatten = require('../utils/flatten')\nconst sleep = require('../utils/sleep')\nconst BufferedAsyncIterator = require('../utils/bufferedAsyncIterator')\nconst websiteUrl = require('../utils/websiteUrl')\nconst arrayDiff = require('../utils/arrayDiff')\nconst createRetry = require('../retry')\n\nconst OffsetManager = require('./offsetManager')\nconst Batch = require('./batch')\nconst SeekOffsets = require('./seekOffsets')\nconst SubscriptionState = require('./subscriptionState')\nconst {\n  events: { GROUP_JOIN, HEARTBEAT, CONNECT, RECEIVED_UNSUBSCRIBED_TOPICS },\n} = require('./instrumentationEvents')\nconst { MemberAssignment } = require('./assignerProtocol')\nconst {\n  KafkaJSError,\n  KafkaJSNonRetriableError,\n  KafkaJSStaleTopicMetadataAssignment,\n} = require('../errors')\n\nconst { keys } = Object\n\nconst STALE_METADATA_ERRORS = [\n  'LEADER_NOT_AVAILABLE',\n  // Fetch before v9 uses NOT_LEADER_FOR_PARTITION\n  'NOT_LEADER_FOR_PARTITION',\n  // Fetch after v9 uses {FENCED,UNKNOWN}_LEADER_EPOCH\n  'FENCED_LEADER_EPOCH',\n  'UNKNOWN_LEADER_EPOCH',\n  'UNKNOWN_TOPIC_OR_PARTITION',\n]\n\nconst isRebalancing = e =>\n  e.type === 'REBALANCE_IN_PROGRESS' || e.type === 'NOT_COORDINATOR_FOR_GROUP'\n\nconst PRIVATE = {\n  JOIN: Symbol('private:ConsumerGroup:join'),\n  SYNC: Symbol('private:ConsumerGroup:sync'),\n}\n\nmodule.exports = class ConsumerGroup {\n  constructor({\n    retry,\n    cluster,\n    groupId,\n    topics,\n    topicConfigurations,\n    logger,\n    instrumentationEmitter,\n    assigners,\n    sessionTimeout,\n    rebalanceTimeout,\n    maxBytesPerPartition,\n    minBytes,\n    maxBytes,\n    maxWaitTimeInMs,\n    autoCommitInterval,\n    autoCommitThreshold,\n    isolationLevel,\n    rackId,\n    metadataMaxAge,\n  }) {\n    /** @type {import(\"../../types\").Cluster} */\n    this.cluster = cluster\n    this.groupId = groupId\n    this.topics = topics\n    this.topicsSubscribed = topics\n    this.topicConfigurations = topicConfigurations\n    this.logger = logger.namespace('ConsumerGroup')\n    this.instrumentationEmitter = instrumentationEmitter\n    this.retrier = createRetry(Object.assign({}, retry))\n    this.assigners = assigners\n    this.sessionTimeout = sessionTimeout\n    this.rebalanceTimeout = rebalanceTimeout\n    this.maxBytesPerPartition = maxBytesPerPartition\n    this.minBytes = minBytes\n    this.maxBytes = maxBytes\n    this.maxWaitTime = maxWaitTimeInMs\n    this.autoCommitInterval = autoCommitInterval\n    this.autoCommitThreshold = autoCommitThreshold\n    this.isolationLevel = isolationLevel\n    this.rackId = rackId\n    this.metadataMaxAge = metadataMaxAge\n\n    this.seekOffset = new SeekOffsets()\n    this.coordinator = null\n    this.generationId = null\n    this.leaderId = null\n    this.memberId = null\n    this.members = null\n    this.groupProtocol = null\n\n    this.partitionsPerSubscribedTopic = null\n    /**\n     * Preferred read replica per topic and partition\n     *\n     * Each of the partitions tracks the preferred read replica (`nodeId`) and a timestamp\n     * until when that preference is valid.\n     *\n     * @type {{[topicName: string]: {[partition: number]: {nodeId: number, expireAt: number}}}}\n     */\n    this.preferredReadReplicasPerTopicPartition = {}\n    this.offsetManager = null\n    this.subscriptionState = new SubscriptionState()\n\n    this.lastRequest = Date.now()\n  }\n\n  isLeader() {\n    return this.leaderId && this.memberId === this.leaderId\n  }\n\n  async connect() {\n    await this.cluster.connect()\n    this.instrumentationEmitter.emit(CONNECT)\n    await this.cluster.refreshMetadataIfNecessary()\n  }\n\n  async [PRIVATE.JOIN]() {\n    const { groupId, sessionTimeout, rebalanceTimeout } = this\n\n    this.coordinator = await this.cluster.findGroupCoordinator({ groupId })\n\n    const groupData = await this.coordinator.joinGroup({\n      groupId,\n      sessionTimeout,\n      rebalanceTimeout,\n      memberId: this.memberId || '',\n      groupProtocols: this.assigners.map(assigner =>\n        assigner.protocol({\n          topics: this.topicsSubscribed,\n        })\n      ),\n    })\n\n    this.generationId = groupData.generationId\n    this.leaderId = groupData.leaderId\n    this.memberId = groupData.memberId\n    this.members = groupData.members\n    this.groupProtocol = groupData.groupProtocol\n  }\n\n  async leave() {\n    const { groupId, memberId } = this\n    if (memberId) {\n      await this.coordinator.leaveGroup({ groupId, memberId })\n      this.memberId = null\n    }\n  }\n\n  async [PRIVATE.SYNC]() {\n    let assignment = []\n    const {\n      groupId,\n      generationId,\n      memberId,\n      members,\n      groupProtocol,\n      topics,\n      topicsSubscribed,\n      coordinator,\n    } = this\n\n    if (this.isLeader()) {\n      this.logger.debug('Chosen as group leader', { groupId, generationId, memberId, topics })\n      const assigner = this.assigners.find(({ name }) => name === groupProtocol)\n\n      if (!assigner) {\n        throw new KafkaJSNonRetriableError(\n          `Unsupported partition assigner \"${groupProtocol}\", the assigner wasn't found in the assigners list`\n        )\n      }\n\n      await this.cluster.refreshMetadata()\n      assignment = await assigner.assign({ members, topics: topicsSubscribed })\n\n      this.logger.debug('Group assignment', {\n        groupId,\n        generationId,\n        groupProtocol,\n        assignment,\n        topics: topicsSubscribed,\n      })\n    }\n\n    // Keep track of the partitions for the subscribed topics\n    this.partitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic()\n    const { memberAssignment } = await this.coordinator.syncGroup({\n      groupId,\n      generationId,\n      memberId,\n      groupAssignment: assignment,\n    })\n\n    const decodedMemberAssignment = MemberAssignment.decode(memberAssignment)\n    const decodedAssignment =\n      decodedMemberAssignment != null ? decodedMemberAssignment.assignment : {}\n\n    this.logger.debug('Received assignment', {\n      groupId,\n      generationId,\n      memberId,\n      memberAssignment: decodedAssignment,\n    })\n\n    const assignedTopics = keys(decodedAssignment)\n    const topicsNotSubscribed = arrayDiff(assignedTopics, topicsSubscribed)\n\n    if (topicsNotSubscribed.length > 0) {\n      const payload = {\n        groupId,\n        generationId,\n        memberId,\n        assignedTopics,\n        topicsSubscribed,\n        topicsNotSubscribed,\n      }\n\n      this.instrumentationEmitter.emit(RECEIVED_UNSUBSCRIBED_TOPICS, payload)\n      this.logger.warn('Consumer group received unsubscribed topics', {\n        ...payload,\n        helpUrl: websiteUrl(\n          'docs/faq',\n          'why-am-i-receiving-messages-for-topics-i-m-not-subscribed-to'\n        ),\n      })\n    }\n\n    // Remove unsubscribed topics from the list\n    const safeAssignment = arrayDiff(assignedTopics, topicsNotSubscribed)\n    const currentMemberAssignment = safeAssignment.map(topic => ({\n      topic,\n      partitions: decodedAssignment[topic],\n    }))\n\n    // Check if the consumer is aware of all assigned partitions\n    for (const assignment of currentMemberAssignment) {\n      const { topic, partitions: assignedPartitions } = assignment\n      const knownPartitions = this.partitionsPerSubscribedTopic.get(topic)\n      const isAwareOfAllAssignedPartitions = assignedPartitions.every(partition =>\n        knownPartitions.includes(partition)\n      )\n\n      if (!isAwareOfAllAssignedPartitions) {\n        this.logger.warn('Consumer is not aware of all assigned partitions, refreshing metadata', {\n          groupId,\n          generationId,\n          memberId,\n          topic,\n          knownPartitions,\n          assignedPartitions,\n        })\n\n        // If the consumer is not aware of all assigned partitions, refresh metadata\n        // and update the list of partitions per subscribed topic. It's enough to perform\n        // this operation once since refresh metadata will update metadata for all topics\n        await this.cluster.refreshMetadata()\n        this.partitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic()\n        break\n      }\n    }\n\n    this.topics = currentMemberAssignment.map(({ topic }) => topic)\n    this.subscriptionState.assign(currentMemberAssignment)\n    this.offsetManager = new OffsetManager({\n      cluster: this.cluster,\n      topicConfigurations: this.topicConfigurations,\n      instrumentationEmitter: this.instrumentationEmitter,\n      memberAssignment: currentMemberAssignment.reduce(\n        (partitionsByTopic, { topic, partitions }) => ({\n          ...partitionsByTopic,\n          [topic]: partitions,\n        }),\n        {}\n      ),\n      autoCommitInterval: this.autoCommitInterval,\n      autoCommitThreshold: this.autoCommitThreshold,\n      coordinator,\n      groupId,\n      generationId,\n      memberId,\n    })\n  }\n\n  joinAndSync() {\n    const startJoin = Date.now()\n    return this.retrier(async bail => {\n      try {\n        await this[PRIVATE.JOIN]()\n        await this[PRIVATE.SYNC]()\n\n        const memberAssignment = this.assigned().reduce(\n          (result, { topic, partitions }) => ({ ...result, [topic]: partitions }),\n          {}\n        )\n\n        const payload = {\n          groupId: this.groupId,\n          memberId: this.memberId,\n          leaderId: this.leaderId,\n          isLeader: this.isLeader(),\n          memberAssignment,\n          groupProtocol: this.groupProtocol,\n          duration: Date.now() - startJoin,\n        }\n\n        this.instrumentationEmitter.emit(GROUP_JOIN, payload)\n        this.logger.info('Consumer has joined the group', payload)\n      } catch (e) {\n        if (isRebalancing(e)) {\n          // Rebalance in progress isn't a retriable protocol error since the consumer\n          // has to go through find coordinator and join again before it can\n          // actually retry the operation. We wrap the original error in a retriable error\n          // here instead in order to restart the join + sync sequence using the retrier.\n          throw new KafkaJSError(e)\n        }\n\n        bail(e)\n      }\n    })\n  }\n\n  resetOffset({ topic, partition }) {\n    this.offsetManager.resetOffset({ topic, partition })\n  }\n\n  resolveOffset({ topic, partition, offset }) {\n    this.offsetManager.resolveOffset({ topic, partition, offset })\n  }\n\n  /**\n   * Update the consumer offset for the given topic/partition. This will be used\n   * on the next fetch. If this API is invoked for the same topic/partition more\n   * than once, the latest offset will be used on the next fetch.\n   *\n   * @param {string} topic\n   * @param {number} partition\n   * @param {string} offset\n   */\n  seek({ topic, partition, offset }) {\n    this.seekOffset.set(topic, partition, offset)\n  }\n\n  pause(topicPartitions) {\n    this.logger.info(`Pausing fetching from ${topicPartitions.length} topics`, {\n      topicPartitions,\n    })\n    this.subscriptionState.pause(topicPartitions)\n  }\n\n  resume(topicPartitions) {\n    this.logger.info(`Resuming fetching from ${topicPartitions.length} topics`, {\n      topicPartitions,\n    })\n    this.subscriptionState.resume(topicPartitions)\n  }\n\n  assigned() {\n    return this.subscriptionState.assigned()\n  }\n\n  paused() {\n    return this.subscriptionState.paused()\n  }\n\n  async commitOffsetsIfNecessary() {\n    await this.offsetManager.commitOffsetsIfNecessary()\n  }\n\n  async commitOffsets(offsets) {\n    await this.offsetManager.commitOffsets(offsets)\n  }\n\n  uncommittedOffsets() {\n    return this.offsetManager.uncommittedOffsets()\n  }\n\n  async heartbeat({ interval }) {\n    const { groupId, generationId, memberId } = this\n    const now = Date.now()\n\n    if (memberId && now >= this.lastRequest + interval) {\n      const payload = {\n        groupId,\n        memberId,\n        groupGenerationId: generationId,\n      }\n\n      await this.coordinator.heartbeat(payload)\n      this.instrumentationEmitter.emit(HEARTBEAT, payload)\n      this.lastRequest = Date.now()\n    }\n  }\n\n  async fetch() {\n    try {\n      const { topics, maxBytesPerPartition, maxWaitTime, minBytes, maxBytes } = this\n      /** @type {{[nodeId: string]: {topic: string, partitions: { partition: number; fetchOffset: string; maxBytes: number }[]}[]}} */\n      const requestsPerNode = {}\n\n      await this.cluster.refreshMetadataIfNecessary()\n      this.checkForStaleAssignment()\n\n      while (this.seekOffset.size > 0) {\n        const seekEntry = this.seekOffset.pop()\n        this.logger.debug('Seek offset', {\n          groupId: this.groupId,\n          memberId: this.memberId,\n          seek: seekEntry,\n        })\n        await this.offsetManager.seek(seekEntry)\n      }\n\n      const pausedTopicPartitions = this.subscriptionState.paused()\n      const activeTopicPartitions = this.subscriptionState.active()\n\n      const activePartitions = flatten(activeTopicPartitions.map(({ partitions }) => partitions))\n      const activeTopics = activeTopicPartitions\n        .filter(({ partitions }) => partitions.length > 0)\n        .map(({ topic }) => topic)\n\n      if (activePartitions.length === 0) {\n        this.logger.debug(`No active topic partitions, sleeping for ${this.maxWaitTime}ms`, {\n          topics,\n          activeTopicPartitions,\n          pausedTopicPartitions,\n        })\n\n        await sleep(this.maxWaitTime)\n        return BufferedAsyncIterator([])\n      }\n\n      await this.offsetManager.resolveOffsets()\n\n      this.logger.debug(\n        `Fetching from ${activePartitions.length} partitions for ${activeTopics.length} out of ${topics.length} topics`,\n        {\n          topics,\n          activeTopicPartitions,\n          pausedTopicPartitions,\n        }\n      )\n\n      for (const topicPartition of activeTopicPartitions) {\n        const partitionsPerNode = this.findReadReplicaForPartitions(\n          topicPartition.topic,\n          topicPartition.partitions\n        )\n\n        const nodeIds = keys(partitionsPerNode)\n        const committedOffsets = this.offsetManager.committedOffsets()\n\n        for (const nodeId of nodeIds) {\n          const partitions = partitionsPerNode[nodeId]\n            .filter(partition => {\n              /**\n               * When recovering from OffsetOutOfRange, each partition can recover\n               * concurrently, which invalidates resolved and committed offsets as part\n               * of the recovery mechanism (see OffsetManager.clearOffsets). In concurrent\n               * scenarios this can initiate a new fetch with invalid offsets.\n               *\n               * This was further highlighted by https://github.com/tulios/kafkajs/pull/570,\n               * which increased concurrency, making this more likely to happen.\n               *\n               * This is solved by only making requests for partitions with initialized offsets.\n               *\n               * See the following pull request which explains the context of the problem:\n               * @issue https://github.com/tulios/kafkajs/pull/578\n               */\n              return committedOffsets[topicPartition.topic][partition] != null\n            })\n            .map(partition => ({\n              partition,\n              fetchOffset: this.offsetManager\n                .nextOffset(topicPartition.topic, partition)\n                .toString(),\n              maxBytes: maxBytesPerPartition,\n            }))\n\n          requestsPerNode[nodeId] = requestsPerNode[nodeId] || []\n          requestsPerNode[nodeId].push({ topic: topicPartition.topic, partitions })\n        }\n      }\n\n      const requests = keys(requestsPerNode).map(async nodeId => {\n        const broker = await this.cluster.findBroker({ nodeId })\n        const { responses } = await broker.fetch({\n          maxWaitTime,\n          minBytes,\n          maxBytes,\n          isolationLevel: this.isolationLevel,\n          topics: requestsPerNode[nodeId],\n          rackId: this.rackId,\n        })\n\n        const batchesPerPartition = responses.map(({ topicName, partitions }) => {\n          const topicRequestData = requestsPerNode[nodeId].find(({ topic }) => topic === topicName)\n          let preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topicName]\n          if (!preferredReadReplicas) {\n            this.preferredReadReplicasPerTopicPartition[topicName] = preferredReadReplicas = {}\n          }\n\n          return partitions\n            .filter(\n              partitionData =>\n                !this.seekOffset.has(topicName, partitionData.partition) &&\n                !this.subscriptionState.isPaused(topicName, partitionData.partition)\n            )\n            .map(partitionData => {\n              const { partition, preferredReadReplica } = partitionData\n              if (preferredReadReplica != null && preferredReadReplica !== -1) {\n                const { nodeId: currentPreferredReadReplica } =\n                  preferredReadReplicas[partition] || {}\n                if (currentPreferredReadReplica !== preferredReadReplica) {\n                  this.logger.info(`Preferred read replica is now ${preferredReadReplica}`, {\n                    groupId: this.groupId,\n                    memberId: this.memberId,\n                    topic: topicName,\n                    partition,\n                  })\n                }\n                preferredReadReplicas[partition] = {\n                  nodeId: preferredReadReplica,\n                  expireAt: Date.now() + this.metadataMaxAge,\n                }\n              }\n\n              const partitionRequestData = topicRequestData.partitions.find(\n                ({ partition }) => partition === partitionData.partition\n              )\n\n              const fetchedOffset = partitionRequestData.fetchOffset\n              const batch = new Batch(topicName, fetchedOffset, partitionData)\n\n              /**\n               * Resolve the offset to skip the control batch since `eachBatch` or `eachMessage` callbacks\n               * won't process empty batches\n               *\n               * @see https://github.com/apache/kafka/blob/9aa660786e46c1efbf5605a6a69136a1dac6edb9/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L1499-L1505\n               */\n              if (batch.isEmptyControlRecord() || batch.isEmptyDueToLogCompactedMessages()) {\n                this.resolveOffset({\n                  topic: batch.topic,\n                  partition: batch.partition,\n                  offset: batch.lastOffset(),\n                })\n              }\n\n              return batch\n            })\n        })\n\n        return flatten(batchesPerPartition)\n      })\n\n      // fetch can generate empty requests when the consumer group receives an assignment\n      // with more topics than the subscribed, so to prevent a busy loop we wait the\n      // configured max wait time\n      if (requests.length === 0) {\n        await sleep(this.maxWaitTime)\n        return BufferedAsyncIterator([])\n      }\n\n      return BufferedAsyncIterator(requests, e => this.recoverFromFetch(e))\n    } catch (e) {\n      await this.recoverFromFetch(e)\n    }\n  }\n\n  async recoverFromFetch(e) {\n    if (STALE_METADATA_ERRORS.includes(e.type) || e.name === 'KafkaJSTopicMetadataNotLoaded') {\n      this.logger.debug('Stale cluster metadata, refreshing...', {\n        groupId: this.groupId,\n        memberId: this.memberId,\n        error: e.message,\n      })\n\n      await this.cluster.refreshMetadata()\n      await this.joinAndSync()\n      throw new KafkaJSError(e.message)\n    }\n\n    if (e.name === 'KafkaJSStaleTopicMetadataAssignment') {\n      this.logger.warn(`${e.message}, resync group`, {\n        groupId: this.groupId,\n        memberId: this.memberId,\n        topic: e.topic,\n        unknownPartitions: e.unknownPartitions,\n      })\n\n      await this.joinAndSync()\n    }\n\n    if (e.name === 'KafkaJSOffsetOutOfRange') {\n      await this.recoverFromOffsetOutOfRange(e)\n    }\n\n    if (e.name === 'KafkaJSConnectionClosedError') {\n      this.cluster.removeBroker({ host: e.host, port: e.port })\n    }\n\n    if (e.name === 'KafkaJSBrokerNotFound' || e.name === 'KafkaJSConnectionClosedError') {\n      this.logger.debug(`${e.message}, refreshing metadata and retrying...`)\n      await this.cluster.refreshMetadata()\n    }\n\n    throw e\n  }\n\n  async recoverFromOffsetOutOfRange(e) {\n    // If we are fetching from a follower try with the leader before resetting offsets\n    const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[e.topic]\n    if (preferredReadReplicas && typeof preferredReadReplicas[e.partition] === 'number') {\n      this.logger.info('Offset out of range while fetching from follower, retrying with leader', {\n        topic: e.topic,\n        partition: e.partition,\n        groupId: this.groupId,\n        memberId: this.memberId,\n      })\n      delete preferredReadReplicas[e.partition]\n    } else {\n      this.logger.error('Offset out of range, resetting to default offset', {\n        topic: e.topic,\n        partition: e.partition,\n        groupId: this.groupId,\n        memberId: this.memberId,\n      })\n\n      await this.offsetManager.setDefaultOffset({\n        topic: e.topic,\n        partition: e.partition,\n      })\n    }\n  }\n\n  generatePartitionsPerSubscribedTopic() {\n    const map = new Map()\n\n    for (const topic of this.topicsSubscribed) {\n      const partitions = this.cluster\n        .findTopicPartitionMetadata(topic)\n        .map(m => m.partitionId)\n        .sort()\n\n      map.set(topic, partitions)\n    }\n\n    return map\n  }\n\n  checkForStaleAssignment() {\n    if (!this.partitionsPerSubscribedTopic) {\n      return\n    }\n\n    const newPartitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic()\n\n    for (const [topic, partitions] of newPartitionsPerSubscribedTopic) {\n      const diff = arrayDiff(partitions, this.partitionsPerSubscribedTopic.get(topic))\n\n      if (diff.length > 0) {\n        throw new KafkaJSStaleTopicMetadataAssignment('Topic has been updated', {\n          topic,\n          unknownPartitions: diff,\n        })\n      }\n    }\n  }\n\n  hasSeekOffset({ topic, partition }) {\n    return this.seekOffset.has(topic, partition)\n  }\n\n  /**\n   * For each of the partitions find the best nodeId to read it from\n   *\n   * @param {string} topic\n   * @param {number[]} partitions\n   * @returns {{[nodeId: number]: number[]}} per-node assignment of partitions\n   * @see Cluster~findLeaderForPartitions\n   */\n  // Invariant: The resulting object has each partition referenced exactly once\n  findReadReplicaForPartitions(topic, partitions) {\n    const partitionMetadata = this.cluster.findTopicPartitionMetadata(topic)\n    const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topic]\n    return partitions.reduce((result, id) => {\n      const partitionId = parseInt(id, 10)\n      const metadata = partitionMetadata.find(p => p.partitionId === partitionId)\n      if (!metadata) {\n        return result\n      }\n\n      if (metadata.leader == null) {\n        throw new KafkaJSError('Invalid partition metadata', { topic, partitionId, metadata })\n      }\n\n      // Pick the preferred replica if there is one, and it isn't known to be offline, otherwise the leader.\n      let nodeId = metadata.leader\n      if (preferredReadReplicas) {\n        const { nodeId: preferredReadReplica, expireAt } = preferredReadReplicas[partitionId] || {}\n        if (Date.now() >= expireAt) {\n          this.logger.debug('Preferred read replica information has expired, using leader', {\n            topic,\n            partitionId,\n            groupId: this.groupId,\n            memberId: this.memberId,\n            preferredReadReplica,\n            leader: metadata.leader,\n          })\n          // Drop the entry\n          delete preferredReadReplicas[partitionId]\n        } else if (preferredReadReplica != null) {\n          // Valid entry, check whether it is not offline\n          // Note that we don't delete the preference here, and rather hope that eventually that replica comes online again\n          const offlineReplicas = metadata.offlineReplicas\n          if (Array.isArray(offlineReplicas) && offlineReplicas.includes(nodeId)) {\n            this.logger.debug('Preferred read replica is offline, using leader', {\n              topic,\n              partitionId,\n              groupId: this.groupId,\n              memberId: this.memberId,\n              preferredReadReplica,\n              leader: metadata.leader,\n            })\n          } else {\n            nodeId = preferredReadReplica\n          }\n        }\n      }\n      const current = result[nodeId] || []\n      return { ...result, [nodeId]: [...current, partitionId] }\n    }, {})\n  }\n}\n"]},"metadata":{},"sourceType":"script"}