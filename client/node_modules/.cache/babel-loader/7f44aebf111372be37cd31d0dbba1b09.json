{"ast":null,"code":"const Encoder = require('../../../encoder');\n\nconst {\n  Fetch: apiKey\n} = require('../../apiKeys');\n/**\n * Fetch Request (Version: 3) => replica_id max_wait_time min_bytes max_bytes [topics]\n *   replica_id => INT32\n *   max_wait_time => INT32\n *   min_bytes => INT32\n *   max_bytes => INT32\n *   topics => topic [partitions]\n *     topic => STRING\n *     partitions => partition fetch_offset max_bytes\n *       partition => INT32\n *       fetch_offset => INT64\n *       max_bytes => INT32\n */\n\n/**\n * @param {number} replicaId Broker id of the follower\n * @param {number} maxWaitTime Maximum time in ms to wait for the response\n * @param {number} minBytes Minimum bytes to accumulate in the response.\n * @param {number} maxBytes Maximum bytes to accumulate in the response. Note that this is not an absolute maximum,\n *                          if the first message in the first non-empty partition of the fetch is larger than this value,\n *                          the message will still be returned to ensure that progress can be made.\n * @param {Array} topics Topics to fetch\n *                        [\n *                          {\n *                            topic: 'topic-name',\n *                            partitions: [\n *                              {\n *                                partition: 0,\n *                                fetchOffset: '4124',\n *                                maxBytes: 2048\n *                              }\n *                            ]\n *                          }\n *                        ]\n */\n\n\nmodule.exports = ({\n  replicaId,\n  maxWaitTime,\n  minBytes,\n  maxBytes,\n  topics\n}) => ({\n  apiKey,\n  apiVersion: 3,\n  apiName: 'Fetch',\n  encode: async () => {\n    return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeInt32(maxBytes).writeArray(topics.map(encodeTopic));\n  }\n});\n\nconst encodeTopic = ({\n  topic,\n  partitions\n}) => {\n  return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));\n};\n\nconst encodePartition = ({\n  partition,\n  fetchOffset,\n  maxBytes\n}) => {\n  return new Encoder().writeInt32(partition).writeInt64(fetchOffset).writeInt32(maxBytes);\n};","map":{"version":3,"sources":["/Users/gagekrumbach/Documents/call-center-manage/node_modules/kafkajs/src/protocol/requests/fetch/v3/request.js"],"names":["Encoder","require","Fetch","apiKey","module","exports","replicaId","maxWaitTime","minBytes","maxBytes","topics","apiVersion","apiName","encode","writeInt32","writeArray","map","encodeTopic","topic","partitions","writeString","encodePartition","partition","fetchOffset","writeInt64"],"mappings":"AAAA,MAAMA,OAAO,GAAGC,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAM;AAAEC,EAAAA,KAAK,EAAEC;AAAT,IAAoBF,OAAO,CAAC,eAAD,CAAjC;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACAG,MAAM,CAACC,OAAP,GAAiB,CAAC;AAAEC,EAAAA,SAAF;AAAaC,EAAAA,WAAb;AAA0BC,EAAAA,QAA1B;AAAoCC,EAAAA,QAApC;AAA8CC,EAAAA;AAA9C,CAAD,MAA6D;AAC5EP,EAAAA,MAD4E;AAE5EQ,EAAAA,UAAU,EAAE,CAFgE;AAG5EC,EAAAA,OAAO,EAAE,OAHmE;AAI5EC,EAAAA,MAAM,EAAE,YAAY;AAClB,WAAO,IAAIb,OAAJ,GACJc,UADI,CACOR,SADP,EAEJQ,UAFI,CAEOP,WAFP,EAGJO,UAHI,CAGON,QAHP,EAIJM,UAJI,CAIOL,QAJP,EAKJM,UALI,CAKOL,MAAM,CAACM,GAAP,CAAWC,WAAX,CALP,CAAP;AAMD;AAX2E,CAA7D,CAAjB;;AAcA,MAAMA,WAAW,GAAG,CAAC;AAAEC,EAAAA,KAAF;AAASC,EAAAA;AAAT,CAAD,KAA2B;AAC7C,SAAO,IAAInB,OAAJ,GAAcoB,WAAd,CAA0BF,KAA1B,EAAiCH,UAAjC,CAA4CI,UAAU,CAACH,GAAX,CAAeK,eAAf,CAA5C,CAAP;AACD,CAFD;;AAIA,MAAMA,eAAe,GAAG,CAAC;AAAEC,EAAAA,SAAF;AAAaC,EAAAA,WAAb;AAA0Bd,EAAAA;AAA1B,CAAD,KAA0C;AAChE,SAAO,IAAIT,OAAJ,GACJc,UADI,CACOQ,SADP,EAEJE,UAFI,CAEOD,WAFP,EAGJT,UAHI,CAGOL,QAHP,CAAP;AAID,CALD","sourcesContent":["const Encoder = require('../../../encoder')\nconst { Fetch: apiKey } = require('../../apiKeys')\n\n/**\n * Fetch Request (Version: 3) => replica_id max_wait_time min_bytes max_bytes [topics]\n *   replica_id => INT32\n *   max_wait_time => INT32\n *   min_bytes => INT32\n *   max_bytes => INT32\n *   topics => topic [partitions]\n *     topic => STRING\n *     partitions => partition fetch_offset max_bytes\n *       partition => INT32\n *       fetch_offset => INT64\n *       max_bytes => INT32\n */\n\n/**\n * @param {number} replicaId Broker id of the follower\n * @param {number} maxWaitTime Maximum time in ms to wait for the response\n * @param {number} minBytes Minimum bytes to accumulate in the response.\n * @param {number} maxBytes Maximum bytes to accumulate in the response. Note that this is not an absolute maximum,\n *                          if the first message in the first non-empty partition of the fetch is larger than this value,\n *                          the message will still be returned to ensure that progress can be made.\n * @param {Array} topics Topics to fetch\n *                        [\n *                          {\n *                            topic: 'topic-name',\n *                            partitions: [\n *                              {\n *                                partition: 0,\n *                                fetchOffset: '4124',\n *                                maxBytes: 2048\n *                              }\n *                            ]\n *                          }\n *                        ]\n */\nmodule.exports = ({ replicaId, maxWaitTime, minBytes, maxBytes, topics }) => ({\n  apiKey,\n  apiVersion: 3,\n  apiName: 'Fetch',\n  encode: async () => {\n    return new Encoder()\n      .writeInt32(replicaId)\n      .writeInt32(maxWaitTime)\n      .writeInt32(minBytes)\n      .writeInt32(maxBytes)\n      .writeArray(topics.map(encodeTopic))\n  },\n})\n\nconst encodeTopic = ({ topic, partitions }) => {\n  return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition))\n}\n\nconst encodePartition = ({ partition, fetchOffset, maxBytes }) => {\n  return new Encoder()\n    .writeInt32(partition)\n    .writeInt64(fetchOffset)\n    .writeInt32(maxBytes)\n}\n"]},"metadata":{},"sourceType":"script"}