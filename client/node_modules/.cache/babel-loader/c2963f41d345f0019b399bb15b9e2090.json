{"ast":null,"code":"const Encoder = require('../../../encoder');\n\nconst {\n  Fetch: apiKey\n} = require('../../apiKeys');\n\nconst ISOLATION_LEVEL = require('../../../isolationLevel');\n/**\n * Allow fetchers to detect and handle log truncation\n * @see https://cwiki.apache.org/confluence/display/KAFKA/KIP-320%3A+Allow+fetchers+to+detect+and+handle+log+truncation\n */\n\n/**\n * Fetch Request (Version: 9) => replica_id max_wait_time min_bytes max_bytes isolation_level session_id session_epoch [topics] [forgotten_topics_data]\n *   replica_id => INT32\n *   max_wait_time => INT32\n *   min_bytes => INT32\n *   max_bytes => INT32\n *   isolation_level => INT8\n *   session_id => INT32\n *   session_epoch => INT32\n *   topics => topic [partitions]\n *     topic => STRING\n *     partitions => partition current_leader_epoch fetch_offset log_start_offset partition_max_bytes\n *       partition => INT32\n *       current_leader_epoch => INT32\n *       fetch_offset => INT64\n *       log_start_offset => INT64\n *       partition_max_bytes => INT32\n *   forgotten_topics_data => topic [partitions]\n *     topic => STRING\n *     partitions => INT32\n */\n\n\nmodule.exports = ({\n  replicaId,\n  maxWaitTime,\n  minBytes,\n  maxBytes,\n  topics,\n  isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,\n  sessionId = 0,\n  sessionEpoch = -1,\n  forgottenTopics = [] // Topics to remove from the fetch session\n\n}) => ({\n  apiKey,\n  apiVersion: 9,\n  apiName: 'Fetch',\n  encode: async () => {\n    return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeInt32(maxBytes).writeInt8(isolationLevel).writeInt32(sessionId).writeInt32(sessionEpoch).writeArray(topics.map(encodeTopic)).writeArray(forgottenTopics.map(encodeForgottenTopics));\n  }\n});\n\nconst encodeForgottenTopics = ({\n  topic,\n  partitions\n}) => {\n  return new Encoder().writeString(topic).writeArray(partitions);\n};\n\nconst encodeTopic = ({\n  topic,\n  partitions\n}) => {\n  return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));\n};\n\nconst encodePartition = ({\n  partition,\n  currentLeaderEpoch = -1,\n  fetchOffset,\n  logStartOffset = -1,\n  maxBytes\n}) => {\n  return new Encoder().writeInt32(partition).writeInt32(currentLeaderEpoch).writeInt64(fetchOffset).writeInt64(logStartOffset).writeInt32(maxBytes);\n};","map":{"version":3,"sources":["/Users/gagekrumbach/Documents/call-center-manage/node_modules/kafkajs/src/protocol/requests/fetch/v9/request.js"],"names":["Encoder","require","Fetch","apiKey","ISOLATION_LEVEL","module","exports","replicaId","maxWaitTime","minBytes","maxBytes","topics","isolationLevel","READ_COMMITTED","sessionId","sessionEpoch","forgottenTopics","apiVersion","apiName","encode","writeInt32","writeInt8","writeArray","map","encodeTopic","encodeForgottenTopics","topic","partitions","writeString","encodePartition","partition","currentLeaderEpoch","fetchOffset","logStartOffset","writeInt64"],"mappings":"AAAA,MAAMA,OAAO,GAAGC,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAM;AAAEC,EAAAA,KAAK,EAAEC;AAAT,IAAoBF,OAAO,CAAC,eAAD,CAAjC;;AACA,MAAMG,eAAe,GAAGH,OAAO,CAAC,yBAAD,CAA/B;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEAI,MAAM,CAACC,OAAP,GAAiB,CAAC;AAChBC,EAAAA,SADgB;AAEhBC,EAAAA,WAFgB;AAGhBC,EAAAA,QAHgB;AAIhBC,EAAAA,QAJgB;AAKhBC,EAAAA,MALgB;AAMhBC,EAAAA,cAAc,GAAGR,eAAe,CAACS,cANjB;AAOhBC,EAAAA,SAAS,GAAG,CAPI;AAQhBC,EAAAA,YAAY,GAAG,CAAC,CARA;AAShBC,EAAAA,eAAe,GAAG,EATF,CASM;;AATN,CAAD,MAUV;AACLb,EAAAA,MADK;AAELc,EAAAA,UAAU,EAAE,CAFP;AAGLC,EAAAA,OAAO,EAAE,OAHJ;AAILC,EAAAA,MAAM,EAAE,YAAY;AAClB,WAAO,IAAInB,OAAJ,GACJoB,UADI,CACOb,SADP,EAEJa,UAFI,CAEOZ,WAFP,EAGJY,UAHI,CAGOX,QAHP,EAIJW,UAJI,CAIOV,QAJP,EAKJW,SALI,CAKMT,cALN,EAMJQ,UANI,CAMON,SANP,EAOJM,UAPI,CAOOL,YAPP,EAQJO,UARI,CAQOX,MAAM,CAACY,GAAP,CAAWC,WAAX,CARP,EASJF,UATI,CASON,eAAe,CAACO,GAAhB,CAAoBE,qBAApB,CATP,CAAP;AAUD;AAfI,CAVU,CAAjB;;AA4BA,MAAMA,qBAAqB,GAAG,CAAC;AAAEC,EAAAA,KAAF;AAASC,EAAAA;AAAT,CAAD,KAA2B;AACvD,SAAO,IAAI3B,OAAJ,GAAc4B,WAAd,CAA0BF,KAA1B,EAAiCJ,UAAjC,CAA4CK,UAA5C,CAAP;AACD,CAFD;;AAIA,MAAMH,WAAW,GAAG,CAAC;AAAEE,EAAAA,KAAF;AAASC,EAAAA;AAAT,CAAD,KAA2B;AAC7C,SAAO,IAAI3B,OAAJ,GAAc4B,WAAd,CAA0BF,KAA1B,EAAiCJ,UAAjC,CAA4CK,UAAU,CAACJ,GAAX,CAAeM,eAAf,CAA5C,CAAP;AACD,CAFD;;AAIA,MAAMA,eAAe,GAAG,CAAC;AACvBC,EAAAA,SADuB;AAEvBC,EAAAA,kBAAkB,GAAG,CAAC,CAFC;AAGvBC,EAAAA,WAHuB;AAIvBC,EAAAA,cAAc,GAAG,CAAC,CAJK;AAKvBvB,EAAAA;AALuB,CAAD,KAMlB;AACJ,SAAO,IAAIV,OAAJ,GACJoB,UADI,CACOU,SADP,EAEJV,UAFI,CAEOW,kBAFP,EAGJG,UAHI,CAGOF,WAHP,EAIJE,UAJI,CAIOD,cAJP,EAKJb,UALI,CAKOV,QALP,CAAP;AAMD,CAbD","sourcesContent":["const Encoder = require('../../../encoder')\nconst { Fetch: apiKey } = require('../../apiKeys')\nconst ISOLATION_LEVEL = require('../../../isolationLevel')\n\n/**\n * Allow fetchers to detect and handle log truncation\n * @see https://cwiki.apache.org/confluence/display/KAFKA/KIP-320%3A+Allow+fetchers+to+detect+and+handle+log+truncation\n */\n\n/**\n * Fetch Request (Version: 9) => replica_id max_wait_time min_bytes max_bytes isolation_level session_id session_epoch [topics] [forgotten_topics_data]\n *   replica_id => INT32\n *   max_wait_time => INT32\n *   min_bytes => INT32\n *   max_bytes => INT32\n *   isolation_level => INT8\n *   session_id => INT32\n *   session_epoch => INT32\n *   topics => topic [partitions]\n *     topic => STRING\n *     partitions => partition current_leader_epoch fetch_offset log_start_offset partition_max_bytes\n *       partition => INT32\n *       current_leader_epoch => INT32\n *       fetch_offset => INT64\n *       log_start_offset => INT64\n *       partition_max_bytes => INT32\n *   forgotten_topics_data => topic [partitions]\n *     topic => STRING\n *     partitions => INT32\n */\n\nmodule.exports = ({\n  replicaId,\n  maxWaitTime,\n  minBytes,\n  maxBytes,\n  topics,\n  isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,\n  sessionId = 0,\n  sessionEpoch = -1,\n  forgottenTopics = [], // Topics to remove from the fetch session\n}) => ({\n  apiKey,\n  apiVersion: 9,\n  apiName: 'Fetch',\n  encode: async () => {\n    return new Encoder()\n      .writeInt32(replicaId)\n      .writeInt32(maxWaitTime)\n      .writeInt32(minBytes)\n      .writeInt32(maxBytes)\n      .writeInt8(isolationLevel)\n      .writeInt32(sessionId)\n      .writeInt32(sessionEpoch)\n      .writeArray(topics.map(encodeTopic))\n      .writeArray(forgottenTopics.map(encodeForgottenTopics))\n  },\n})\n\nconst encodeForgottenTopics = ({ topic, partitions }) => {\n  return new Encoder().writeString(topic).writeArray(partitions)\n}\n\nconst encodeTopic = ({ topic, partitions }) => {\n  return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition))\n}\n\nconst encodePartition = ({\n  partition,\n  currentLeaderEpoch = -1,\n  fetchOffset,\n  logStartOffset = -1,\n  maxBytes,\n}) => {\n  return new Encoder()\n    .writeInt32(partition)\n    .writeInt32(currentLeaderEpoch)\n    .writeInt64(fetchOffset)\n    .writeInt64(logStartOffset)\n    .writeInt32(maxBytes)\n}\n"]},"metadata":{},"sourceType":"script"}