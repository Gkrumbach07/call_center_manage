{"ast":null,"code":"const Decoder = require('../../../decoder');\n\nconst {\n  KafkaJSDeleteTopicRecordsError\n} = require('../../../../errors');\n\nconst {\n  failure,\n  createErrorFromCode\n} = require('../../../error');\n/**\n * DeleteRecords Response (Version: 0) => throttle_time_ms [topics]\n *  throttle_time_ms => INT32\n *  topics => name [partitions]\n *    name => STRING\n *    partitions => partition low_watermark error_code\n *      partition => INT32\n *      low_watermark => INT64\n *      error_code => INT16\n */\n\n\nconst topicNameComparator = (a, b) => a.topic.localeCompare(b.topic);\n\nconst decode = async rawData => {\n  const decoder = new Decoder(rawData);\n  return {\n    throttleTime: decoder.readInt32(),\n    topics: decoder.readArray(decoder => ({\n      topic: decoder.readString(),\n      partitions: decoder.readArray(decoder => ({\n        partition: decoder.readInt32(),\n        lowWatermark: decoder.readInt64(),\n        errorCode: decoder.readInt16()\n      }))\n    })).sort(topicNameComparator)\n  };\n};\n\nconst parse = requestTopics => async data => {\n  const topicsWithErrors = data.topics.map(({\n    partitions\n  }) => ({\n    partitionsWithErrors: partitions.filter(({\n      errorCode\n    }) => failure(errorCode))\n  })).filter(({\n    partitionsWithErrors\n  }) => partitionsWithErrors.length);\n\n  if (topicsWithErrors.length > 0) {\n    // at present we only ever request one topic at a time, so can destructure the arrays\n    const [{\n      topic\n    }] = data.topics; // topic name\n\n    const [{\n      partitions: requestPartitions\n    }] = requestTopics; // requested offset(s)\n\n    const [{\n      partitionsWithErrors\n    }] = topicsWithErrors; // partition(s) + error(s)\n\n    throw new KafkaJSDeleteTopicRecordsError({\n      topic,\n      partitions: partitionsWithErrors.map(({\n        partition,\n        errorCode\n      }) => ({\n        partition,\n        error: createErrorFromCode(errorCode),\n        // attach the original offset from the request, onto the error response\n        offset: requestPartitions.find(p => p.partition === partition).offset\n      }))\n    });\n  }\n\n  return data;\n};\n\nmodule.exports = ({\n  topics\n}) => ({\n  decode,\n  parse: parse(topics)\n});","map":{"version":3,"sources":["/Users/gagekrumbach/Documents/call-center-manage/node_modules/kafkajs/src/protocol/requests/deleteRecords/v0/response.js"],"names":["Decoder","require","KafkaJSDeleteTopicRecordsError","failure","createErrorFromCode","topicNameComparator","a","b","topic","localeCompare","decode","rawData","decoder","throttleTime","readInt32","topics","readArray","readString","partitions","partition","lowWatermark","readInt64","errorCode","readInt16","sort","parse","requestTopics","data","topicsWithErrors","map","partitionsWithErrors","filter","length","requestPartitions","error","offset","find","p","module","exports"],"mappings":"AAAA,MAAMA,OAAO,GAAGC,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAM;AAAEC,EAAAA;AAAF,IAAqCD,OAAO,CAAC,oBAAD,CAAlD;;AACA,MAAM;AAAEE,EAAAA,OAAF;AAAWC,EAAAA;AAAX,IAAmCH,OAAO,CAAC,gBAAD,CAAhD;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,MAAMI,mBAAmB,GAAG,CAACC,CAAD,EAAIC,CAAJ,KAAUD,CAAC,CAACE,KAAF,CAAQC,aAAR,CAAsBF,CAAC,CAACC,KAAxB,CAAtC;;AAEA,MAAME,MAAM,GAAG,MAAMC,OAAN,IAAiB;AAC9B,QAAMC,OAAO,GAAG,IAAIZ,OAAJ,CAAYW,OAAZ,CAAhB;AACA,SAAO;AACLE,IAAAA,YAAY,EAAED,OAAO,CAACE,SAAR,EADT;AAELC,IAAAA,MAAM,EAAEH,OAAO,CACZI,SADK,CACKJ,OAAO,KAAK;AACrBJ,MAAAA,KAAK,EAAEI,OAAO,CAACK,UAAR,EADc;AAErBC,MAAAA,UAAU,EAAEN,OAAO,CAACI,SAAR,CAAkBJ,OAAO,KAAK;AACxCO,QAAAA,SAAS,EAAEP,OAAO,CAACE,SAAR,EAD6B;AAExCM,QAAAA,YAAY,EAAER,OAAO,CAACS,SAAR,EAF0B;AAGxCC,QAAAA,SAAS,EAAEV,OAAO,CAACW,SAAR;AAH6B,OAAL,CAAzB;AAFS,KAAL,CADZ,EASLC,IATK,CASAnB,mBATA;AAFH,GAAP;AAaD,CAfD;;AAiBA,MAAMoB,KAAK,GAAGC,aAAa,IAAI,MAAMC,IAAN,IAAc;AAC3C,QAAMC,gBAAgB,GAAGD,IAAI,CAACZ,MAAL,CACtBc,GADsB,CAClB,CAAC;AAAEX,IAAAA;AAAF,GAAD,MAAqB;AACxBY,IAAAA,oBAAoB,EAAEZ,UAAU,CAACa,MAAX,CAAkB,CAAC;AAAET,MAAAA;AAAF,KAAD,KAAmBnB,OAAO,CAACmB,SAAD,CAA5C;AADE,GAArB,CADkB,EAItBS,MAJsB,CAIf,CAAC;AAAED,IAAAA;AAAF,GAAD,KAA8BA,oBAAoB,CAACE,MAJpC,CAAzB;;AAMA,MAAIJ,gBAAgB,CAACI,MAAjB,GAA0B,CAA9B,EAAiC;AAC/B;AACA,UAAM,CAAC;AAAExB,MAAAA;AAAF,KAAD,IAAcmB,IAAI,CAACZ,MAAzB,CAF+B,CAEC;;AAChC,UAAM,CAAC;AAAEG,MAAAA,UAAU,EAAEe;AAAd,KAAD,IAAsCP,aAA5C,CAH+B,CAG2B;;AAC1D,UAAM,CAAC;AAAEI,MAAAA;AAAF,KAAD,IAA6BF,gBAAnC,CAJ+B,CAIqB;;AAEpD,UAAM,IAAI1B,8BAAJ,CAAmC;AACvCM,MAAAA,KADuC;AAEvCU,MAAAA,UAAU,EAAEY,oBAAoB,CAACD,GAArB,CAAyB,CAAC;AAAEV,QAAAA,SAAF;AAAaG,QAAAA;AAAb,OAAD,MAA+B;AAClEH,QAAAA,SADkE;AAElEe,QAAAA,KAAK,EAAE9B,mBAAmB,CAACkB,SAAD,CAFwC;AAGlE;AACAa,QAAAA,MAAM,EAAEF,iBAAiB,CAACG,IAAlB,CAAuBC,CAAC,IAAIA,CAAC,CAAClB,SAAF,KAAgBA,SAA5C,EAAuDgB;AAJG,OAA/B,CAAzB;AAF2B,KAAnC,CAAN;AASD;;AAED,SAAOR,IAAP;AACD,CAzBD;;AA2BAW,MAAM,CAACC,OAAP,GAAiB,CAAC;AAAExB,EAAAA;AAAF,CAAD,MAAiB;AAChCL,EAAAA,MADgC;AAEhCe,EAAAA,KAAK,EAAEA,KAAK,CAACV,MAAD;AAFoB,CAAjB,CAAjB","sourcesContent":["const Decoder = require('../../../decoder')\nconst { KafkaJSDeleteTopicRecordsError } = require('../../../../errors')\nconst { failure, createErrorFromCode } = require('../../../error')\n\n/**\n * DeleteRecords Response (Version: 0) => throttle_time_ms [topics]\n *  throttle_time_ms => INT32\n *  topics => name [partitions]\n *    name => STRING\n *    partitions => partition low_watermark error_code\n *      partition => INT32\n *      low_watermark => INT64\n *      error_code => INT16\n */\n\nconst topicNameComparator = (a, b) => a.topic.localeCompare(b.topic)\n\nconst decode = async rawData => {\n  const decoder = new Decoder(rawData)\n  return {\n    throttleTime: decoder.readInt32(),\n    topics: decoder\n      .readArray(decoder => ({\n        topic: decoder.readString(),\n        partitions: decoder.readArray(decoder => ({\n          partition: decoder.readInt32(),\n          lowWatermark: decoder.readInt64(),\n          errorCode: decoder.readInt16(),\n        })),\n      }))\n      .sort(topicNameComparator),\n  }\n}\n\nconst parse = requestTopics => async data => {\n  const topicsWithErrors = data.topics\n    .map(({ partitions }) => ({\n      partitionsWithErrors: partitions.filter(({ errorCode }) => failure(errorCode)),\n    }))\n    .filter(({ partitionsWithErrors }) => partitionsWithErrors.length)\n\n  if (topicsWithErrors.length > 0) {\n    // at present we only ever request one topic at a time, so can destructure the arrays\n    const [{ topic }] = data.topics // topic name\n    const [{ partitions: requestPartitions }] = requestTopics // requested offset(s)\n    const [{ partitionsWithErrors }] = topicsWithErrors // partition(s) + error(s)\n\n    throw new KafkaJSDeleteTopicRecordsError({\n      topic,\n      partitions: partitionsWithErrors.map(({ partition, errorCode }) => ({\n        partition,\n        error: createErrorFromCode(errorCode),\n        // attach the original offset from the request, onto the error response\n        offset: requestPartitions.find(p => p.partition === partition).offset,\n      })),\n    })\n  }\n\n  return data\n}\n\nmodule.exports = ({ topics }) => ({\n  decode,\n  parse: parse(topics),\n})\n"]},"metadata":{},"sourceType":"script"}